{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"What is SFTPGo?","text":""},{"location":"#what-is-sftpgo","title":"What is SFTPGo?","text":"<p>SFTPGo is a managed, event-driven file transfer solution that abstracts storage backends and provides access to files through its built-in WebClient over HTTPS, as well as via standard SFTP, SCP, FTP/S, and WebDAV protocols.</p> <p>With SFTPGo you can leverage local and cloud storage backends for exchanging and storing files internally or with business partners using the same tools and processes you are already familiar with.</p> <p>The WebAdmin UI allows to easily create and manage your users, folders, groups and other resources.</p> <p>The WebClient UI allows end users to change their credentials, browse and manage their files in the browser and setup two-factor authentication which works with Microsoft Authenticator, Google Authenticator, Authy and other compatible apps.</p> <p>SFTPGo in short:</p> <ul> <li>Event driven file transfer solution.</li> <li>Multiple protocols: SFTP, SCP, FTP/S, WebDAV, HTTP/S, REST API.</li> <li>Multiple storage backends: S3 Compatible, Google Cloud Storage, Azure Blob, other SFTP servers, local filesystem, encrypted local filesystem.</li> <li>Multiple data providers: SQLite, MySQL, PostresSQL, CockroachDB, Bolt and in-memory.</li> <li>Extensible via plugins and hooks.</li> <li>It works everywhere: on small embedded devices or large Kubernetes clusters. On Linux, Windows, macOS, FreeBSD. On x86, arm, ppc64.</li> </ul> <p></p>"},{"location":"#enterprise-edition","title":"Enterprise edition","text":"<p>This documentation applies to the Enterprise edition of SFTPGo. If you're using the Open Source edition, please refer to the corresponding documentation.</p> <p>SFTPGo Enterprise is an enhanced version of the open-source SFTPGo, based on its core functionality, and tailored for organizations that require more advanced features, improved performance and a commercially licensed solution.</p> <p>New features are regularly added to the Enterprise edition, which may or may not be backported to the open-source edition.</p> <p>Key Enhancements:</p> <ul> <li>Significant performance improvements for cloud storage backends \u2014 up to 70% faster when transferring many small files.</li> <li>A more powerful EventManager, enabling advanced and flexible automation workflows.</li> <li>PGP encryption and decryption.</li> <li>WOPI protocol integration, allowing in-browser document editing and real-time collaboration directly within the SFTPGo WebClient. Multiple users can edit the same document simultaneously, with live updates for all participants.</li> <li>Email-based authentication and group delegation for public shares, enhancing security and access control.</li> <li>Numerous additional customization options and configuration improvements across the platform.</li> <li>Additional storage backends.</li> <li>Automatic file ingestion from IMAP mailbox attachments.</li> <li>ICAP integration for antivirus and DLP scanning.</li> <li>Support included.</li> </ul> <p>The open-source version of SFTPGo will continue to be maintained and updated with bug fixes and improvements, ensuring both versions remain reliable and functional.</p>"},{"location":"#licensing","title":"Licensing","text":"<p>The Enterprise version is offered under a proprietary license that removes the restrictions of the open-source AGPLv3.</p>"},{"location":"#copyright","title":"Copyright","text":"<p>Copyright (C) 2019 - 2026 Nicola Murino</p>"},{"location":"azure-blob-storage/","title":"Azure Blob","text":""},{"location":"azure-blob-storage/#azure-blob-storage-backend","title":"Azure Blob Storage backend","text":"<p>To connect SFTPGo to Azure Blob Storage, you need to specify the access credentials. Azure Blob Storage has different options for credentials, we support:</p> <ol> <li>Providing an account name and account key.</li> <li>Providing a shared access signature (SAS).</li> </ol> <p>If you authenticate using account and key you also need to specify a container. The endpoint can generally be left blank, the default is <code>blob.core.windows.net</code>.</p> <p>If you provide a SAS URL the container is optional and if given it must match the one inside the shared access signature.</p> <p>If you want to connect to an emulator such as Azurite you need to provide the account name/key pair and an endpoint prefixed with the protocol, for example <code>http://127.0.0.1:10000</code>.</p> <p>Specifying a different <code>key_prefix</code>, you can assign different \"folders\" of the same container to different users. This is similar to a chroot directory for local filesystem. Each SFTPGo user can only access the assigned folder and its contents. The folder identified by <code>key_prefix</code> does not need to be pre-created.</p> <p>For multipart uploads you can customize the parts size and the upload concurrency. Please note that if the upload bandwidth between the client and SFTPGo is greater than the upload bandwidth between SFTPGo and the Azure Blob service then the client should wait for the last parts to be uploaded to Azure after finishing uploading the file to SFTPGo, and it may time out. Keep this in mind if you customize these parameters.</p> <p>The configured container must exist.</p> <p>This backend is very similar to the S3 backend, and it has similar limitations.</p>"},{"location":"changelog/","title":"Release Notes","text":""},{"location":"changelog/#release-notes","title":"Release Notes","text":"<p>This page provides a concise overview of the new features, improvements and bug fixes introduced in each SFTPGo Enterprise release. We encourage you to check back regularly to stay up to date with the latest changes and to make the most of all enhancements.</p>"},{"location":"changelog/#compatibility-notes","title":"Compatibility notes","text":"<p>Upgrading to the Enterprise edition of SFTPGo is supported starting from Open Source release 2.6.x.</p> <p>If you're migrating from an open-source installation, please follow the guide here: Migration from Open-Source 2.6.x to Enterprise</p>"},{"location":"changelog/#update-january-20-2026-v2720260120","title":"Update January 20, 2026 - v2.7.20260120","text":""},{"location":"changelog/#new-features","title":"New features","text":"<ul> <li>Hooks: Added the ability to automatically create virtual folders from the pre-login and pre-auth hooks by setting the <code>SFTPGO_HOOK__AUTO_FOLDERS</code> environment variable to <code>1</code>.</li> <li>Pre-login hook: Added support for returning a different username than the one used during login.</li> <li>EventManaged: Added the <code>{{.Shares}}</code> lazy placeholder to retrieve the shares associated with the path on which the filesystem action was executed.</li> <li>REST API: Introduced the ability to change the log level dynamically without restarting the service.</li> </ul>"},{"location":"changelog/#bug-fixes","title":"Bug fixes","text":"<ul> <li>Data Provider: Fixed lock handling issues during migrations that could affect MySQL when migrations are executed concurrently by multiple instances.</li> <li>Shares: Fixed a bug introduced in <code>v2.7.20260110</code> that prevented uploads to write-only shares from the WebClient.</li> </ul>"},{"location":"changelog/#update-january-10-2026-v2720260110","title":"Update January 10, 2026 - v2.7.20260110","text":""},{"location":"changelog/#new-features_1","title":"New features","text":"<ul> <li>EventManager: Added <code>IMAP</code> action allowing to automatically retrieves email attachments from IMAP mailboxes and makes them available in SFTPGo. Attachments can be placed in a user\u2019s home directory or mapped into a virtual folder, enabling seamless ingestion of files delivered via email.</li> <li>EventManager: Removed hard-coded subjects for emails generated from filesystem templates (outside EventManager) and made them configurable via environment variables.</li> <li>EventManager: Added an <code>ICAP</code> action to enable integration with ICAP servers for antivirus scanning and DLP checks as part of SFTPGo rules, with automatic handling based on scan results (block, adapt, quarantine, or trigger notifications).</li> <li>EventManager: Added <code>ShareExpiration</code> action to automate share lifecycle management. It enables expiration based on inactivity thresholds or token exhaustion, with support for pre-expiration warnings (<code>AdvanceNotice</code>) and soft deletes (<code>GracePeriod</code>). The action handles group shares by notifying all members during the warning phase while restricting the deletion event to the share owner.</li> <li>SFTPD: Allow to hide dot directory entries.</li> <li>Shares: Added support for associating groups with shares. This allows permissions to read, update, and delete shares to be granted to members of the same group, facilitating team collaboration and delegation.</li> <li>OIDC: Added support for configuring the claim values used to map an OIDC-authenticated user to an SFTPGo admin. Previously, only the fixed value <code>admin</code> was accepted and could not be customized.</li> <li>OIDC: Added support for <code>max_age</code> and <code>prompt</code> parameters to enforce re-authentication based on session age and control the login/consent interaction.</li> <li>WebAdmin UI / REST API: Added support for configuring request size limits. Previously, the maximum size for HTTP request payloads was fixed at 1 MB.</li> <li>WebClient: Added support for cloning shares.</li> <li>WebAdmin / WebClient: Added Chinese and Spanish translations.</li> <li>Web UI: Added a new option in the Branding section that allows hiding the WebAdmin or WebClient link from the login page.</li> <li>Users: Added support for multiple custom placeholders (up to 10), which can be referenced in group configurations as <code>%custom1%</code>, <code>%custom2%</code>, and so on.</li> </ul>"},{"location":"changelog/#bug-fixes_1","title":"Bug fixes","text":"<ul> <li>EventManager: optimized filtering by pushing queries down to the database when no wildcards are used, also resolving certain incorrect results for inverse matches.</li> <li>PreLogin hook: Previously, partial user objects were accepted, which could lead to inconsistent updates (e.g., merging instead of replacing per-directory permissions). Now, the hook requires either a complete user object or an empty response if no modifications are needed.</li> </ul>"},{"location":"changelog/#backward-incompatible-changes","title":"Backward incompatible changes","text":"<ul> <li>Enforced stricter validation for usernames and object names: Control characters, <code>/</code>, and <code>\\</code> are now rejected. These characters are included, URL-encoded, in request paths (e.g., <code>/web/admin/user/&lt;username&gt;</code>) and can be misinterpreted by some older proxy servers, potentially causing request routing issues.</li> <li>OAuth2: PKCE is now enabled by default to improve security. If you are connecting to a legacy OAuth2/OIDC endpoint, you can disable PKCE in your configuration.</li> <li>OIDC: Matching of role claim values used to map an OIDC-authenticated user to an SFTPGo admin is now case-insensitive.</li> <li>Public Shares API: The file upload endpoint has been updated from <code>POST /api/v2/shares/{id}/{filePath}</code> to <code>POST /api/v2/shares/{id}/files/{filePath}</code>. Previously, the file path was required to be a single, fully URL-encoded segment (e.g. <code>dir%2Ffile.txt</code>). The new endpoint supports standard slash-delimited paths (e.g. <code>dir/file.txt</code>). This change resolves 404 errors that could occur in edge cases with the previous URL structure.</li> </ul>"},{"location":"changelog/#update-november-7-2025-v2720251107","title":"Update November 7, 2025 - v2.7.20251107","text":""},{"location":"changelog/#new-features_2","title":"New features","text":"<ul> <li>New storage backend: Added FTP as a storage backend. This allows using an external FTP server for storage, as well as integrating FTP virtual folders with the EventManager to push or pull files over FTP/S.</li> <li>REST API: Added the <code>/api/v2/saas/usage</code> endpoint to retrieve storage and bandwidth usage for SFTPGo SaaS deployments.</li> <li>Added static password validation rules to enforce minimum length, uppercase, lowercase, digit, and special character requirements. While this feature was introduced following multiple requests, we still recommend using the password strength setting instead, as it evaluates the overall cryptographic strength of passwords and provides stronger security.</li> <li>SSH: When the <code>Enforce secure algorithms</code> setting is enabled, public key signature algorithms are now also validated.</li> <li>Auth plugin: Import email addresses from Active Directory when creating SFTPGo users.</li> <li>EventManager: Added a new action for extracting ZIP archives.</li> <li>EventManager: Added <code>fromMillis</code> helper function to easily convert Unix timestamp expressed in milliseconds into time objects.</li> <li>EventManager: Scheduling rules now support minute-level precision.</li> <li>SFTPD: Added support for OpenPubkey SSH, enabling tighter integration between OpenID Connect and SFTP.</li> <li>JWT: Replaced lestrrat-go/jwx with a lightweight wrapper around go-jose. Implementing our own wrapper simplifies the codebase and improves maintainability. Moreover, go-jose depends only on the standard library, resulting in a leaner dependency that still meets all our requirements.</li> </ul>"},{"location":"changelog/#bug-fixes_2","title":"Bug fixes","text":"<ul> <li>Enforced password validation rules also when applied through a group.</li> <li>Upload Resume: Improved and finalized the fix introduced in <code>v2.7.20251009</code>.</li> <li>Fixed an issue where <code>X-Forwarded-For</code> headers containing a port number were not handled correctly.</li> <li>IP addresses in the trusted list were never blocked, but they were still counted toward auto-blocking, which caused confusion.</li> </ul>"},{"location":"changelog/#update-october-9-2025-v2720251009","title":"Update October 9, 2025 - v2.7.20251009","text":""},{"location":"changelog/#new-features_3","title":"New features","text":"<ul> <li>EventManager: Introduced support for split retention report notifications, enabling separate email notifications to be sent to individual users.</li> <li>EventManager: Added the <code>{{.ExtName}}</code> placeholder, representing the email address used for authenticating public shares with email-based access.</li> <li>Status page: Added display of license information.</li> <li>WebClient: External users can now explicitly create directories in public shares.</li> <li>WebClient: Added the ability to modify the name of a public share and display it to external users.</li> <li>WebUI: Updated to Bootstrap 5.3.8, Axios 1.12.2, and the latest versions of other dependencies.</li> <li>WebUI: Added support for cloning groups, rules and actions.</li> <li>FTPD: Added TLS version and cipher suite information to the login log.</li> <li>Windows: Added support for installing the service under a custom user account via command line.</li> </ul>"},{"location":"changelog/#bug-fixes_3","title":"Bug fixes","text":"<ul> <li>Upload Resume: Fixed edge cases related to resuming uploads with cloud storage backends.</li> <li>WebAdmin UI: preserve condition pattern order to ensure correct filter evaluation, especially with inverse matches.</li> <li>Cloud Storage backends: Fixed a rare bug that could cause directory listings to fail under specific conditions.</li> </ul>"},{"location":"changelog/#backward-incompatible-changes_1","title":"Backward incompatible changes","text":"<ul> <li>Removed <code>rsync</code> support. In the previous versions, rsync was executed as an external command, which means we have no insight into or control over what it actually does. From a security perspective, this is far from ideal. To be clear, there's nothing inherently wrong with <code>rsync</code> itself. However, if we were to support it properly within SFTPGo, we would need to implement the low-level protocol internally rather than relying on launching an external process. This would ensure it works seamlessly with any storage backend, just as SFTP does, for example. We recommend using one of the many alternatives that rely on the SFTP protocol, such as <code>rclone</code>.</li> <li>Windows: To clearly differentiate the Enterprise edition from the open source version, the installer now uses a distinct GUID and installs SFTPGo into the folder named \"SFTPGo Enterprise\".</li> </ul>"},{"location":"changelog/#documentation","title":"Documentation","text":"<ul> <li>Added a tutorial on public shares.</li> <li>Expanded the Event Manager tutorial with a PGP usage example.</li> </ul>"},{"location":"changelog/#update-august-31-2025-v2720250831","title":"Update August 31, 2025 - v2.7.20250831","text":""},{"location":"changelog/#new-features_4","title":"New features","text":"<ul> <li>Added support for license keys and made the Enterprise Edition generally available.</li> <li>SFTP storage backend: Added support for SOCKS proxy versions v4 and v4a.</li> <li>Preserve sort order for related folders and groups, improving compatibility and predictability when used with the Terraform provider.</li> <li>Cluster mode: ensures near real-time propagation of event rule updates, IP lists, and license changes across all cluster nodes.</li> <li>Password hashing: Introduced general support for importing password using the <code>yescrypt</code> format.</li> <li>EventManager: Added \"Metadata Check\" action to verify the presence or value of a metadata key in cloud storage backends, with optional retries and timeout.</li> </ul>"},{"location":"changelog/#bug-fixes_4","title":"Bug fixes","text":"<ul> <li>SMTP: Fixed OAuth2 authentication issue when using the Microsoft provider with a tenant ID.</li> <li>Fixed a rare edge case where transfers could remain stalled due to unresponsive storage backends.</li> <li>WebDAV: Fixed an issue where some scanner devices failed to process PROPFIND responses returned for GET requests on collection resources.</li> <li>Preserved the initial sort order of folders and groups to improve compatibility and ensure predictable behavior when used with Terraform.</li> </ul>"},{"location":"changelog/#backward-incompatible-changes_2","title":"Backward incompatible changes","text":"<ul> <li>Removed Git support. Hosting Git repositories over SSH falls outside the intended scope of a file transfer solution, and the use of external commands introduces unnecessary security risks by increasing the attack surface.</li> </ul>"},{"location":"changelog/#update-july-26-2025-v2720250726","title":"Update July 26, 2025 - v2.7.20250726","text":""},{"location":"changelog/#new-features_5","title":"New features","text":"<ul> <li>EventManager: Completely rewritten the action placeholder system to significantly improve flexibility. Please refer to the documentation for details and migration steps. Note that this change may break compatibility in some cases. Don\u2019t hesitate to contact us if you need assistance migrating your actions.</li> <li>EventManager: Added an optional archive folder to the data retention action, enabling files to be moved to the specified virtual folder instead of being deleted.</li> <li>Users: Added support for a custom placeholder value set in user configurations. It can be referenced as <code>%custom1%</code> within group configurations.</li> <li>User Templates: Added support for password change requirement option.</li> </ul>"},{"location":"changelog/#bug-fixes_5","title":"Bug fixes","text":"<ul> <li>PGP: Fixed support for keys without flags, making behavior consistent with the <code>gpg</code> CLI tool.</li> <li>OIDC: Use the global HTTP client to ensure consistent settings, such as timeouts and TLS.</li> <li>WOPI: Use the global HTTP client to ensure consistent settings, such as timeouts and TLS. Removed <code>skip_tls_verify</code>.</li> <li>EventManager: Updated user inactivity calculation to also consider the <code>updated at</code> timestamp.</li> <li>Active Sessions: Fixed a rare edge case that could cause incorrect calculation of the number of currently active sessions.</li> <li>WebClient: Improved layout and responsiveness on mobile browsers.</li> <li>Memorypipe: Fixed edge cases that could occur during retries of multipart requests.</li> </ul>"},{"location":"changelog/#backward-incompatible-changes_3","title":"Backward incompatible changes","text":"<ul> <li>EventManager: Removed the Data Retention API. You can achieve equivalent functionality using the Data Retention Check action.</li> <li>EventManager: Removed several placeholders. Refer to the migration guide to update your existing actions accordingly.</li> <li>SFTPFs: Removed the root directory existence check. If a root path is configured, it is now assumed to exist, avoiding redundant and time-consuming validations. This change improves login times in environments with multiple virtual folders backed by SFTP, particularly when one or more of the backend SFTP storage endpoints are unreachable or experiencing timeouts.</li> </ul>"},{"location":"changelog/#update-july-2-2025-v2720250702","title":"Update July 2, 2025 - v2.7.20250702","text":""},{"location":"changelog/#new-features_6","title":"New features","text":"<ul> <li>EventManager: Added support for folder integration to simplify pushing files to external SFTP servers and other storage backends, either after an upload or on a scheduled basis. Tutorials have been updated with examples demonstrating folders integration.</li> <li>WebAdmin: Added the ability to disable password authentication for administrators. This is useful if you want to enforce API key\u2013only access or restrict login to OpenID Connect.</li> <li>Audit Log: Log entries for configuration changes now include details about the specific modified section.</li> <li>Terraform Provider: Updated to fully support SFTPGo Enterprise.</li> <li>Extend metadata propagation in cloud storage to include <code>delete</code>, <code>rename</code>, and <code>copy</code> events. Support for these features depends on the storage backend: for example, metadata may not always be available with S3, whereas it is consistently supported with Google Cloud Storage and Azure Blob Storage.</li> <li>WebUI: Added autofocus to the login and 2FA input fields, improving the user experience by automatically focusing on the first field when the page loads.</li> <li>REST API documentation for SFTPGo Enterprise is now hosted on the sftpgo.com domain.</li> </ul>"},{"location":"changelog/#update-june-7-2025-v2720250607","title":"Update June 7, 2025 - v2.7.20250607","text":""},{"location":"changelog/#new-features_7","title":"New features","text":"<ul> <li>Google Cloud Storage: Added support for Hierarchical Namespace enabled buckets.</li> <li>OIDC: UI display name is now configurable. The label \"Sign in with OpenID\" on the login screen is now configurable. You can change <code>OpenID</code> to something else.</li> <li>OIDC: added support for discovery when the issuer URL and discovery URL differ (e.g. Azure B2C). This behavior is disabled by default and can be enabled by setting the environment variable <code>SFTPGO_HTTPD__BINDINGS__0__OIDC__INSECURE_ISSUER_URL</code> to <code>1</code>.</li> <li>FTPD: implemented the STRU command to improve compatibility with legacy FTP clients.</li> <li>Shares: added audit logging for legal agreement acceptance.</li> </ul>"},{"location":"changelog/#bug-fixes_6","title":"Bug fixes","text":"<ul> <li>Storage sync plugin: fixed handling of unexpectedly interrupted sync operations to ensure proper recovery and consistency.</li> </ul>"},{"location":"changelog/#update-may-18-2025-v2720250518","title":"Update May 18, 2025 - v2.7.20250518","text":""},{"location":"changelog/#new-features_8","title":"New features","text":"<ul> <li>Cloud backends: Added support for the following new environment variables: <code>SFTPGO_HOOK__GCS_CHECK_PARENT_DIR</code>, <code>SFTPGO_HOOK__S3_CHECK_PARENT_DIR</code>, <code>SFTPGO_HOOK__AZBLOB_CHECK_PARENT_DIR</code>. When set to <code>1</code>, these variables prevent uploads to non-existent directories. Cloud backends do not use real directories, so uploading to non-existent paths typically works without errors.</li> <li>SFTPD: Added support for restricting insecure algorithms on a per-user basis. In the Advanced Settings section, you can enable the \"Enforce secure algorithms\" checkbox for each user or group. This will disable weak host keys, key exchange, MAC, and cipher algorithms that are enabled system-wide.</li> <li>WOPI: Added support for skipping specific file extensions.</li> <li>Plugins: Added storage sync.</li> <li>REST API can be disabled on a per-user basis.</li> </ul>"},{"location":"changelog/#bug-fixes_7","title":"Bug fixes","text":"<ul> <li>WebClient: Fixed an issue with recursive folder deletion.</li> <li>WebClient: Leading and trailing spaces are now allowed in user passwords, improving compatibility with certain external identity providers.</li> <li>WebClient: Fixed issue with incorrect behavior in multi-page selection.</li> </ul>"},{"location":"changelog/#update-april-22-2025-v2720250422","title":"Update April 22, 2025 - v2.7.20250422","text":""},{"location":"changelog/#new-features_9","title":"New features","text":"<ul> <li>EventManager: All placeholder names must now include a leading dot, changing from <code>{{PlaceholderName}}</code> to <code>{{.PlaceholderName}}</code>. For example, use <code>{{.VirtualPath}}</code> instead of <code>{{VirtualPath}}</code>. Existig actions are automatically migrated to the new format. When adding new actions, make sure to use the new format. This change is a preparation to improve flexibility in the future, allowing for features like conditions, loops, and other advanced options.</li> <li>EventManager: Added support for PGP encryption and decryption.</li> <li>HTTPD: Allowed to configure the <code>Referrer-Policy</code> header.</li> <li>SFTPD: Added support for Post-Quantum Traditional Hybrid Key Exchange through the newly added algorithm <code>mlkem768x25519-sha256</code>.</li> </ul> <p>Some notes about <code>mlkem768x25519-sha256</code>:</p> <ul> <li>Enabled by default: no configuration changes are needed. If both client and server support it, the hybrid KEX will be used automatically.</li> <li>Fully interoperable: clients that don't yet support post-quantum algorithms like <code>mlkem768x25519-sha256</code> will continue to work as expected using standard key exchange algorithms\u2014ensuring a smooth and backward-compatible experience.</li> </ul>"},{"location":"changelog/#bug-fixes_8","title":"Bug fixes","text":"<ul> <li>Respect the configured naming rules also for OpenID Connect authentication.</li> </ul>"},{"location":"changelog/#update-april-5-2025-v2720250405","title":"Update April 5, 2025 - v2.7.20250405","text":""},{"location":"changelog/#new-features_10","title":"New features","text":"<ul> <li>Azure Blob Storage Backend: General performance enhancements, including all the optimizations previously applied to S3 and Google Cloud storage.</li> <li>AES CTR Ciphers: Enhanced performance by 2x, with CTR mode now offering performance comparable to GCM mode.</li> <li>A legal agreement can be displayed before granting access to the share by external users. This feature can be enabled by setting the environment variable <code>SFTPGO_HOOK__HAS_SHARE_LEGAL_AGREEMENT</code> to <code>1</code>. The default legal agreement is located in the SFTPGo templates directory (<code>templates/webclient/sharelegal.html</code>). To customize it, you can specify a new template by setting the <code>SFTPGO_HOOK_SHARE_LEGAL_TMPL_PATH</code> environment variable to the path of the desired template. We recommend using the default template as a starting point.</li> <li>Web UIs: Added support for French and German localizations.</li> </ul> <p>Here is an example configuration to enable all the supported localizations using environment variables.</p> <pre><code>SFTPGO_HTTPD__BINDINGS__0__LANGUAGES=en,it,de,fr\n</code></pre>"},{"location":"changelog/#bug-fixes_9","title":"Bug fixes","text":"<ul> <li>Fixed issue with loading user data after an update from the pre-login hook. Previously, related fields such as virtual folders and groups were not refreshed, causing inconsistent user data.</li> <li>Enabled login via OpenID Connect even when password-based login is disabled.</li> <li>Fixed a security issue in an SFTPGo dependency; more details, including a CVE link, will be added once the security issue is made public.</li> </ul>"},{"location":"changelog/#update-march-27-2025-v2720250327","title":"Update March 27, 2025 - v2.7.20250327","text":""},{"location":"changelog/#new-features_11","title":"New features","text":"<ul> <li>SFTP storage backend: Added SOCKS5 proxy support.</li> <li>WebClient: Integrated the WOPI protocol, enabling the opening and editing of Office files through a compatible document server (e.g. Collabora Online, OnlyOffice)</li> </ul> <p>Here is an example configuration for the WOPI integration using environment variables.</p> <pre><code>SFTPGO_HTTPD__BINDINGS__0__WOPI__SERVER_URL=\"http://192.168.1.136\"\nSFTPGO_HTTPD__BINDINGS__0__WOPI__CALLBACK_URL=\"http://192.168.1.148:8080\"\nSFTPGO_HTTPD__BINDINGS__0__WOPI__SKIP_TLS_VERIFY=0\nSFTPGO_HTTPD__BINDINGS__0__WOPI__SKIP_PROOF_KEY_VERIFY=0\nSFTPGO_HTTPD__BINDINGS__0__WOPI__ALLOWED_FROM=192.168.1.0/24,192.168.2.25\n</code></pre> <p>The required configuration settings are the <code>server_url</code> and the <code>callback_url</code>, the other settings are optional. Additionally, you can configure the lifetime of WOPI access tokens (default is 360 minutes) by setting the environment variable <code>SFTPGO_HTTPD__WOPI_TOKEN_LIFETIME</code>. The value must be specified in minutes.</p> <ul> <li><code>server_url</code>, defines the base URL of your document server. The URL where your document server is reachable.</li> <li><code>callback_url</code>, defines the base URL that the document server uses to save your documents. This is the base URL where SFTPGo is reachable.</li> <li><code>skip_tls_verify</code>, skips TLS validation. Maybe be useful if your document server uses a self-signed certificate. Enabling this setting is not recommended.</li> <li><code>skip_proof_key_verify</code>, if your document server supports proof keys, SFTPGo will validate them to ensure that incoming WOPI requests are originating from your document server. Disabling this setting is not recommended.</li> <li><code>allowed_from</code>, allows to define IP addresses and ranges allowed to perform WOPI requests. This setting can be configured for servers not supporting proof keys or in addition to them.</li> </ul>"},{"location":"changelog/#bug-fixes_10","title":"Bug fixes","text":"<ul> <li>Public shares: Show the configured disclaimer on the login page.</li> <li>SMTP: Added support for servers that do not advertise the SMTP AUTH extension.</li> </ul>"},{"location":"changelog/#update-march-08-2025-v2720250308","title":"Update March 08, 2025 - v2.7.20250308","text":""},{"location":"changelog/#new-features_12","title":"New features","text":"<ul> <li>EventManager: date/time placeholders like <code>{{DateTime}}</code>, <code>{{Year}}</code>, <code>{{Month}}</code>, <code>{{Day}}</code>, <code>{{Hour}}</code>, <code>{{Minute}}</code> can now be used in actions started on schedule.</li> <li>EventManager: the <code>{{Email}}</code> placeholder now expands to multiple email addresses. For example, you can define multiple email addresses for a user - before this change, only the primary email address was taken into account.</li> <li>WebClient: External users can now authenticate to shared files and folders using their email address; each public share can be restricted to one or more specified email addresses, and when email authentication is enabled, users must enter their email and will receive a one-time authentication code via email to complete authentication.</li> </ul>"},{"location":"changelog/#bug-fixes_11","title":"Bug fixes","text":"<ul> <li>WebUI: the column visibility feature now hides the correct columns even after reordering table columns.</li> <li>WebUI: fixed context menu activation in user lists and other tables. In some edge cases the menu was not displayed because it was activated too early in the page rendering.</li> <li>WebUI: hidden some advanced settings like part size and concurrency for cloud storage backends. They are confusing for users and the values \u200b\u200bare closely related to instance resources, so now they are adjusted automatically.</li> </ul>"},{"location":"changelog/#other-additions-compared-to-the-open-source-edition","title":"Other additions compared to the Open Source edition","text":"<ul> <li>Performance improvements for the cloud storage backends, especially when uploading numerous small files.</li> <li>Downloads and uploads to cloud storage backends can be fully handled in memory by setting the environment variable <code>SFTPGO_HOOK__MEMORY_PIPES__ENABLED</code> to <code>1</code>. No unlinked files will be created, and therefore no local storage space will be used.</li> <li>Added new configuration parameters to specify the maximum number of transfers (downloads and uploads) allowed, both in total and per host. The Open Source edition only allows limiting total and per-host connections, not transfers. By default the maximum number of transfers allowed per host is 20.</li> <li>Added Trusted List. IP addresses or networks added to this list are always trusted, exempt from blocking by the Defender and Geo-IP filtering, and will never be subject to rate limiting.</li> </ul>"},{"location":"check-password-hook/","title":"Check password","text":""},{"location":"check-password-hook/#check-password-hook","title":"Check password hook","text":"<p>This hook allows you to externally check the provided password, its main use case is to allow to easily support things like password+OTP for protocols without keyboard interactive support such as FTP and WebDAV. You can ask your users to login using a string consisting of a fixed password and a One Time Token, you can verify the token inside the hook and ask to SFTPGo to verify the fixed part.</p> <p>The same thing can be achieved using External authentication but using this hook is simpler in some use cases.</p> <p>The <code>check password hook</code> can be defined as the absolute path of your program or an HTTP URL.</p> <p>The expected response is a JSON serialized struct containing the following keys:</p> <ul> <li><code>status</code> integer. 0 means KO, 1 means OK, 2 means partial success</li> <li><code>to_verify</code> string. For <code>status</code> = 2 SFTPGo will check this password against the one stored inside SFTPGo data provider</li> </ul> <p>If the hook defines an external program it can read the following environment variables:</p> <ul> <li><code>SFTPGO_AUTHD_USERNAME</code></li> <li><code>SFTPGO_AUTHD_PASSWORD</code></li> <li><code>SFTPGO_AUTHD_IP</code></li> <li><code>SFTPGO_AUTHD_PROTOCOL</code>, possible values are <code>SSH</code>, <code>FTP</code>, <code>DAV</code>, <code>HTTP</code></li> </ul> <p>Global environment variables are cleared, for security reasons, when the script is called. You can set additional environment variables in the \"command\" configuration section.</p> <p>The program must write, on its standard output, the expected JSON serialized response described above.</p> <p>If the hook is an HTTP URL then it will be invoked as HTTP POST. The request body will contain a JSON serialized struct with the following fields:</p> <ul> <li><code>username</code></li> <li><code>password</code></li> <li><code>ip</code></li> <li><code>protocol</code>, possible values are <code>SSH</code>, <code>FTP</code>, <code>DAV</code></li> </ul> <p>If authentication succeeds the HTTP response code must be 200 and the response body must contain the expected JSON serialized response described above.</p> <p>The program hook must finish within 30 seconds, the HTTP hook timeout will use the global configuration for HTTP clients.</p> <p>You can also restrict the hook scope using the <code>check_password_scope</code> configuration key:</p> <ul> <li><code>0</code> means all supported protocols.</li> <li><code>1</code> means SSH only</li> <li><code>2</code> means FTP only</li> <li><code>4</code> means WebDAV only</li> </ul> <p>You can combine the scopes. For example, 6 means FTP and WebDAV.</p> <p>You can disable the hook on a per-user basis.</p> <p>An example check password program allowing 2FA using password + one time token can be found inside the source tree checkpwd directory.</p>"},{"location":"cli/","title":"Command line options","text":""},{"location":"cli/#command-line-options","title":"Command line options","text":"<p>The SFTPGo executable can be used this way:</p> <pre><code>Usage:\n  sftpgo [command]\n\nAvailable Commands:\n  acme           Obtain TLS certificates from ACME-based CAs like Let's Encrypt\n  gen            A collection of useful generators\n  help           Help about any command\n  initprovider   Initialize and/or updates the configured data provider\n  ping           Issues an health check to SFTPGo\n  portable       Serve a single directory/account\n  resetprovider  Reset the configured provider, any data will be lost\n  resetpwd       Reset the password for the specified administrator\n  revertprovider Revert the configured data provider to a previous version\n  serve          Start the SFTPGo service\n  smtptest       Test the SMTP configuration\n\nFlags:\n  -h, --help      help for sftpgo\n  -v, --version\n\nUse \"sftpgo [command] --help\" for more information about a command.\n</code></pre>"},{"location":"cli/#starting-the-server","title":"Starting the server","text":"<p>To start the SFTPGo server you can use the <code>serve</code> command. It supports the following flags:</p> <ul> <li><code>--config-dir</code> string. Location of the config dir. This directory is used as the base for files with a relative path, e.g. the private keys for the SFTP server or the database file if you use a file-based data provider.. The configuration file, if not explicitly set, is looked for in this dir. We support reading from JSON, TOML, YAML, HCL, envfile and Java properties config files. The default config file name is <code>sftpgo</code> and therefore <code>sftpgo.json</code>, <code>sftpgo.yaml</code> and so on are searched. The default value is the working directory (\".\") or the value of <code>SFTPGO_CONFIG_DIR</code> environment variable.</li> <li><code>--config-file</code> string. This flag explicitly defines the path, name and extension of the config file. If must be an absolute path or a path relative to the configuration directory. The specified file name must have a supported extension (JSON, YAML, TOML, HCL or Java properties). The default value is empty or the value of <code>SFTPGO_CONFIG_FILE</code> environment variable.</li> <li><code>--grace-time</code>, integer. Graceful shutdown is an option to initiate a shutdown without abrupt cancellation of the currently ongoing client-initiated transfer sessions. This grace time defines the number of seconds allowed for existing transfers to get completed before shutting down. 0 means disabled. The default value is <code>0</code> or the value of <code>SFTPGO_GRACE_TIME</code> environment variable. A graceful shutdown is triggered by an interrupt signal or by a service <code>stop</code> request on Windows, if a grace time is configured.</li> <li><code>--loaddata-from</code> string. Load users and folders from this file. The file must be specified as absolute path and it must contain a backup obtained using the <code>dumpdata</code> REST API or compatible content. The default value is empty or the value of <code>SFTPGO_LOADDATA_FROM</code> environment variable.</li> <li><code>--loaddata-clean</code> boolean. Determine if the loaddata-from file should be removed after a successful load. Default <code>false</code> or the value of <code>SFTPGO_LOADDATA_CLEAN</code> environment variable (1 or <code>true</code>, 0 or <code>false</code>).</li> <li><code>--loaddata-mode</code>, integer. Restore mode for data to load. 0 means new users are added, existing users are updated. 1 means new users are added, existing users are not modified. Default 1 or the value of <code>SFTPGO_LOADDATA_MODE</code> environment variable.</li> <li><code>--loaddata-scan</code>, integer. Quota scan mode after data load. 0 means no quota scan. 1 means quota scan. 2 means scan quota if the user has quota restrictions. Default 0 or the value of <code>SFTPGO_LOADDATA_QUOTA_SCAN</code> environment variable.</li> <li><code>--log-compress</code> boolean. Determine if the rotated log files should be compressed using gzip. Default <code>false</code> or the value of <code>SFTPGO_LOG_COMPRESS</code> environment variable (1 or <code>true</code>, 0 or <code>false</code>). It is unused if <code>log-file-path</code> is empty.</li> <li><code>--log-file-path</code> string. Location for the log file, default \"sftpgo.log\" or the value of <code>SFTPGO_LOG_FILE_PATH</code> environment variable. Leave empty to write logs to the standard error.</li> <li><code>--log-max-age</code> int. Maximum number of days to retain old log files. Default 28 or the value of <code>SFTPGO_LOG_MAX_AGE</code> environment variable. It is unused if <code>log-file-path</code> is empty.</li> <li><code>--log-max-backups</code> int. Maximum number of old log files to retain. Default 5 or the value of <code>SFTPGO_LOG_MAX_BACKUPS</code> environment variable. It is unused if <code>log-file-path</code> is empty.</li> <li><code>--log-max-size</code> int. Maximum size in megabytes of the log file before it gets rotated. Default 10 or the value of <code>SFTPGO_LOG_MAX_SIZE</code> environment variable. It is unused if <code>log-file-path</code> is empty.</li> <li><code>--log-level</code> string. Set the log level. Supported values: <code>debug</code>, <code>info</code>, <code>warn</code>, <code>error</code>. Default <code>debug</code> or the value of <code>SFTPGO_LOG_LEVEL</code> environment variable.</li> <li><code>--log-utc-time</code> boolean. Enable UTC time for logging. Default <code>false</code> or the value of <code>SFTPGO_LOG_UTC_TIME</code> environment variable (1 or <code>true</code>, 0 or <code>false</code>)</li> </ul> <p>Log file can be rotated on demand sending a <code>SIGUSR1</code> signal on Unix based systems and using the command <code>sftpgo service rotatelogs</code> on Windows.</p>"},{"location":"cli/#portable-mode","title":"Portable mode","text":"<p>SFTPGo allows to share a single directory on demand using the <code>portable</code> command:</p> <pre><code>sftpgo portable --help\nTo serve the current working directory with auto generated credentials simply\nuse:\n\n$ sftpgo portable\n\nPlease take a look at the usage below to customize the serving parameters\n\nUsage:\n  sftpgo portable [flags]\n\nFlags:\n      --allowed-patterns stringArray    Allowed file patterns case insensitive.\n                                        The format is:\n                                        /dir::pattern1,pattern2.\n                                        For example: \"/somedir::*.jpg,a*b?.png\"\n      --az-access-tier string           Leave empty to use the default\n                                        container setting\n      --az-account-key string\n      --az-account-name string\n      --az-container string\n      --az-download-concurrency int     How many parts are downloaded in\n                                        parallel (default 5)\n      --az-download-part-size int       The buffer size for multipart downloads\n                                        (MB) (default 5)\n      --az-endpoint string              Leave empty to use the default:\n                                        \"blob.core.windows.net\"\n      --az-key-prefix string            Allows to restrict access to the\n                                        virtual folder identified by this\n                                        prefix and its contents\n      --az-sas-url string               Shared access signature URL\n      --az-upload-concurrency int       How many parts are uploaded in\n                                        parallel (default 5)\n      --az-upload-part-size int         The buffer size for multipart uploads\n                                        (MB) (default 5)\n      --az-use-emulator\n  -c, --config-dir string               Location of the config dir. This directory\n                                        is used as the base for files with a relative\n                                        path, e.g. the private keys for the SFTP\n                                        server or the database file if you use a\n                                        file-based data provider.\n                                        The configuration file, if not explicitly set,\n                                        is looked for in this dir. We support reading\n                                        from JSON, TOML, YAML, HCL, envfile and Java\n                                        properties config files. The default config\n                                        file name is \"sftpgo\" and therefore\n                                        \"sftpgo.json\", \"sftpgo.yaml\" and so on are\n                                        searched.\n                                        This flag can be set using SFTPGO_CONFIG_DIR\n                                        env var too. (default \".\")\n      --config-file string              Path to SFTPGo configuration file.\n                                        This flag explicitly defines the path, name\n                                        and extension of the config file. If must be\n                                        an absolute path or a path relative to the\n                                        configuration directory. The specified file\n                                        name must have a supported extension (JSON,\n                                        YAML, TOML, HCL or Java properties).\n                                        This flag can be set using SFTPGO_CONFIG_FILE\n                                        env var too.\n      --crypto-passphrase string        Passphrase for encryption/decryption\n      --denied-patterns stringArray     Denied file patterns case insensitive.\n                                        The format is:\n                                        /dir::pattern1,pattern2.\n                                        For example: \"/somedir::*.jpg,a*b?.png\"\n  -d, --directory string                Path to the directory to serve.\n                                        This can be an absolute path or a path\n                                        relative to the current directory\n                                         (default \".\")\n  -f, --fs-provider string              osfs =&gt; local filesystem (legacy value: 0)\n                                        s3fs =&gt; AWS S3 compatible (legacy: 1)\n                                        gcsfs =&gt; Google Cloud Storage (legacy: 2)\n                                        azblobfs =&gt; Azure Blob Storage (legacy: 3)\n                                        cryptfs =&gt; Encrypted local filesystem (legacy: 4)\n                                        sftpfs =&gt; SFTP (legacy: 5) (default \"osfs\")\n      --ftpd-cert string                Path to the certificate file for FTPS\n      --ftpd-key string                 Path to the key file for FTPS\n      --ftpd-port int                   0 means a random unprivileged port,\n                                        &lt; 0 disabled (default -1)\n      --gcs-automatic-credentials int   0 means explicit credentials using\n                                        a JSON credentials file, 1 automatic\n                                         (default 1)\n      --gcs-bucket string\n      --gcs-credentials-file string     Google Cloud Storage JSON credentials\n                                        file\n      --gcs-key-prefix string           Allows to restrict access to the\n                                        virtual folder identified by this\n                                        prefix and its contents\n      --gcs-storage-class string\n      --grace-time int                  This grace time defines the number of\n                                        seconds allowed for existing transfers\n                                        to get completed before shutting down.\n                                        A graceful shutdown is triggered by an\n                                        interrupt signal.\n\n  -h, --help                            help for portable\n      --httpd-cert string               Path to the certificate file for WebClient\n                                        over HTTPS\n      --httpd-key string                Path to the key file for WebClient over\n                                        HTTPS\n      --httpd-port int                  0 means a random unprivileged port,\n                                        &lt; 0 disabled (default -1)\n  -l, --log-file-path string            Leave empty to disable logging\n      --log-level string                Set the log level.\n                                        Supported values:\n\n                                        debug, info, warn, error.\n                                         (default \"debug\")\n      --log-utc-time                    Use UTC time for logging\n  -p, --password string                 Leave empty to use an auto generated\n                                        value\n      --password-file string            Read the password from the specified\n                                        file path. Leave empty to use an auto\n                                        generated value\n  -g, --permissions strings             User's permissions. \"*\" means any\n                                        permission (default [list,download])\n  -k, --public-key strings\n      --s3-access-key string\n      --s3-access-secret string\n      --s3-acl string\n      --s3-bucket string\n      --s3-endpoint string\n      --s3-force-path-style             Force path style bucket URL\n      --s3-key-prefix string            Allows to restrict access to the\n                                        virtual folder identified by this\n                                        prefix and its contents\n      --s3-region string\n      --s3-role-arn string\n      --s3-skip-tls-verify              If enabled the S3 client accepts any TLS\n                                        certificate presented by the server and\n                                        any host name in that certificate.\n                                        In this mode, TLS is susceptible to\n                                        man-in-the-middle attacks.\n                                        This should be used only for testing.\n\n      --s3-storage-class string\n      --s3-upload-concurrency int       How many parts are uploaded in\n                                        parallel (default 2)\n      --s3-upload-part-size int         The buffer size for multipart uploads\n                                        (MB) (default 5)\n      --sftp-buffer-size int            The size of the buffer (in MB) to use\n                                        for transfers. By enabling buffering,\n                                        the reads and writes, from/to the\n                                        remote SFTP server, are split in\n                                        multiple concurrent requests and this\n                                        allows data to be transferred at a\n                                        faster rate, over high latency networks,\n                                        by overlapping round-trip times\n      --sftp-disable-concurrent-reads   Concurrent reads are safe to use and\n                                        disabling them will degrade performance.\n                                        Disable for read once servers\n      --sftp-endpoint string            SFTP endpoint as host:port for SFTP\n                                        provider\n      --sftp-fingerprints strings       SFTP fingerprints to verify remote host\n                                        key for SFTP provider\n      --sftp-key-path string            SFTP private key path for SFTP provider\n      --sftp-password string            SFTP password for SFTP provider\n      --sftp-prefix string              SFTP prefix allows restrict all\n                                        operations to a given path within the\n                                        remote SFTP server\n      --sftp-username string            SFTP user for SFTP provider\n  -s, --sftpd-port int                  0 means a random unprivileged port,\n                                        &lt; 0 disabled\n      --ssh-commands strings            SSH commands to enable.\n                                        \"*\" means any supported SSH command\n                                        including scp\n                                         (default [md5sum,sha1sum,sha256sum,cd,pwd,scp])\n      --start-directory string          Alternate start directory.\n                                        This is a virtual path not a filesystem\n                                        path (default \"/\")\n  -u, --username string                 Leave empty to use an auto generated\n                                        value\n      --webdav-cert string              Path to the certificate file for WebDAV\n                                        over HTTPS\n      --webdav-key string               Path to the key file for WebDAV over\n                                        HTTPS\n      --webdav-port int                 0 means a random unprivileged port,\n                                        &lt; 0 disabled (default -1)\n</code></pre> <p>In portable mode you can apply further customizations using a configuration file/environment variables as for the service mode. SFTP, FTP, HTTP and WebDAV settings configured using the CLI flags are applied to the first binding, any additional bindings will not be affected.</p>"},{"location":"cli/#manage-windows-service","title":"Manage Windows Service","text":"<p>On Windows, you can register SFTPGo as Windows Service. Take a look at the CLI usage to learn how to do this:</p> <pre><code>PS&gt; sftpgo.exe service --help\nManage SFTPGo Windows Service\n\nUsage:\n  sftpgo service [command]\n\nAvailable Commands:\n  install     Install SFTPGo as Windows Service\n  reload      Reload the SFTPGo Windows Service sending a \"paramchange\" request\n  rotatelogs  Signal to the running service to rotate the logs\n  start       Start SFTPGo Windows Service\n  status      Retrieve the status for the SFTPGo Windows Service\n  stop        Stop SFTPGo Windows Service\n  uninstall   Uninstall SFTPGo Windows Service\n\nFlags:\n  -h, --help   help for service\n\nUse \"sftpgo service [command] --help\" for more information about a command.\n</code></pre> <p>The <code>install</code> subcommand accepts the same flags that are valid for <code>serve</code>.</p> <p>After installing as a Windows Service, please remember to allow network access to the SFTPGo executable using something like this:</p> <pre><code>PS&gt; netsh advfirewall firewall add rule name=\"SFTPGo Service\" dir=in action=allow program=\"C:\\Program Files\\SFTPGo\\sftpgo.exe\"\n</code></pre> <p>Or through the Windows Firewall GUI.</p> <p>The Windows installer will register the service and allow network access for it automatically.</p>"},{"location":"cli/#other-commands","title":"Other commands","text":"<p>For other commands run <code>sftpgo &lt;command&gt; --help</code> to understand the usage.</p>"},{"location":"config-file/","title":"Configuration file","text":""},{"location":"config-file/#configuration-file","title":"Configuration file","text":"<p>The default configuration file is <code>sftpgo.json</code> and is divided in several sections.</p>"},{"location":"config-file/#common","title":"Common","text":"<p>Supported configuration parameters for the <code>common</code> section:</p> <ul> <li><code>idle_timeout</code>, integer. Time in minutes after which an idle client will be disconnected. 0 means disabled. Default: 15</li> <li><code>upload_mode</code> integer. <code>0</code> means standard: the files are uploaded directly to the requested path. <code>1</code> means atomic: files are uploaded to a temporary path and renamed to the requested path when the client ends the upload. Atomic mode avoids problems such as a web server that serves partial files when the files are being uploaded. In atomic mode, if there is an upload error, the temporary file is deleted and so the requested upload path will not contain a partial file. <code>2</code> means atomic with resume support: same as atomic but if there is an upload error, the temporary file is renamed to the requested path and not deleted. This way, a client can reconnect and resume the upload. <code>4</code> means files for S3 backend are stored even if a client-side upload error is detected. <code>8</code> means files for Google Cloud Storage backend are stored even if a client-side upload error is detected. <code>16</code> means files for Azure Blob backend are stored even if a client-side upload error is detected. Ignored for SFTP backend if buffering is enabled. The flags can be combined, if you provide both <code>1</code> and <code>2</code>, <code>2</code> will be used. Default: <code>0</code></li> <li><code>actions</code>, struct. It contains the command to execute and/or the HTTP URL to notify and the trigger conditions. See Custom Actions for more details<ul> <li><code>execute_on</code>, list of strings. Valid values are <code>pre-download</code>, <code>download</code>, <code>first-download</code>, <code>pre-upload</code>, <code>upload</code>, <code>first-upload</code>, <code>pre-delete</code>, <code>delete</code>, <code>rename</code>, <code>mkdir</code>, <code>rmdir</code>, <code>ssh_cmd</code>, <code>copy</code>. Leave empty to disable actions.</li> <li><code>execute_sync</code>, list of strings. Actions, defined in the <code>execute_on</code> list above, to be performed synchronously. The <code>pre-*</code> actions are always executed synchronously while the other ones are asynchronous. Executing an action synchronously means that SFTPGo will not return a result code to the client (which is waiting for it) until your hook have completed its execution. Leave empty to execute only the defined <code>pre-*</code> hook synchronously</li> <li><code>hook</code>, string. Absolute path to the command to execute or HTTP URL to notify.</li> </ul> </li> <li><code>setstat_mode</code>, integer. 0 means \"normal mode\": requests for changing permissions, owner/group and access/modification times are executed. 1 means \"ignore mode\": requests for changing permissions, owner/group and access/modification times are silently ignored. 2 means \"ignore mode if not supported\": requests for changing permissions and owner/group are silently ignored for cloud filesystems and executed for local/SFTP filesystem.</li> <li><code>rename_mode</code>, integer. By default (<code>0</code>), renaming of non-empty directories is not allowed for cloud storage providers (S3, GCS, Azure Blob). Set to <code>1</code> to enable recursive renames for these providers, they may be slow, there is no atomic rename API like for local filesystem, so SFTPGo will recursively list the directory contents and do a rename for each entry (partial renaming and incorrect disk quota updates are possible in error cases). Default <code>0</code>.</li> <li><code>resume_max_size</code>, integer. defines the maximum size allowed, in bytes, to resume uploads on storage backends with immutable objects. By default, resuming uploads is not allowed for cloud storage providers (S3, GCS, Azure Blob) because SFTPGo must rewrite the entire file. Set to a value greater than 0 to allow resuming uploads of files smaller than or equal to the defined size. Please note that uploads for these backends are still atomic, the client must intentionally upload a portion of the target file and then resume uploading.. Default <code>0</code>.</li> <li><code>temp_path</code>, string. Defines the path for temporary files such as those used for atomic uploads or file pipes. If you set this option you must make sure that the defined path exists, is accessible for writing by the user running SFTPGo, and is on the same filesystem as the users home directories otherwise the renaming for atomic uploads will become a copy and therefore may take a long time. The temporary files are not namespaced. The default is generally fine. Leave empty for the default.</li> <li><code>proxy_protocol</code>, integer. Support for HAProxy PROXY protocol. If you are running SFTPGo behind a proxy server such as HAProxy, AWS ELB or NGINX, and your proxy is not able to preserve the IP address of clients, you can enable the proxy protocol. It provides a convenient way to safely transport connection information such as a client's address across multiple layers of NAT or TCP proxies to get the real client IP address instead of the proxy IP. Both protocol versions 1 and 2 are supported. If the proxy protocol is enabled in SFTPGo then you have to enable the protocol in your proxy configuration too. For example, for HAProxy, add <code>send-proxy</code> or <code>send-proxy-v2</code> to each server configuration line. The PROXY protocol is supported for SSH/SFTP and FTP/S. The following modes are supported:<ul> <li>0, disabled</li> <li>1, enabled. If the upstream IP is not allowed to send a proxy header, the header will be ignored. Using this mode does not mean that we can accept connections with and without the proxy header. We always try to read the proxy header and we ignore it if the upstream IP is not allowed to send a proxy header. Set <code>proxy_skipped</code> if you want to allow some IPs/networks to connect without sending a proxy header and without SFTPGo trying to read it</li> <li>2, required. If the upstream IP is not allowed to send a proxy header, the connection will be rejected if a proxy header is found. We always try to read the proxy header. Set <code>proxy_skipped</code> if you want to allow some IPs/networks to connect without sending a proxy header and without SFTPGo trying to read it</li> </ul> </li> <li><code>proxy_allowed</code>, list of IP addresses and IP ranges allowed to send the proxy header:<ul> <li>If <code>proxy_protocol</code> is set to 1 and we receive a proxy header from an IP that is not in the list then the connection will be accepted and the header will be ignored</li> <li>If <code>proxy_protocol</code> is set to 2 and we receive a proxy header from an IP that is not in the list then the connection will be rejected</li> </ul> </li> <li><code>proxy_skipped</code>, list of IP address and IP ranges for which not to read the proxy header</li> <li><code>startup_hook</code>, string. Absolute path to an external program or an HTTP URL to invoke as soon as SFTPGo starts. If you define an HTTP URL it will be invoked using a <code>GET</code> request. Please note that SFTPGo services may not yet be available when this hook is run. Leave empty do disable</li> <li><code>post_connect_hook</code>, string. Absolute path to the command to execute or HTTP URL to notify. See Post-connect hook for more details. Leave empty to disable</li> <li><code>post_disconnect_hook</code>, string. Absolute path to the command to execute or HTTP URL to notify. See Post-disconnect hook for more details. Leave empty to disable</li> <li><code>max_total_connections</code>, integer. Maximum number of concurrent client connections. 0 means unlimited. Default: <code>0</code>.</li> <li><code>max_per_host_connections</code>, integer.  Maximum number of concurrent client connections from the same host (IP). If the defender is enabled, exceeding this limit will generate <code>score_limit_exceeded</code> events and thus hosts that repeatedly exceed the max allowed connections can be automatically blocked. 0 means unlimited. Default: <code>20</code>.</li> <li><code>max_total_transfers</code>, integer. Maximum number of concurrent file transfers, upload and downloads. 0 means unlimited. Default: <code>0</code>.</li> <li><code>max_per_host_transfers</code>, integer. Maximum number of concurrent file transfers from the same host (IP). If the defender is enabled, exceeding this limit will generate <code>score_limit_exceeded</code> events and thus hosts that repeatedly exceed the max allowed connections can be automatically blocked. 0 means unlimited. Default: <code>20</code>.</li> <li><code>allowlist_status</code>, integer. Set to <code>1</code> to enable the allow list. The allow list can be populated using the WebAdmin or the REST API. If enabled, only the listed IPs/networks can access the configured services, all other client connections will be dropped before they even try to authenticate. Ensure to populate your allow list before enabling this setting. In multi-nodes setups, the list entries propagation between nodes may take some minutes. Default: <code>0</code>.</li> <li><code>allow_self_connections</code>, integer. Allow users on this instance to use other users/virtual folders on this instance as storage backend. Enable this setting if you know what you are doing. Set to <code>1</code> to enable. Default: <code>0</code>.</li> <li><code>umask</code>, string. Set the file mode creation mask, for example <code>002</code>. Leave blank to use the system umask. Supported on *NIX platforms. Default: blank.</li> <li><code>server_version</code>, string. Allow some degree of customization for the advertised software version. Set to <code>short</code> to hide the SFTPGo version number. If set to a non-empty, valid custom string (ASCII only, max 50 characters, no newlines), it will fully override the default banner, replacing both the application name and version. The commit hash may still be appended and when SFTPGo acts as a client for another service (e.g., S3), this value may be ignored depending on the context. Default: blank.</li> <li><code>tz</code>, string. Defines the time zone to use for the EventManager scheduler and to control time-based access restrictions. Set to <code>local</code> to use the server's local time, otherwise UTC will be used. Default: blank.</li> <li><code>metadata</code>, struct containing the configuration for managing the Cloud Storage backends metadata.<ul> <li><code>read</code>, integer. Set to <code>1</code> to read metadata before downloading files from Cloud Storage backends and making them available in notification events. Default: <code>0</code>.</li> </ul> </li> <li><code>defender</code>, struct containing the defender configuration. See Defender for more details.<ul> <li><code>enabled</code>, boolean. Default <code>false</code>.</li> <li><code>driver</code>, string. Supported drivers are <code>memory</code> and <code>provider</code>. The <code>provider</code> driver will use the configured data provider to store defender events and it is supported for <code>MySQL</code>, <code>PostgreSQL</code> and <code>CockroachDB</code> data providers. Using the <code>provider</code> driver you can share the defender events among multiple SFTPGO instances. For a single instance the <code>memory</code> driver will be much faster. Default: <code>memory</code>.</li> <li><code>ban_time</code>, integer. Ban time in minutes. Default: <code>30</code>.</li> <li><code>ban_time_increment</code>, integer. Ban time increment, as a percentage, if a banned host tries to connect again. Default: <code>50</code>.</li> <li><code>threshold</code>, integer. Threshold value for banning a client. Default: <code>15</code>.</li> <li><code>score_invalid</code>, integer. Score for invalid login attempts, eg. non-existent user accounts. Default: <code>2</code>.</li> <li><code>score_valid</code>, integer. Score for valid login attempts, eg. user accounts that exist. Default: <code>1</code>.</li> <li><code>score_limit_exceeded</code>, integer. Score for hosts that exceeded the configured rate limits or the maximum, per-host, allowed connections. Default: <code>3</code>.</li> <li><code>score_no_auth</code>, defines the score for clients disconnected without any authentication attempt. Default: <code>0</code>.</li> <li><code>observation_time</code>, integer. Defines the time window, in minutes, for tracking client errors. A host is banned if it has exceeded the defined threshold during the last observation time minutes. Default: <code>30</code>.</li> <li><code>entries_soft_limit</code>, integer. Ignored for <code>provider</code> driver. Default: <code>100</code>.</li> <li><code>entries_hard_limit</code>, integer. The number of banned IPs and host scores kept in memory will vary between the soft and hard limit for <code>memory</code> driver. If you use the <code>provider</code> driver, this setting will limit the number of entries to return when you ask for the entire host list from the defender. Default: <code>150</code>.</li> <li><code>login_delay</code>, struct containing the configuration to impose a delay between login attempts:<ul> <li><code>success</code>, integer. Defines the number of milliseconds to pause prior to allowing a successful login. <code>0</code> means disabled. Default: <code>0</code>.</li> <li><code>password_failed</code>, integer. Defines the number of milliseconds to pause prior to reporting a failed password/interactive login. <code>0</code> means disabled. Default: <code>1000</code>.</li> </ul> </li> </ul> </li> <li><code>rate_limiters</code>, list of structs containing the rate limiters configuration. More details. Each struct has the following fields:<ul> <li><code>average</code>, integer. Average defines the maximum rate allowed. 0 means disabled. Default: 0</li> <li><code>period</code>, integer. Period defines the period as milliseconds. The rate is actually defined by dividing average by period Default: 1000 (1 second).</li> <li><code>burst</code>, integer. Burst defines the maximum number of requests allowed to go through in the same arbitrarily small period of time. Default: 1</li> <li><code>type</code>, integer. 1 means a global rate limiter, independent from the source host. 2 means a per-ip rate limiter. Default: 2</li> <li><code>protocols</code>, list of strings. Available protocols are <code>SSH</code>, <code>FTP</code>, <code>DAV</code>, <code>HTTP</code>. By default all supported protocols are enabled</li> <li><code>generate_defender_events</code>, boolean. If <code>true</code>, the defender is enabled, and this is not a global rate limiter, a new defender event will be generated each time the configured limit is exceeded. Default <code>false</code></li> <li><code>entries_soft_limit</code>, integer.</li> <li><code>entries_hard_limit</code>, integer. The number of per-ip rate limiters kept in memory will vary between the soft and hard limit</li> </ul> </li> <li><code>event_manager</code>, struct containing the configuration for the EventManager<ul> <li><code>enabled_commands</code>, list of strings. Absolute path to system commands that can be executed through Event Manager. An empty list means that no commands are allowed to be executed.  Allowing system command could pose a security risk. Default: empty</li> </ul> </li> </ul>"},{"location":"config-file/#acme","title":"ACME","text":"<p>Automatic Certificate Management Environment (ACME) protocol configuration. To obtain the certificates the first time you have to configure the ACME protocol and execute the <code>sftpgo acme run</code> command or use the WebAdmin UI. The SFTPGo service will take care of the automatic renewal of certificates for the configured domains.</p> <p>Supported configuration parameters for the <code>acme</code> section:</p> <ul> <li><code>domains</code>, list of domains for which to obtain certificates. If a single certificate is to be valid for multiple domains specify the names separated by commas or spaces, for example: <code>example.com,www.example.com</code> or <code>example.com www.example.com</code>. An empty list means that ACME protocol is disabled. Default: empty.</li> <li><code>email</code>, string. Email used for registration and recovery contact. Default: empty.</li> <li><code>key_type</code>, string. Key type to use for private keys. Supported values: <code>2048</code> (RSA 2048), <code>3072</code> (RSA 3072), <code>4096</code> (RSA 4096), <code>8192</code> (RSA 8192), <code>P256</code> (EC 256), <code>P384</code> (EC 384). Default: <code>4096</code></li> <li><code>certs_path</code>, string. Directory, absolute or relative to the configuration directory, to use for storing certificates and related data.</li> <li><code>ca_endpoint</code>, string. Default: <code>https://acme-v02.api.letsencrypt.org/directory</code>.</li> <li><code>renew_days</code>, integer. The number of days left on a certificate to renew it. Default: <code>30</code>.</li> <li><code>http01_challenge</code>, configuration for <code>HTTP-01</code> challenge type, the following fields are supported:<ul> <li><code>port</code>, integer. This challenge is expected to run on port <code>80</code>. If you set a port other than <code>80</code> you have to proxy the path <code>/.well-known/acme-challenge</code> from the port <code>80</code> to the configured port. Default: <code>80</code>.</li> <li><code>proxy_header</code>, string. Validate against this HTTP header when solving HTTP based challenges behind a reverse proxy. Empty means <code>Host</code>. Default: empty.</li> <li><code>webroot</code>, string. Set the absolute path to the webroot folder to use for HTTP based challenges to write directly in a file in <code>.well-known/acme-challenge</code>. Setting a <code>webroot</code> disables the built-in server (the <code>port</code> setting is ignored) and expects the given directory to be publicly served, on port <code>80</code>, with access to <code>.well-known/acme-challenge</code>. If <code>webroot</code> is empty and <code>port</code> is <code>0</code> the <code>HTTP-01</code> challenge is disabled. Default: empty.</li> </ul> </li> <li><code>tls_alpn01_challenge</code>, configuration for <code>TLS-ALPN-01</code> challenge type, the following fields are supported:<ul> <li><code>port</code>, integer. This challenge is expected to run on port <code>443</code>. <code>0</code> means <code>TLS-ALPN-01</code> is disabled. Default: <code>0</code>.</li> </ul> </li> </ul>"},{"location":"config-file/#sshsftp-server","title":"SSH/SFTP server","text":"<p>Supported configuration parameters for the <code>sftpd</code> section:</p> <ul> <li><code>bindings</code>, list of structs. Each struct has the following fields:<ul> <li><code>port</code>, integer. The port used for serving SFTP requests. 0 means disabled. Default: 2022</li> <li><code>address</code>, string. Leave blank to listen on all available network interfaces. Default: \"\"</li> <li><code>apply_proxy_config</code>, boolean. If enabled the common proxy configuration, if any, will be applied. Default <code>true</code></li> </ul> </li> <li><code>max_auth_tries</code> integer. Maximum number of authentication attempts permitted per connection. If set to a negative number, the number of attempts is unlimited. If set to zero, the number of attempts is limited to 6.</li> <li><code>host_keys</code>, list of strings. It contains the daemon's private host keys. Each host key can be defined as a path relative to the configuration directory or an absolute one. If empty, the daemon will search or try to generate <code>id_rsa</code>, <code>id_ecdsa</code> and <code>id_ed25519</code> keys inside the configuration directory. If you configure absolute paths to files named <code>id_rsa</code>, <code>id_ecdsa</code> and/or <code>id_ed25519</code> then SFTPGo will try to generate these keys using the default settings.</li> <li><code>host_certificates</code>, list of strings. Public host certificates. Each certificate can be defined as a path relative to the configuration directory or an absolute one. Certificate's public key must match a private host key otherwise it will be silently ignored. Default: empty.</li> <li><code>host_key_algorithms</code>, list of strings. Public key algorithms that the server will accept for host key authentication. The supported values are: <code>rsa-sha2-512-cert-v01@openssh.com</code>, <code>rsa-sha2-256-cert-v01@openssh.com</code>, <code>ssh-rsa-cert-v01@openssh.com</code>, <code>ssh-dss-cert-v01@openssh.com</code>, <code>ecdsa-sha2-nistp256-cert-v01@openssh.com</code>, <code>ecdsa-sha2-nistp384-cert-v01@openssh.com</code>, <code>ecdsa-sha2-nistp521-cert-v01@openssh.com</code>, <code>ssh-ed25519-cert-v01@openssh.com</code>, <code>ecdsa-sha2-nistp256</code>, <code>ecdsa-sha2-nistp384</code>, <code>ecdsa-sha2-nistp521</code>, <code>rsa-sha2-512</code>, <code>rsa-sha2-256</code>, <code>ssh-rsa</code>, <code>ssh-dss</code>, <code>ssh-ed25519</code>. Certificate algorithms are listed for backward compatibility purposes only, they are not used. Default values: <code>rsa-sha2-512</code>, <code>rsa-sha2-256</code>, <code>ecdsa-sha2-nistp256</code>, <code>ecdsa-sha2-nistp384</code>, <code>ecdsa-sha2-nistp521</code>, <code>ssh-ed25519</code>.</li> <li><code>kex_algorithms</code>, list of strings. Available KEX (Key Exchange) algorithms in preference order. Leave empty to use default values. The supported values are: <code>mlkem768x25519-sha256</code>, <code>curve25519-sha256</code> (will also enable the alias <code>curve25519-sha256@libssh.org</code>), <code>ecdh-sha2-nistp256</code>, <code>ecdh-sha2-nistp384</code>, <code>ecdh-sha2-nistp521</code>, <code>diffie-hellman-group14-sha256</code>, <code>diffie-hellman-group16-sha512</code>, <code>diffie-hellman-group14-sha1</code>, <code>diffie-hellman-group1-sha1</code>, <code>diffie-hellman-group-exchange-sha256</code>, <code>diffie-hellman-group-exchange-sha1</code>. Default values: <code>mlkem768x25519-sha256</code>, <code>curve25519-sha256</code>, <code>ecdh-sha2-nistp256</code>, <code>ecdh-sha2-nistp384</code>, <code>ecdh-sha2-nistp521</code>, <code>diffie-hellman-group14-sha256</code>,  <code>diffie-hellman-group-exchange-sha256</code>. SHA512 based KEXs are disabled by default because they are slow.</li> <li><code>min_dh_group_exchange_key_size</code>, integer. Defines the minimum key size to allow for the key exchanges when using diffie-ellman-group-exchange-sha1 or sha256 key exchange algorithms. Allowed values: <code>2048</code>, <code>3072</code>. Default: <code>2048</code>.</li> <li><code>ciphers</code>, list of strings. Allowed ciphers in preference order. Leave empty to use default values. The supported values are: <code>aes128-gcm@openssh.com</code>, <code>aes256-gcm@openssh.com</code>, <code>chacha20-poly1305@openssh.com</code>, <code>aes128-ctr</code>, <code>aes192-ctr</code>, <code>aes256-ctr</code>, <code>aes128-cbc</code>, <code>aes192-cbc</code>, <code>aes256-cbc</code>, <code>3des-cbc</code>, <code>arcfour256</code>, <code>arcfour128</code>, <code>arcfour</code>. Default values: <code>aes128-gcm@openssh.com</code>, <code>aes256-gcm@openssh.com</code>, <code>chacha20-poly1305@openssh.com</code>, <code>aes128-ctr</code>, <code>aes192-ctr</code>, <code>aes256-ctr</code>. Please note that the ciphers disabled by default are insecure, you should expect that an active attacker can recover plaintext if you enable them.</li> <li><code>macs</code>, list of strings. Available MAC (message authentication code) algorithms in preference order. Leave empty to use default values. The supported values are: <code>hmac-sha2-256-etm@openssh.com</code>, <code>hmac-sha2-256</code>, <code>hmac-sha2-512-etm@openssh.com</code>, <code>hmac-sha2-512</code>, <code>hmac-sha1</code>, <code>hmac-sha1-96</code>. Default values: <code>hmac-sha2-256-etm@openssh.com</code>, <code>hmac-sha2-256</code>.</li> <li><code>public_key_algorithms</code>, list of strings. Public key algorithms that the server will accept for client authentication. The supported values are: <code>ecdsa-sha2-nistp256</code>, <code>ecdsa-sha2-nistp384</code>, <code>ecdsa-sha2-nistp521</code>, <code>rsa-sha2-512</code>, <code>rsa-sha2-256</code>, <code>ssh-rsa</code>, <code>ssh-dss</code>, <code>ssh-ed25519</code>, <code>sk-ssh-ed25519@openssh.com</code>, <code>sk-ecdsa-sha2-nistp256@openssh.com</code>. Default values: <code>ecdsa-sha2-nistp256</code>, <code>ecdsa-sha2-nistp384</code>, <code>ecdsa-sha2-nistp521</code>, <code>rsa-sha2-512</code>, <code>rsa-sha2-256</code>, <code>ssh-ed25519</code>, <code>sk-ssh-ed25519@openssh.com</code>, <code>sk-ecdsa-sha2-nistp256@openssh.com</code>.</li> <li><code>trusted_user_ca_keys</code>, list of public keys paths of certificate authorities that are trusted to sign user certificates for authentication. The paths can be absolute or relative to the configuration directory.</li> <li><code>revoked_user_certs_file</code>, path to a file containing the revoked user certificates. The path can be absolute or relative to the configuration directory. It must contain a JSON list with the public key fingerprints of the revoked certificates. Example content: <code>[\"SHA256:bsBRHC/xgiqBJdSuvSTNpJNLTISP/G356jNMCRYC5Es\",\"SHA256:119+8cL/HH+NLMawRsJx6CzPF1I3xC+jpM60bQHXGE8\"]</code>. The revocation list can be reloaded on demand sending a <code>SIGHUP</code> signal on Unix based systems and a <code>paramchange</code> request to the running service on Windows. Default: \"\".</li> <li><code>opkssh_path</code>, absolute path to the <code>opkssh</code> binary used for OpenPubkey SSH integration. SFTPGo is typically run under a dedicated user (for example, the <code>sftpgo</code> system user on Linux). Ensure that this user has the appropriate system-level permissions to access the <code>opkssh</code> binary and its associated configuration files. The <code>trusted_user_ca_keys</code> and <code>opkssh_path</code> settings are mutually exclusive. Default: \"\".</li> <li><code>opkssh_checksum</code>, expected SHA256 checksum of the <code>opkssh</code> binary. It is verified at application startup. Default: \"\".</li> <li><code>login_banner_file</code>, path to the login banner file. The contents of the specified file, if any, are sent to the remote user before authentication is allowed. It can be a path relative to the config dir or an absolute one. Leave empty to disable login banner.</li> <li><code>enabled_ssh_commands</code>, list of enabled SSH commands. <code>*</code> enables all supported commands. More information.</li> <li><code>keyboard_interactive_authentication</code>, boolean. This setting specifies whether keyboard interactive authentication is allowed. If no keyboard interactive hook or auth plugin is defined the default is to prompt for the user password and then the one time authentication code, if defined. Default: <code>true</code>.</li> <li><code>keyboard_interactive_auth_hook</code>, string. Absolute path to an external program or an HTTP URL to invoke for keyboard interactive authentication. See Keyboard Interactive Authentication for more details.</li> <li><code>password_authentication</code>, boolean. Set to false to disable password authentication. This setting will disable multi-step authentication method using public key + password too. It is useful for public key only configurations if you need to manage old clients that will not attempt to authenticate with public keys if the password login method is advertised. Default: <code>true</code>.</li> </ul>"},{"location":"config-file/#ftp-server","title":"FTP server","text":"<p>Supported configuration parameters for the <code>ftpd</code> section:</p> <ul> <li><code>bindings</code>, list of structs. Each struct has the following fields:<ul> <li><code>port</code>, integer. The port used for serving FTP requests. 0 means disabled. Default: 0.</li> <li><code>address</code>, string. Leave blank to listen on all available network interfaces. Default: \"\".</li> <li><code>apply_proxy_config</code>, boolean. If enabled the common proxy configuration, if any, will be applied. Please note that we expect the proxy header on control and data connections. Default <code>true</code>.</li> <li><code>tls_mode</code>, integer. 0 means accept both cleartext and encrypted sessions. 1 means TLS is required for both control and data connection. 2 means implicit TLS.Please check that a proper TLS config is in place if you set <code>tls_mode</code> is different from 0.</li> <li><code>tls_session_reuse</code>, integer. 0 means session reuse is not checked, clients may or may not reuse TLS sessions. 1 means TLS session reuse is required for explicit FTPS. Legacy reuse method based on session IDs is not supported, clients must use session tickets. Session reuse is not supported for implicit TLS. 2 means that session reuse is disabled (not recommended for security reasons).  Default: <code>0</code>.</li> <li><code>certificate_file</code>, string. Binding specific TLS certificate. This can be an absolute path or a path relative to the config dir.</li> <li><code>certificate_key_file</code>, string. Binding specific private key matching the above certificate. This can be an absolute path or a path relative to the config dir. If not set the global ones will be used, if any.</li> <li><code>min_tls_version</code>, integer. Defines the minimum version of TLS to be enabled. <code>12</code> means TLS 1.2 (and therefore TLS 1.2 and TLS 1.3 will be enabled),<code>13</code> means TLS 1.3, <code>10</code> means TLS 1.0, <code>11</code> means TLS 1.1. Default: <code>12</code>.</li> <li><code>force_passive_ip</code>, ip address. External IP address for passive connections. Leave empty to autodetect. If not empty, it must be a valid IPv4 address. Default: \"\".</li> <li><code>passive_ip_overrides</code>, list of struct that allows to return a different passive ip based on the client IP address. Each struct has the following fields:<ul> <li><code>networks</code>, list of strings. Each string must define a network in CIDR notation, for example 192.168.1.0/24.</li> <li><code>ip</code>, string. Passive IP to return if the client IP address belongs to the defined networks. Empty means autodetect.</li> </ul> </li> <li><code>passive_host</code>, string. Hostname for passive connections. This hostname will be resolved each time a passive connection is requested and this can, depending on the DNS configuration, take a noticeable amount of time. Enable this setting only if you have a dynamic IP address. Default: \"\".</li> <li><code>client_auth_type</code>, integer. Set to <code>1</code> to require a client certificate and verify it. Set to <code>2</code> to request a client certificate during the TLS handshake and verify it if given, in this mode the client is allowed not to send a certificate. At least one certification authority must be defined in order to verify client certificates. If no certification authority is defined, this setting is ignored. Default: 0.</li> <li><code>tls_cipher_suites</code>, list of strings. List of supported cipher suites for TLS version 1.2 and below. If empty, a default list of secure cipher suites is used, with a preference order based on hardware performance. Note that TLS 1.3 ciphersuites are not configurable. Supported ciphersuites names. Any invalid name will be silently ignored. The order matters, the ciphers listed first will be the preferred ones. Default: empty.</li> <li><code>passive_connections_security</code>, integer. Defines the security checks for passive data connections. Set to <code>0</code> to require matching peer IP addresses of control and data connection. Set to <code>1</code> to disable any checks. Please note that if you run the FTP service behind a proxy you must enable the proxy protocol for control and data connections. Default: <code>0</code>.</li> <li><code>active_connections_security</code>, integer. Defines the security checks for active data connections. The supported values are the same as described for <code>passive_connections_security</code>. Please note that disabling the security checks you will make the FTP service vulnerable to bounce attacks on active data connections, so change the default value only if you are on a trusted/internal network. Default: <code>0</code>.</li> <li><code>ignore_ascii_transfer_type</code>, integer. Set to <code>1</code> to silently ignore any client requests to perform ASCII translations via the <code>TYPE</code> command. useful in circumstances involving older/mainframe clients and EBCDIC files. This behavior can be Default: <code>0</code>.</li> <li><code>debug</code>, boolean. If enabled any FTP command will be logged. This will generate a lot of logs. Enable only if you are investigating a client compatibility issue or something similar. You shouldn't leave this setting enabled for production servers. Default <code>false</code>.</li> </ul> </li> <li><code>banner_file</code>, path to the banner file. The contents of the specified file, if any, are displayed when someone connects to the server. It can be a path relative to the config dir or an absolute one. Leave empty to disable.</li> <li><code>active_transfers_port_non_20</code>, boolean. Do not impose the port 20 for active data transfers. Enabling this option allows to run SFTPGo with less privilege. Default: <code>true</code>.</li> <li><code>passive_port_range</code>, struct containing the key <code>start</code> and <code>end</code>. Port Range for data connections. Random if not specified. Default range is 50000-50100.</li> <li><code>disable_active_mode</code>, boolean. Set to <code>true</code> to disable active FTP, default <code>false</code>.</li> <li><code>enable_site</code>, boolean. Set to true to enable the FTP SITE command. We support <code>chmod</code> and <code>symlink</code> if SITE support is enabled. Default <code>false</code></li> <li><code>hash_support</code>, integer. Set to <code>1</code> to enable FTP commands that allow to calculate the hash value of files. These FTP commands will be enabled: <code>HASH</code>, <code>XCRC</code>, <code>MD5/XMD5</code>, <code>XSHA/XSHA1</code>, <code>XSHA256</code>, <code>XSHA512</code>. Please keep in mind that to calculate the hash we need to read the whole file, for remote backends this means downloading the file, for the encrypted backend this means decrypting the file. Default <code>0</code>.</li> <li><code>combine_support</code>, integer. Set to 1 to enable support for the non standard <code>COMB</code> FTP command. Combine is only supported for local filesystem, for cloud backends it has no advantage as it will download the partial files and will upload the combined one. Cloud backends natively support multipart uploads. Default <code>0</code>.</li> <li><code>certificate_file</code>, string. Certificate for FTPS. This can be an absolute path or a path relative to the config dir.</li> <li><code>certificate_key_file</code>, string. Private key matching the above certificate. This can be an absolute path or a path relative to the config dir. A certificate and the private key are required to enable explicit and implicit TLS. Certificate and key files can be reloaded on demand sending a <code>SIGHUP</code> signal on Unix based systems and a <code>paramchange</code> request to the running service on Windows. The certificates are also polled for changes every 8 hours.</li> <li><code>ca_certificates</code>, list of strings. Set of root certificate authorities to be used to verify client certificates.</li> <li><code>ca_revocation_lists</code>, list of strings. Set a revocation lists, one for each root CA, to be used to check if a client certificate has been revoked. The revocation lists can be reloaded on demand sending a <code>SIGHUP</code> signal on Unix based systems and a <code>paramchange</code> request to the running service on Windows.</li> </ul>"},{"location":"config-file/#webdav-server","title":"WebDAV Server","text":"<p>Supported configuration parameters for the <code>webdavd</code> section:</p> <ul> <li><code>bindings</code>, list of structs. Each struct has the following fields:<ul> <li><code>port</code>, integer. The port used for serving WebDAV requests. 0 means disabled. Default: 0.</li> <li><code>address</code>, string. Leave blank to listen on all available network interfaces. Default: \"\".</li> <li><code>enable_https</code>, boolean. Set to <code>true</code> and provide both a certificate and a key file to enable HTTPS connection for this binding. Default <code>false</code>.</li> <li><code>certificate_file</code>, string. Binding specific TLS certificate. This can be an absolute path or a path relative to the config dir.</li> <li><code>certificate_key_file</code>, string. Binding specific private key matching the above certificate. This can be an absolute path or a path relative to the config dir. If not set the global ones will be used, if any.</li> <li><code>min_tls_version</code>, integer. Defines the minimum version of TLS to be enabled. <code>12</code> means TLS 1.2 (and therefore TLS 1.2 and TLS 1.3 will be enabled),<code>13</code> means TLS 1.3, <code>10</code> means TLS 1.0, <code>11</code> means TLS 1.1. Default: <code>12</code>.</li> <li><code>client_auth_type</code>, integer. Set to <code>1</code> to require a client certificate and verify it. Set to <code>2</code> to request a client certificate during the TLS handshake and verify it if given, in this mode the client is allowed not to send a certificate. At least one certification authority must be defined in order to verify client certificates. If no certification authority is defined, this setting is ignored. Default: 0.</li> <li><code>tls_cipher_suites</code>, list of strings. List of supported cipher suites for TLS version 1.2 and below. If empty, a default list of secure cipher suites is used, with a preference order based on hardware performance. Note that TLS 1.3 ciphersuites are not configurable. Supported ciphersuites names. Any invalid name will be silently ignored. The order matters, the ciphers listed first will be the preferred ones. Default: empty.</li> <li><code>tls_protocols</code>, list of string. HTTPS protocols in preference order. Supported values: <code>http/1.1</code>, <code>h2</code>. Default: <code>http/1.1</code>, <code>h2</code>.</li> <li><code>prefix</code>, string. Prefix for WebDAV resources, if empty WebDAV resources will be available at the <code>/</code> URI. If defined it must be an absolute URI, for example <code>/dav</code>. Default: \"\".</li> <li><code>proxy_mode</code>, integer. Set to <code>1</code> to use the proxy protocol configuration defined within the <code>common</code> section instead of the proxy header configuration. Default: <code>0</code>.</li> <li><code>proxy_allowed</code>, list of IP addresses and IP ranges allowed to set client IP proxy header such as <code>X-Forwarded-For</code>. Any client IP proxy headers, if set on requests from a connection address not in this list, will be silently ignored. Default: empty.</li> <li><code>client_ip_proxy_header</code>, string. Defines the allowed client IP proxy header such as <code>X-Forwarded-For</code>, <code>X-Real-IP</code> etc. Default: empty</li> <li><code>client_ip_header_depth</code>, integer. Some client IP headers such as <code>X-Forwarded-For</code> can contain multiple IP address, this setting define the position to trust starting from the right. For example if we have: <code>10.0.0.1,11.0.0.1,12.0.0.1,13.0.0.1</code> and the depth is <code>0</code>, SFTPGo will use <code>13.0.0.1</code> as client IP, if depth is <code>1</code>, <code>12.0.0.1</code> will be used and so on. Set to <code>-1</code> to trust the leftmost IP address: this may have security implications and should only be used if your proxy has appropriate security controls in place to prevent spoofed IP headers. Default: <code>0</code>.</li> <li><code>disable_www_auth_header</code>, boolean. Set to <code>true</code> to not add the WWW-Authenticate header after an authentication failure, only the <code>401</code> status code will be sent. Default: <code>false</code>.</li> </ul> </li> <li><code>certificate_file</code>, string. Certificate for WebDAV over HTTPS. This can be an absolute path or a path relative to the config dir.</li> <li><code>certificate_key_file</code>, string. Private key matching the above certificate. This can be an absolute path or a path relative to the config dir. A certificate and a private key are required to enable HTTPS connections. Certificate and key files can be reloaded on demand sending a <code>SIGHUP</code> signal on Unix based systems and a <code>paramchange</code> request to the running service on Windows.</li> <li><code>ca_certificates</code>, list of strings. Set of root certificate authorities to be used to verify client certificates.</li> <li><code>ca_revocation_lists</code>, list of strings. Set a revocation lists, one for each root CA, to be used to check if a client certificate has been revoked. The revocation lists can be reloaded on demand sending a <code>SIGHUP</code> signal on Unix based systems and a <code>paramchange</code> request to the running service on Windows. The certificates are also polled for changes every 8 hours.</li> <li><code>cors</code> struct containing CORS configuration. SFTPGo uses Go CORS handler, please refer to upstream documentation for fields meaning and their default values.<ul> <li><code>enabled</code>, boolean, set to true to enable CORS.</li> <li><code>allowed_origins</code>, list of strings.</li> <li><code>allowed_methods</code>, list of strings.</li> <li><code>allowed_headers</code>, list of strings.</li> <li><code>exposed_headers</code>, list of strings.</li> <li><code>allow_credentials</code> boolean.</li> <li><code>max_age</code>, integer.</li> <li><code>options_passthrough</code>, boolean.</li> <li><code>options_success_status</code>, integer.</li> <li><code>allow_private_network</code>, boolean.</li> </ul> </li> <li><code>cache</code> struct containing cache configurations.<ul> <li><code>users</code>, cache configuration for the authenticated users.<ul> <li><code>expiration_time</code>, integer. Expiration time, in minutes, for the cached users. 0 means unlimited. Default: 0.</li> <li><code>max_size</code>, integer. Maximum number of users to cache. 0 means unlimited. Default: 50.</li> </ul> </li> <li><code>mime_types</code>, cache configuration for mime types.<ul> <li><code>enabled</code>, boolean, set to true to enable mime types caching. Default: <code>true</code>.</li> <li><code>max_size</code>, integer. Maximum number of mime types to cache. 0 means no cache. Default: 1000.</li> <li><code>custom_mappings</code>, additional mime types mapping. This is a platform independet way to add few additional mappings. You can set a limited number of mappings here, if you want to add a large list use the method provided by the OS of your choice. List of struct, each struct has the following fields:<ul> <li><code>ext</code>, string, file extension including the dot, for example <code>.json</code></li> <li><code>mime</code>, string, mime type, for example <code>application/json</code></li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"config-file/#data-provider","title":"Data provider","text":"<p>Supported configuration parameters for the <code>data_provider</code> section:</p> <ul> <li><code>driver</code>, string. Supported drivers are <code>sqlite</code>, <code>mysql</code>, <code>postgresql</code>, <code>cockroachdb</code>, <code>bolt</code>, <code>memory</code></li> <li><code>name</code>, string. Database name. For driver <code>sqlite</code> this can be the database name relative to the config dir or the absolute path to the SQLite database. For driver <code>memory</code> this is the (optional) path relative to the config dir or the absolute path to the provider dump, obtained using the <code>dumpdata</code> REST API, to load. This dump will be loaded at startup and can be reloaded on demand sending a <code>SIGHUP</code> signal on Unix based systems and a <code>paramchange</code> request to the running service on Windows. The <code>memory</code> provider will not modify the provided file so quota usage and last login will not be persisted. If you plan to use a SQLite database over a <code>cifs</code> network share (this is not recommended in general) you must use the <code>nobrl</code> mount option otherwise you will get the <code>database is locked</code> error. Some users reported that the <code>bolt</code> provider works fine over <code>cifs</code> shares.</li> <li><code>host</code>, string. Database host. For <code>postgresql</code> and <code>cockroachdb</code> drivers you can specify multiple hosts separated by commas. Leave empty for drivers <code>sqlite</code>, <code>bolt</code> and <code>memory</code></li> <li><code>port</code>, integer. Database port. Leave empty for drivers <code>sqlite</code>, <code>bolt</code> and <code>memory</code></li> <li><code>username</code>, string. Database user. Leave empty for drivers <code>sqlite</code>, <code>bolt</code> and <code>memory</code></li> <li><code>password</code>, string. Database password. Leave empty for drivers <code>sqlite</code>, <code>bolt</code> and <code>memory</code></li> <li><code>sslmode</code>, integer. Used for drivers <code>mysql</code> and <code>postgresql</code>. 0 disable TLS connections, 1 require TLS, 2 set TLS mode to <code>verify-ca</code> for driver <code>postgresql</code> and <code>skip-verify</code> for driver <code>mysql</code>, 3 set TLS mode to <code>verify-full</code> for driver <code>postgresql</code> and <code>preferred</code> for driver <code>mysql</code>, 4 set the TLS mode to <code>prefer</code> for driver <code>postgresql</code>, 5 set the TLS mode to <code>allow</code> for driver <code>postgresql</code></li> <li><code>root_cert</code>, string. Path to the root certificate authority used to verify that the server certificate was signed by a trusted CA</li> <li><code>disable_sni</code>, boolean. Allows to opt out Server Name Indication (SNI) for TLS connections. Default: <code>false</code></li> <li><code>target_session_attrs</code>, string. This is a <code>postgresql</code> and <code>cockroachdb</code> specific option. It determines whether the session must have certain properties to be acceptable. It's typically used in combination with multiple host names to select the first acceptable alternative among several hosts. Supported values: <code>any</code>, <code>read-write</code>, <code>read-only</code>, <code>primary</code>, <code>standby</code>, <code>prefer-standby</code>. If empty, <code>any</code> is assumed. If you explicitly set <code>any</code> the connections will be randomly distributed among the specified hosts</li> <li><code>client_cert</code>, string. Path to the client certificate for two-way TLS authentication</li> <li><code>client_key</code>,string. Path to the client key for two-way TLS authentication</li> <li><code>connection_string</code>, string. Provide a custom database connection string. If not empty, this connection string will be used instead of building one using the previous parameters. Leave empty for drivers <code>bolt</code> and <code>memory</code></li> <li><code>sql_tables_prefix</code>, string. Prefix for SQL tables</li> <li><code>track_quota</code>, integer. Set the preferred mode to track users quota between the following choices:<ul> <li>0, disable quota tracking. REST API to scan users home directories/virtual folders and update quota will do nothing</li> <li>1, quota is updated each time a user uploads or deletes a file, even if the user has no quota restrictions</li> <li>2, quota is updated each time a user uploads or deletes a file, but only for users with quota restrictions and for virtual folders. With this configuration, the <code>quota scan</code> and <code>folder_quota_scan</code> REST API can still be used to periodically update space usage for users without quota restrictions and for folders</li> </ul> </li> <li><code>delayed_quota_update</code>, integer. This configuration parameter defines the number of seconds to accumulate quota updates. If there are a lot of close uploads, accumulating quota updates can save you many queries to the data provider. If you want to track quotas, a scheduled quota update is recommended in any case, the stored quota may be incorrect for several reasons, such as an unexpected shutdown while uploading files, temporary provider failures, files copied outside of SFTPGo, and so on. You can use the eventmanager to schedule a periodic quota update. 0 means immediate quota update.</li> <li><code>pool_size</code>, integer. Sets the maximum number of open connections for <code>mysql</code> and <code>postgresql</code> driver. Default 0 (unlimited)</li> <li><code>users_base_dir</code>, string. Users default base directory. If no home dir is defined while adding a new user, and this value is a valid absolute path, then the user home dir will be automatically defined as the path obtained joining the base dir and the username</li> <li><code>actions</code>, struct. It contains the command to execute and/or the HTTP URL to notify and the trigger conditions. See Custom Actions for more details<ul> <li><code>execute_on</code>, list of strings. Valid values are <code>add</code>, <code>update</code>, <code>delete</code>. <code>update</code> action will not be fired for internal updates such as the last login or the user quota fields.</li> <li><code>execute_for</code>, list of strings. Defines the provider objects that trigger the action. Valid values are <code>user</code>, <code>folder</code>, <code>group</code>, <code>admin</code>, <code>api_key</code>, <code>share</code>, <code>event_action</code>, <code>event_rule</code>.</li> <li><code>hook</code>, string. Absolute path to the command to execute or HTTP URL to notify.</li> </ul> </li> <li><code>external_auth_hook</code>, string. Absolute path to an external program or an HTTP URL to invoke for users authentication. See External Authentication for more details. Leave empty to disable.</li> <li><code>external_auth_scope</code>, integer. 0 means all supported authentication scopes (passwords, public keys and keyboard interactive). 1 means passwords only. 2 means public keys only. 4 means key keyboard interactive only. 8 means TLS certificate. The flags can be combined, for example 6 means public keys and keyboard interactive</li> <li><code>credentials_path</code>, string. It defines the directory for storing user provided credential files such as Google Cloud Storage credentials. This can be an absolute path or a path relative to the config dir</li> <li><code>pre_login_hook</code>, string. Absolute path to an external program or an HTTP URL to invoke to modify user details just before the login. See Dynamic user modification for more details. Leave empty to disable.</li> <li><code>post_login_hook</code>, string. Absolute path to an external program or an HTTP URL to invoke to notify a successful or failed login. See Post-login hook for more details. Leave empty to disable.</li> <li><code>post_login_scope</code>, defines the scope for the post-login hook. 0 means notify both failed and successful logins. 1 means notify failed logins. 2 means notify successful logins.</li> <li><code>check_password_hook</code>, string.  Absolute path to an external program or an HTTP URL to invoke to check the user provided password. See Check password hook for more details. Leave empty to disable.</li> <li><code>check_password_scope</code>, defines the scope for the check password hook. 0 means all protocols, 1 means SSH, 2 means FTP, 4 means WebDAV. You can combine the scopes, for example 6 means FTP and WebDAV.</li> <li><code>password_hashing</code>, struct. It contains the configuration parameters to be used to generate the password hash. SFTPGo can verify passwords in several formats and uses, by default, the <code>bcrypt</code> algorithm to hash passwords in plain-text before storing them inside the data provider. These options allow you to customize how the hash is generated.<ul> <li><code>argon2_options</code>, struct containing the options for argon2id hashing algorithm. The <code>memory</code> and <code>iterations</code> parameters control the computational cost of hashing the password. The higher these figures are, the greater the cost of generating the hash and the longer the runtime. It also follows that the greater the cost will be for any attacker trying to guess the password. If the code is running on a machine with multiple cores, then you can decrease the runtime without reducing the cost by increasing the <code>parallelism</code> parameter. This controls the number of threads that the work is spread across.<ul> <li><code>memory</code>, unsigned integer. The amount of memory used by the algorithm (in kibibytes). Default: 65536.</li> <li><code>iterations</code>, unsigned integer. The number of iterations over the memory. Default: 1.</li> <li><code>parallelism</code>. unsigned 8 bit integer. The number of threads (or lanes) used by the algorithm. Default: 2.</li> </ul> </li> <li><code>bcrypt_options</code>, struct containing the options for bcrypt hashing algorithm<ul> <li><code>cost</code>, integer between 4 and 31. Default: 10</li> </ul> </li> <li><code>algo</code>, string. Algorithm to use for hashing passwords. Available algorithms: <code>argon2id</code>, <code>bcrypt</code>. For bcrypt hashing we use the <code>$2a$</code> prefix. Default: <code>bcrypt</code></li> </ul> </li> <li><code>password_validation</code> struct. It defines the password validation rules for admins and protocol users. Prefer the entropy based approach to the static rules as it evaluates the overall cryptographic strength of passwords and provides stronger security.<ul> <li><code>admins</code>, struct. It defines the password validation rules for SFTPGo admins.<ul> <li><code>min_entropy</code>, float. Defines the minimum password entropy. More details. <code>0</code> means disabled, any password will be accepted. Default: <code>0</code>.</li> <li><code>length</code>, integer. Defines the minimum password length. Default: <code>0</code>.</li> <li><code>uppers</code>, integer. Defines the minimum number of uppercase characters. Default: <code>0</code>.</li> <li><code>lowers</code>, integer. Defines the minimum number of lowercase characters. Default: <code>0</code>.</li> <li><code>digits</code>, integer. Defines the minimum number of digits. Default: <code>0</code>.</li> <li><code>specials</code>, integer. Defines the minimum number of special characters. Default: <code>0</code>.</li> </ul> </li> <li><code>users</code>, struct. It defines the password validation rules for SFTPGo protocol users.<ul> <li><code>min_entropy</code>, float. This value is used as fallback if no more specific password strength is set at user/group level. Default: <code>0</code>.</li> <li><code>length</code>, integer. Defines the minimum password length. Default: <code>0</code>.</li> <li><code>uppers</code>, integer. Defines the minimum number of uppercase characters. Default: <code>0</code>.</li> <li><code>lowers</code>, integer. Defines the minimum number of lowercase characters. Default: <code>0</code>.</li> <li><code>digits</code>, integer. Defines the minimum number of digits. Default: <code>0</code>.</li> <li><code>specials</code>, integer. Defines the minimum number of special characters. Default: <code>0</code>.</li> </ul> </li> </ul> </li> <li><code>password_caching</code>, boolean. Verifying argon2id passwords has a high memory and computational cost, verifying bcrypt passwords has a high computational cost, by enabling, in memory, password caching you reduce these costs. Default: <code>true</code></li> <li><code>update_mode</code>, integer. Defines how the database will be initialized/updated. 0 means automatically. 1 means manually using the initprovider sub-command.</li> <li><code>create_default_admin</code>, boolean. Before you can use SFTPGo you need to create an admin account. If you open the admin web UI, a setup screen will guide you in creating the first admin account. You can automatically create the first admin account by enabling this setting and setting the environment variables <code>SFTPGO_DEFAULT_ADMIN_USERNAME</code> and <code>SFTPGO_DEFAULT_ADMIN_PASSWORD</code>. You can also create the first admin by loading initial data. This setting has no effect if an admin account is already found within the data provider. Default <code>false</code>.</li> <li><code>naming_rules</code>, integer. Naming rules for usernames, folder, group, role and object names in general. <code>0</code> means no rules. <code>1</code> means you can use any UTF-8 character. The names are used in URIs for REST API and Web admin. If not set only unreserved URI characters are allowed: ALPHA / DIGIT / \"-\" / \".\" / \"_\" / \"~\". <code>2</code> means names are converted to lowercase before saving/matching and so case insensitive matching is possible. <code>4</code> means trimming trailing and leading white spaces before saving/matching, the WebAdmin needs this setting to work properly. Rules can be combined, for example <code>3</code> means both converting to lowercase and allowing any UTF-8 character. Enabling these options for existing installations could be backward incompatible, some users could be unable to login, for example existing users with mixed cases in their usernames. You have to ensure that all existing users respect the defined rules. Control characters, <code>/</code>, and <code>\\</code> are not permitted regardless of the naming rules. Default: <code>5</code>.</li> <li><code>is_shared</code>, integer. If the data provider is shared across multiple SFTPGo instances, set this parameter to <code>1</code>. <code>MySQL</code>, <code>PostgreSQL</code> and <code>CockroachDB</code> can be shared, this setting is ignored for other data providers. For shared data providers, active transfers are persisted in the database and thus quota checks between ongoing transfers will work cross multiple instances. Password reset requests and OIDC tokens/states are also persisted in the database if the provider is shared. For shared data providers, scheduled event actions are only executed on a single SFTPGo instance by default, you can override this behavior on a per-action basis. The database table <code>shared_sessions</code> is used only to store temporary sessions. In performance critical installations, you might consider using a database-specific optimization, for example you might use an <code>UNLOGGED</code> table for PostgreSQL. This optimization in only required in very limited use cases. Default: <code>0</code>.</li> <li><code>node</code>, struct. Node-specific configurations to allow inter-node communications. If your provider is shared across multiple nodes, the nodes can exchange information to present a uniform view for node-specific data. The current implementation allows to obtain active connections from all nodes. Nodes connect to each other using the REST API.<ul> <li><code>host</code>, string. IP address or hostname that other nodes can use to connect to this node via REST API. Empty means inter-node communications disabled. Default: empty.</li> <li><code>port</code>, integer. The port that other nodes can use to connect to this node via REST API. Default: <code>0</code></li> <li><code>proto</code>, string. Supported values <code>http</code> or <code>https</code>. For <code>https</code> the configurations for http clients is used, so you can, for example, enable mutual TLS authentication. Default: <code>http</code></li> </ul> </li> <li><code>backups_path</code>, string. Path to the backup directory. This can be an absolute path or a path relative to the config dir. We don't allow backups in arbitrary paths for security reasons.</li> </ul>"},{"location":"config-file/#http-server","title":"HTTP server","text":"<p>Supported configuration parameters for the <code>httpd</code> section (REST API, WebAdmin, WebClient):</p> <ul> <li><code>bindings</code>, list of structs. Each struct has the following fields:<ul> <li><code>port</code>, integer. The port used for serving HTTP requests. Default: 8080.</li> <li><code>address</code>, string. Leave blank to listen on all available network interfaces. On *NIX you can specify an absolute path to listen on a Unix-domain socket Default: blank.</li> <li><code>enable_web_admin</code>, boolean. Set to <code>false</code> to disable the built-in web admin for this binding. You also need to define <code>templates_path</code> and <code>static_files_path</code> to use the built-in web admin interface. Default <code>true</code>.</li> <li><code>enable_web_client</code>, boolean. Set to <code>false</code> to disable the built-in web client for this binding. You also need to define <code>templates_path</code> and <code>static_files_path</code> to use the built-in web client interface. Default <code>true</code>.</li> <li><code>enable_rest_api</code>, boolean. Set to <code>false</code> to disable REST API. Default <code>true</code>.</li> <li><code>enabled_login_methods</code>, integer. Defines the login methods available for the WebAdmin and WebClient UIs. <code>0</code> means any configured method: username/password login form and OIDC, if enabled. <code>1</code> means OIDC for the WebAdmin UI. <code>2</code> means OIDC for the WebClient UI. <code>4</code> means login form for the WebAdmin UI. <code>8</code> means login form for the WebClient UI. You can combine the values. For example <code>3</code> means that you can only login using OIDC on both WebClient and WebAdmin UI. DEPRECATED: use <code>disabled_login_methods</code>. Default: <code>0</code>.</li> <li><code>disabled_login_methods</code>, integer. Defines the disabled login methods. <code>0</code> means all available login methods are enabled. <code>1</code> means OIDC for the WebAdmin UI. <code>2</code> means OIDC for the WebClient UI. <code>4</code> means login form for the WebAdmin UI. <code>8</code> means login form for the WebClient UI. You can combine the values. <code>16</code> means the admin token endpoint for REST API. <code>32</code> means the user token endpoint for REST API. <code>64</code> means admin API key login. <code>128</code> means user API key login. For example <code>252</code> means that you can only login using OIDC on both WebClient and WebAdmin UI. Default: <code>0</code></li> <li><code>enable_https</code>, boolean. Set to <code>true</code> and provide both a certificate and a key file to enable HTTPS connection for this binding. Default <code>false</code>.</li> <li><code>certificate_file</code>, string. Binding specific TLS certificate. This can be an absolute path or a path relative to the config dir.</li> <li><code>certificate_key_file</code>, string. Binding specific private key matching the above certificate. This can be an absolute path or a path relative to the config dir. If not set the global ones will be used, if any.</li> <li><code>min_tls_version</code>, integer. Defines the minimum version of TLS to be enabled. <code>12</code> means TLS 1.2 (and therefore TLS 1.2 and TLS 1.3 will be enabled),<code>13</code> means TLS 1.3, <code>10</code> means TLS 1.0, <code>11</code> means TLS 1.1. Default: <code>12</code>.</li> <li><code>client_auth_type</code>, integer. Set to <code>1</code> to require client certificate authentication in addition to JWT/Web authentication. You need to define at least a certificate authority for this to work. Default: 0.</li> <li><code>tls_cipher_suites</code>, list of strings. List of supported cipher suites for TLS version 1.2 and below. If empty, a default list of secure cipher suites is used, with a preference order based on hardware performance. Note that TLS 1.3 ciphersuites are not configurable. Supported ciphersuites names. Any invalid name will be silently ignored. The order matters, the ciphers listed first will be the preferred ones. Default: empty.</li> <li><code>tls_protocols</code>, list of string. HTTPS protocols in preference order. Supported values: <code>http/1.1</code>, <code>h2</code>. Default: <code>http/1.1</code>, <code>h2</code>.</li> <li><code>proxy_mode</code>, integer. Set to <code>1</code> to use the proxy protocol configuration defined within the <code>common</code> section instead of the proxy header configuration. Default: <code>0</code>.</li> <li><code>proxy_allowed</code>, list of IP addresses and IP ranges allowed to set client IP proxy header such as <code>X-Forwarded-For</code>, <code>X-Real-IP</code> and any other headers defined in the <code>security</code> section. Any of the indicated headers, if set on requests from a connection address not in this list, will be silently ignored. Default: empty.</li> <li><code>client_ip_proxy_header</code>, string. Defines the allowed client IP proxy header such as <code>X-Forwarded-For</code>, <code>X-Real-IP</code> etc. Default: empty</li> <li><code>client_ip_header_depth</code>, integer. Some client IP headers such as <code>X-Forwarded-For</code> can contain multiple IP address, this setting define the position to trust starting from the right. For example if we have: <code>10.0.0.1,11.0.0.1,12.0.0.1,13.0.0.1</code> and the depth is <code>0</code>, SFTPGo will use <code>13.0.0.1</code> as client IP, if depth is <code>1</code>, <code>12.0.0.1</code> will be used and so on. Set to <code>-1</code> to trust the leftmost IP address: this may have security implications and should only be used if your proxy has appropriate security controls in place to prevent spoofed IP headers. Default: <code>0</code>.</li> <li><code>hide_login_url</code>, integer. If both web admin and web client are enabled each login page will show a link to the other one. This setting allows to hide this link. 0 means that the login links are displayed on both admin and client login page. This is the default. 1 means that the login link to the web client login page is hidden on admin login page. 2 means that the login link to the web admin login page is hidden on client login page. The flags can be combined, for example 3 will disable both login links.</li> <li><code>render_openapi</code>, boolean. Set to <code>false</code> to disable serving of the OpenAPI schema and renderer. Default <code>true</code>.</li> <li><code>languages</code>, list of strings. Supporrted values: <code>en</code>, <code>it</code>, <code>de</code>, <code>fr</code>, <code>es</code>, <code>zh-CN</code>. Default: <code>en</code>.</li> <li><code>oidc</code>, struct. Defines the OpenID connect configuration. OpenID integration allows you to map your identity provider users to SFTPGo users and so you can login to SFTPGo Web Client and Web Admin user interfaces using your identity provider. The following fields are supported:<ul> <li><code>config_url</code>, string. Identifier for the service. If defined, SFTPGo will add <code>/.well-known/openid-configuration</code> to this url and attempt to retrieve the provider configuration on startup. SFTPGo will refuse to start if it fails to connect to the specified URL. Default: blank.</li> <li><code>client_id</code>, string. Defines the application's ID. Default: blank.</li> <li><code>client_secret</code>, string. Defines the application's secret. Default: blank.</li> <li><code>client_secret_file</code>, string. Defines the path to a file containing the application secret. This can be an absolute path or a path relative to the config dir. If not empty, it takes precedence over <code>client_secret</code>. Default: blank.</li> <li><code>redirect_base_url</code>, string. Defines the base URL to redirect to after OpenID authentication. The suffix <code>/web/oidc/redirect</code> will be added to this base URL, adding also the <code>web_root</code> if configured. Default: blank.</li> <li><code>username_field</code>, string. Defines the ID token claims field to map to the SFTPGo username. Default: blank.</li> <li><code>scopes</code>, list of strings. Request the OAuth provider to provide the scope information from an authenticated users. The <code>openid</code> scope is mandatory. Default: <code>\"openid\", \"profile\", \"email\"</code>.</li> <li><code>role_field</code>, string. Optional ID token claim used to determine the SFTPGo role. If the specified claim contains one of the values defined in <code>role_values</code>, the authenticated user is mapped to the SFTPGo admin role. This field is not required when OpenID Connect is used only for the Web Client UI. If the claim is nested, dot notation can be used to traverse the structure. Default: empty.</li> <li><code>role_values</code>, list of strings. List of accepted values for the ID token claim specified by <code>role_field</code>. If the claim value matches any of these values, the user is mapped to the SFTPGo admin role. Matching is case-insensitive. Default: <code>[\"admin\"]</code>.</li> <li><code>implicit_roles</code>, boolean. If set, the <code>role_field</code> is ignored and the SFTPGo role is assumed based on the login link used. Default: <code>false</code>.</li> <li><code>custom_fields</code>, list of strings. Custom token claims fields to pass to the pre-login hook. Default: empty.</li> <li><code>insecure_skip_signature_check</code>, boolean. This setting causes SFTPGo to skip JWT signature validation. It's intended for special cases where providers, such as Azure, use the <code>none</code> algorithm. Skipping the signature validation can cause security issues. Default: <code>false</code>.</li> <li><code>insecure_issuer_url</code>, boolean. Enable to allow discovery to work when the issuer_url reported by upstream is mismatched with the discovery URL. This is meant for integration with off-spec providers such as Azure B2C. Default: <code>false</code>.</li> <li><code>disabled_security_features</code>, integer. Allows to disable some security features enabled by default. Set to <code>1</code> to disable PKCE. Default: <code>0</code>.</li> <li><code>max_age</code>, string. Specifies the allowable elapsed time in seconds since the last time the End-User was actively authenticated. If the elapsed time is greater than this value, the provider must actively re-authenticate the user. Set to <code>0</code> to force re-authentication. If empty, the parameter is not sent and the provider's default policy applies. Default: blank.</li> <li><code>prompt</code>, string. A space-delimited, case-sensitive list of ASCII string values that specifies whether the Authorization Server prompts the End-User for reauthentication and consent. Common values include <code>none</code>, <code>login</code>, <code>consent</code>, <code>select_account</code>. If empty, the parameter is not sent. Default: blank.</li> <li><code>ui_name</code>, string. Defines the the name to display in the login page. Default: <code>OpenID</code>.</li> <li><code>debug</code>, boolean. If set, the received id tokens will be logged at debug level. Default: <code>false</code>.</li> </ul> </li> <li><code>wopi</code>, struct. Defines the configuration for the WOPI integration, compatible with document servers like Collabora Online.<ul> <li><code>server_url</code>, string. Defines the base URL of the WOPI server. The path <code>/hosting/discovery</code> will be automatically added.</li> <li><code>skip_proof_key_verify</code>, boolean. If enabled the proof keys are not verified. This should be used only for testing.</li> <li><code>callback_url</code>, string. Defines the base URL that the WOPI server uses to access and update files. This is typically the SFTPGo URL reachable from the WOPI server, for example: <code>https://sftpgo.example.com</code>.</li> <li><code>allowed_from</code>. Defines the list of IP addresses and IP ranges permitted to access the SFTPGo WOPI implementation. This typically includes the IP address of the WOPI server and can be used alongside proof keys for enhanced security.</li> <li><code>skipped_extensions</code>. Specifies the file extensions for which the WOPI protocol will be bypassed. Examples include: <code>png</code>, <code>jpg</code>, <code>jpeg</code>.</li> <li><code>max_users</code>, integer. Defines the maximum number of SFTPGo users allowed to access the WOPI implementation. 0 means unlimited. Default: <code>0</code>.</li> </ul> </li> <li><code>security</code>, struct. Defines security headers to add to HTTP responses and allows to restrict allowed hosts. The following parameters are supported:<ul> <li><code>enabled</code>, boolean. Set to <code>true</code> to enable security configurations. Default: <code>false</code>.</li> <li><code>allowed_hosts</code>, list of strings. Fully qualified domain names that are allowed. An empty list allows any and all host names. Default: empty.</li> <li><code>allowed_hosts_are_regex</code>, boolean. Determines if the provided allowed hosts contains valid regular expressions. Default: <code>false</code>.</li> <li><code>hosts_proxy_headers</code>, list of string. Defines a set of header keys that may hold a proxied hostname value for the request, for example <code>X-Forwarded-Host</code>. Default: empty.</li> <li><code>https_redirect</code>, boolean. Set to <code>true</code> to redirect HTTP requests to HTTPS. If you redirect from port <code>80</code> and you get your TLS certificates using the built-in ACME protocol and the <code>HTTP-01</code> challenge type, you need to use the webroot method and set the ACME web root to a path writable by SFTPGo in order to renew your certificates. Default: <code>false</code>.</li> <li><code>https_host</code>, string. Defines the host name that is used to redirect HTTP requests to HTTPS. Default is blank, which indicates to use the same host. For example, if <code>https_redirect</code> is enabled and <code>https_host</code> is blank, a request for <code>http://127.0.0.1/web/client/login</code> will be redirected to <code>https://127.0.0.1/web/client/login</code>, if <code>https_host</code> is set to <code>www.example.com</code> the same request will be redirected to <code>https://www.example.com/web/client/login</code>.</li> <li><code>https_proxy_headers</code>, list of struct, each struct contains the fields <code>key</code> and <code>value</code>. Defines a a list of header keys with associated values that would indicate a valid https request. For example <code>key</code> could be <code>X-Forwarded-Proto</code> and <code>value</code> <code>https</code>. Default: empty.</li> <li><code>sts_seconds</code>, integer. Defines the max-age of the <code>Strict-Transport-Security</code> header. This header will be included for <code>https</code> responses or for HTTP request if the request includes a defined HTTPS proxy header. Default: <code>0</code>, which would NOT include the header.</li> <li><code>sts_include_subdomains</code>, boolean. Set to <code>true</code>, the <code>includeSubdomains</code> will be appended to the <code>Strict-Transport-Security</code> header. Default: <code>false</code>.</li> <li><code>sts_preload</code>, boolean. Set to true, the <code>preload</code> flag will be appended to the <code>Strict-Transport-Security</code> header. Default: <code>false</code>.</li> <li><code>content_type_nosniff</code>, boolean. Set to <code>true</code> to add the <code>X-Content-Type-Options</code> header with the value <code>nosniff</code>. Default: <code>false</code>.</li> <li><code>content_security_policy</code>, string. Allows to set the <code>Content-Security-Policy</code> header value. Default: blank.</li> <li><code>permissions_policy</code>, string. Allows to set the <code>Permissions-Policy</code> header value. Default: blank.</li> <li><code>cross_origin_opener_policy</code>, string. Allows to set the <code>Cross-Origin-Opener-Policy</code> header value. Default: blank.</li> <li><code>cross_origin_resource_policy</code>, string. Allows to set the <code>Cross-Origin-Resource-Policy</code> header value. Default: blank.</li> <li><code>cross_origin_embedder_policy</code>, string. Allows to set the <code>Cross-Origin-Embedder-Policy</code> header value. Default: blank.</li> <li><code>referrer_policy</code>, string. Allows to set the <code>Referrer-Policy</code> header value. Default: blank.</li> <li><code>cache_control</code>, string. Allows to set the <code>Cache-Control</code> header. Set to <code>private</code> to disable caching for dynamic pages. Default: blank.</li> </ul> </li> <li><code>branding</code>, struct. Defines the supported customizations to suit your brand. It contains the <code>web_admin</code> and <code>web_client</code> structs that define customizations for the WebAdmin and the WebClient UIs. Each customization struct contains the following fields:<ul> <li><code>name</code>, string. Defines the UI name</li> <li><code>short_name</code>, string. Defines the short name to show next to the logo image and on the login page</li> <li><code>favicon_path</code>, string. Path to the favicon relative to <code>static_files_path</code>. For example, if you create a directory named <code>branding</code> inside the static dir and put the <code>favicon.png</code> file in it, you must set <code>/branding/favicon.png</code> as path.</li> <li><code>logo_path</code>, string. Path to your logo relative to <code>static_files_path</code>. The preferred image size is 256x256 pixel</li> <li><code>disclaimer_name</code>, string. Name for your optional disclaimer</li> <li><code>disclaimer_path</code>, string. Path to the HTML page with the disclaimer relative to <code>static_files_path</code> or an absolute URL (http or https).</li> <li><code>default_css</code>, list of strings. Optional path to custom CSS files, relative to <code>static_files_path</code>, which replaces the default CSS</li> <li><code>extra_css</code>, list of strings. Defines the paths, relative to <code>static_files_path</code>, to additional CSS files</li> </ul> </li> </ul> </li> <li><code>templates_path</code>, string. Path to the HTML web templates. This can be an absolute path or a path relative to the config dir</li> <li><code>static_files_path</code>, string. Path to the static files for the web interface. This can be an absolute path or a path relative to the config dir. If both <code>templates_path</code> and <code>static_files_path</code> are empty the built-in web interface will be disabled</li> <li><code>openapi_path</code>, string. Path to the directory that contains the OpenAPI schema and the default renderer. This can be an absolute path or a path relative to the config dir. If empty the OpenAPI schema and the renderer will not be served regardless of the <code>render_openapi</code> directive</li> <li><code>web_root</code>, string.  Defines a base URL for the web admin and client interfaces. If empty web admin and client resources will be available at the root (\"/\") URI. If defined it must be an absolute URI or it will be ignored</li> <li><code>certificate_file</code>, string. Certificate for HTTPS. This can be an absolute path or a path relative to the config dir.</li> <li><code>certificate_key_file</code>, string. Private key matching the above certificate. This can be an absolute path or a path relative to the config dir. If both the certificate and the private key are provided, you can enable HTTPS for the configured bindings. Certificate and key files can be reloaded on demand sending a <code>SIGHUP</code> signal on Unix based systems and a <code>paramchange</code> request to the running service on Windows. The certificates are also polled for changes every 8 hours.</li> <li><code>ca_certificates</code>, list of strings. Set of root certificate authorities to be used to verify client certificates.</li> <li><code>ca_revocation_lists</code>, list of strings. Set a revocation lists, one for each root CA, to be used to check if a client certificate has been revoked. The revocation lists can be reloaded on demand sending a <code>SIGHUP</code> signal on Unix based systems and a <code>paramchange</code> request to the running service on Windows.</li> <li><code>signing_passphrase</code>, string. Passphrase to use to derive the signing key for JWT and CSRF tokens. If empty a random signing key will be generated each time SFTPGo starts. If you set a signing passphrase you should consider rotating it periodically for added security.</li> <li><code>signing_passphrase_file</code>, string. Defines the path to a file containing the signing passphrase. This can be an absolute path or a path relative to the config dir. If not empty, it takes precedence over <code>signing_passphrase</code>. Default: blank.</li> <li><code>token_validation</code>, integer. Defines how to validate JWT tokens, cookies and CSRF tokens. By default a token must be used by the same IP for which it was issued, set to <code>1</code> to disable this requirement. Set to <code>2</code> to invalidate admin and user tokens issued before the last update. Flags can be combined. Default: <code>0</code>.</li> <li><code>cookie_lifetime</code>, integer. Defines the duration in minutes for WebAdmin and WebClient cookies. Cookies are automatically refreshed if there is user activity and the maximum duration is 12 hours. An invalid value is silently ignored. Maximum allowed value <code>720</code>, default: <code>20</code>.</li> <li><code>share_cookie_lifetime</code>, integer. Defines the duration in minutes for public sharing cookies. An invalid value is silently ignored. Maximum allowed value <code>720</code>, default: <code>120</code>.</li> <li><code>jwt_lifetime</code>, integer. Defines the duration in minutes for REST API tokens. An invalid value is silently ignored. Maximum allowed value <code>720</code>, default: <code>20</code>.</li> <li><code>wopi_token_lifetime</code>, integer. Defines the duration in minutes for WOPI access tokens. An invalid value is silently ignored. Maximum allowed value <code>720</code>, default: <code>360</code>.</li> <li><code>max_upload_file_size</code>, integer. Defines the maximum request body size, in bytes, for Web Client/API HTTP upload requests. <code>0</code> means no limit. Default: <code>0</code>.</li> <li><code>cors</code> struct containing CORS configuration. SFTPGo uses Go CORS handler, please refer to upstream documentation for fields meaning and their default values.<ul> <li><code>enabled</code>, boolean, set to <code>true</code> to enable CORS.</li> <li><code>allowed_origins</code>, list of strings.</li> <li><code>allowed_methods</code>, list of strings.</li> <li><code>allowed_headers</code>, list of strings.</li> <li><code>exposed_headers</code>, list of strings.</li> <li><code>allow_credentials</code> boolean.</li> <li><code>max_age</code>, integer.</li> <li><code>options_passthrough</code>, boolean.</li> <li><code>options_success_status</code>, integer.</li> <li><code>allow_private_network</code>, boolean.</li> </ul> </li> <li><code>setup</code> struct containing configurations for the initial setup screen<ul> <li><code>installation_code</code>, string. If set, this installation code will be required when creating the first admin account. Please note that even if set using an environment variable this field is read at SFTPGo startup and not at runtime. This is not a license key or similar, the purpose here is to prevent anyone who can access to the initial setup screen from creating an admin user. Default: blank.</li> <li><code>installation_code_hint</code>, string. Description for the installation code input field. Default: <code>Installation code</code>.</li> </ul> </li> </ul>"},{"location":"config-file/#telemetry","title":"Telemetry","text":"<p>Supported configuration parameters for the <code>telemetry</code> section:</p> <ul> <li><code>bind_port</code>, integer. The port used for serving HTTP requests. Set to 0 to disable HTTP server. Default: 0</li> <li><code>bind_address</code>, string. Leave blank to listen on all available network interfaces. On *NIX you can specify an absolute path to listen on a Unix-domain socket. Default: <code>127.0.0.1</code></li> <li><code>enable_profiler</code>, boolean. Enable the built-in profiler. Default <code>false</code></li> <li><code>auth_user_file</code>, string. Path to a file used to store usernames and passwords for basic authentication. This can be an absolute path or a path relative to the config dir. We support HTTP basic authentication, and the file format must conform to the one generated using the Apache <code>htpasswd</code> tool. The supported password formats are bcrypt (<code>$2y$</code> prefix) and md5 crypt (<code>$apr1$</code> prefix). If empty, HTTP authentication is disabled. Authentication will be always disabled for the <code>/healthz</code> endpoint.</li> <li><code>certificate_file</code>, string. Certificate for HTTPS. This can be an absolute path or a path relative to the config dir.</li> <li><code>certificate_key_file</code>, string. Private key matching the above certificate. This can be an absolute path or a path relative to the config dir. If both the certificate and the private key are provided, the server will expect HTTPS connections. Certificate and key files can be reloaded on demand sending a <code>SIGHUP</code> signal on Unix based systems and a <code>paramchange</code> request to the running service on Windows.</li> <li><code>min_tls_version</code>, integer. Defines the minimum version of TLS to be enabled. <code>12</code> means TLS 1.2 (and therefore TLS 1.2 and TLS 1.3 will be enabled),<code>13</code> means TLS 1.3, <code>10</code> means TLS 1.0, <code>11</code> means TLS 1.1. Default: <code>12</code>.</li> <li><code>tls_cipher_suites</code>, list of strings. List of supported cipher suites for TLS version 1.2 and below. If empty, a default list of secure cipher suites is used, with a preference order based on hardware performance. Note that TLS 1.3 ciphersuites are not configurable. Supported ciphersuites names. Any invalid name will be silently ignored. The order matters, the ciphers listed first will be the preferred ones. Default: empty.</li> <li><code>tls_protocols</code>, list of string. HTTPS protocols in preference order. Supported values: <code>http/1.1</code>, <code>h2</code>. Default: <code>http/1.1</code>, <code>h2</code>.</li> </ul> <p>The telemetry server publishes the following endpoints:</p> <ul> <li><code>/healthz</code>, health information (for health checks)</li> <li><code>/metrics</code>, Prometheus metrics</li> <li><code>/debug/pprof</code>, if enabled via the <code>enable_profiler</code> configuration key, for profiling, more details</li> </ul>"},{"location":"config-file/#http-clients","title":"HTTP clients","text":"<p>HTTP clients are used for executing hooks. Some hooks use a retryable HTTP client, for these hooks you can configure the time between retries and the number of retries. Please check the hook specific documentation to understand which hooks use a retryable HTTP client.</p> <p>Supported configuration parameters for the <code>http</code> section:</p> <ul> <li><code>timeout</code>, float. Timeout specifies a time limit, in seconds, for requests. For requests with retries this is the timeout for a single request</li> <li><code>retry_wait_min</code>, integer. Defines the minimum waiting time between attempts in seconds.</li> <li><code>retry_wait_max</code>, integer. Defines the maximum waiting time between attempts in seconds. The backoff algorithm will perform exponential backoff based on the attempt number and limited by the provided minimum and maximum durations.</li> <li><code>retry_max</code>, integer. Defines the maximum number of retries if the first request fails.</li> <li><code>ca_certificates</code>, list of strings. List of paths to extra CA certificates to trust. The paths can be absolute or relative to the config dir. Adding trusted CA certificates is a convenient way to use self-signed certificates without defeating the purpose of using TLS.</li> <li><code>certificates</code>, list of certificate for mutual TLS. Each certificate is a struct with the following fields:<ul> <li><code>cert</code>, string. Path to the certificate file. The path can be absolute or relative to the config dir.</li> <li><code>key</code>, string. Path to the key file. The path can be absolute or relative to the config dir.</li> </ul> </li> <li><code>skip_tls_verify</code>, boolean. if enabled the HTTP client accepts any TLS certificate presented by the server and any host name in that certificate. In this mode, TLS is susceptible to man-in-the-middle attacks. This should be used only for testing.</li> <li><code>headers</code>, list of structs. You can define a list of http headers to add to each hook. Each struct has the following fields:<ul> <li><code>key</code>, string</li> <li><code>value</code>, string. The header is silently ignored if <code>key</code> or <code>value</code> are empty</li> <li><code>url</code>, string, optional. If not empty, the header will be added only if the request URL starts with the one specified here</li> </ul> </li> </ul>"},{"location":"config-file/#commands","title":"Commands","text":"<p>External commands are used for executing hooks. Supported configuration parameters for the <code>command</code> section:</p> <ul> <li><code>timeout</code>, integer. Timeout specifies a time limit, in seconds, to execute external commands. Valid range: <code>1-300</code>. Default: <code>30</code></li> <li><code>env</code>, list of strings. Environment variables to pass to all the external commands. Global environment variables are cleared, for security reasons, you have to explicitly set any environment variable such as <code>PATH</code> etc. if you need them. Each entry is of the form <code>key=value</code>. Do not use environment variables prefixed with <code>SFTPGO_</code> to avoid conflicts with environment variables that SFTPGo hooks can set. Default: empty</li> <li><code>commands</code>, list of structs. Allow to customize configuration per-command. Each struct has the following fields:<ul> <li><code>path</code>, string. Define the command path as defined in the hook configuration</li> <li><code>timeout</code>, integer. This value overrides the global timeout if set</li> <li><code>env</code>, list of strings. These values are added to the environment variables defined for all commands, if any. Default: empty</li> <li><code>args</code>, list of strings. Arguments to pass to the command identified by <code>path</code>. Default: empty</li> <li><code>hook</code>, string. If not empty this configuration only apply to the specified hook name. Supported hook names: <code>fs_actions</code>, <code>provider_actions</code>, <code>startup</code>, <code>post_connect</code>, <code>post_disconnect</code>, <code>check_password</code>, <code>pre_login</code>, <code>post_login</code>, <code>external_auth</code>, <code>keyboard_interactive</code>. Default: empty</li> </ul> </li> </ul>"},{"location":"config-file/#kms","title":"KMS","text":"<p>Supported configuration parameters for the <code>kms</code> section:</p> <ul> <li><code>secrets</code><ul> <li><code>url</code>, string. Defines the URI to the KMS service. Default: blank.</li> <li><code>master_key</code>, string. Defines the master encryption key as string. Default: blank.</li> <li><code>master_key_path</code>, string. Defines the absolute path to a file containing the master encryption key. If not empty, it takes precedence over <code>master_key</code>. Default: blank.</li> </ul> </li> </ul>"},{"location":"config-file/#multi-factor-authentication","title":"Multi-factor authentication","text":"<p>Supported configuration parameters for the <code>mfa</code> section:</p> <ul> <li><code>totp</code>, list of struct that define settings for time-based one time passwords (RFC 6238). Each struct has the following fields:<ul> <li><code>name</code>, string. Unique configuration name. This name should not be changed if there are users or admins using the configuration. The name is not visible to the authentication apps. Default: <code>Default</code>.</li> <li><code>issuer</code>, string. Name of the issuing Organization/Company. Default: <code>SFTPGo</code>.</li> <li><code>algo</code>, string. Algorithm to use for HMAC. The supported algorithms are: <code>sha1</code>, <code>sha256</code>, <code>sha512</code>. Currently Google Authenticator app on iPhone seems to only support <code>sha1</code>, please check the compatibility with your target apps/device before setting a different algorithm. You can also define multiple configurations, for example one that uses <code>sha256</code> or <code>sha512</code> and another one that uses <code>sha1</code> and instruct your users to use the appropriate configuration for their devices/apps. The algorithm should not be changed if there are users or admins using the configuration. Default: <code>sha1</code>.</li> </ul> </li> </ul>"},{"location":"config-file/#smtp","title":"SMTP","text":"<p>SMTP configuration enables SFTPGo email sending capabilities. Supported configuration parameters for the <code>smtp</code> section:</p> <ul> <li><code>host</code>, string. Location of SMTP email server. Leave empty to disable email sending capabilities. Default: blank.</li> <li><code>port</code>, integer. Port of SMTP email server.</li> <li><code>from</code>, string. From address, for example <code>SFTPGo &lt;sftpgo@example.com&gt;</code>. Many SMTP servers reject emails without a <code>From</code> header so, if not set, SFTPGo will try to use the username as fallback, this may or may not be appropriate. Default: blank</li> <li><code>user</code>, string. SMTP username. Default: blank</li> <li><code>password</code>, string. SMTP password. Leaving both username and password empty the SMTP authentication will be disabled. Default: blank</li> <li><code>auth_type</code>, integer. 0 means <code>Plain</code>, 1 means <code>Login</code>, 2 means <code>CRAM-MD5</code>, 3 means <code>XOAUTH2</code>. Default: <code>0</code>.</li> <li><code>encryption</code>, integer. 0 means no encryption, 1 means <code>TLS</code>, 2 means <code>STARTTLS</code>. Default: <code>0</code>.</li> <li><code>domain</code>, string. Domain to use for <code>HELO</code> command, if empty <code>localhost</code> will be used. Default: blank.</li> <li><code>templates_path</code>, string. Path to the email templates. This can be an absolute path or a path relative to the config dir. Templates are searched within a subdirectory named \"email\" in the specified path. You can customize the email templates by simply specifying an alternate path and putting your custom templates there.</li> <li><code>debug</code>, integer. Set to <code>1</code> to enable SMTP debug. Default: <code>0</code>.</li> <li><code>oauth2</code>, struct containing OAuth2 related configurations:<ul> <li><code>provider</code>, integer, 0 means <code>Google</code>, 1 means <code>Microsoft</code>. Default: <code>0</code>.</li> <li><code>tenant</code>, string. Azure Active Directory tenant for the Microsoft provider. Typical values are <code>common</code>, <code>organizations</code>, <code>consumers</code> or tenant identifier. If empty <code>common</code> is used. Default: blank.</li> <li><code>client_id</code>, string. Default: blank.</li> <li><code>client_secret</code>, string. Default: blank.</li> <li><code>refresh_token</code>, string. Default: blank.</li> </ul> </li> </ul>"},{"location":"config-file/#plugins","title":"Plugins","text":"<p>The <code>plugins</code> section allow to configure a list of external plugins.  Please note that the plugin system is experimental, the configuration parameters and interfaces may change in a backward incompatible way in future. Each plugin is configured using a struct with the following fields:</p> <ul> <li><code>type</code>, string. Defines the plugin type. Supported types: <code>notifier</code>, <code>kms</code>, <code>auth</code>, <code>eventsearcher</code>, <code>ipfilter</code>.</li> <li><code>notifier_options</code>, struct. Defines the options for notifier plugins.<ul> <li><code>fs_events</code>, list of strings. Defines the filesystem events that will be notified to this plugin. Supported values: <code>download</code>, <code>upload</code>, <code>first-upload</code>, <code>first-download</code>, <code>delete</code>, <code>rename</code>, <code>rmkdir</code>, <code>rmdir</code>, <code>ssh_cmd</code>.</li> <li><code>provider_events</code>, list of strings. Defines the provider events that will be notified to this plugin. Supported valies: <code>add</code>, <code>update</code>, <code>delete</code>.</li> <li><code>provider_objects</code>, list if strings. Defines the provider objects that will be notified to this plugin. Supported values: <code>user</code>, <code>folder</code>, <code>group</code>, <code>admin</code>, <code>api_key</code>, <code>share</code>, <code>event_action</code>, <code>event_rule</code>, <code>role</code>, <code>ip_list_entry</code>, <code>configs</code>, <code>license</code>.</li> <li><code>log_events</code>, list of integers. Defines the log events that will be notified to this plugin. <code>1</code> means \"Login failed\", <code>2</code> means \"Login with non-existent user\", <code>3</code> means \"No login tried\", <code>4</code> means \"Algorithm negotiation failed\", <code>5</code> means \"Login succeeded\", <code>6</code> means \"Share legal agreement accepted\".</li> <li><code>retry_max_time</code>, integer. Defines the maximum number of seconds an event can be late. SFTPGo adds a timestamp to each event and add to an internal queue any events that a the plugin fails to handle (the plugin returns an error or it is not running). If a plugin fails to handle an event that is too late, based on this configuration, it will be discarded. SFTPGo will try to resend queued events every 30 seconds. 0 means no retry.</li> <li><code>retry_queue_max_size</code>, integer. Defines the maximum number of events that the internal queue can hold. Once the queue is full, the events that cannot be sent to the plugin will be discarded. 0 means no limit.</li> </ul> </li> <li><code>kms_options</code>, struct. Defines the options for kms plugins.<ul> <li><code>scheme</code>, string. KMS scheme. Supported schemes are: <code>awskms</code>, <code>gcpkms</code>, <code>hashivault</code>, <code>azurekeyvault</code>.</li> <li><code>encrypted_status</code>, string. Encrypted status for a KMS secret. Supported statuses are: <code>AWS</code>, <code>GCP</code>, <code>VaultTransit</code>, <code>AzureKeyVault</code>.</li> </ul> </li> <li><code>auth_options</code>, struct. Defines the options for auth plugins.<ul> <li><code>scope</code>, integer. 1 means passwords only. 2 means public keys only. 4 means key keyboard interactive only. 8 means TLS certificate. The flags can be combined, for example 6 means public keys and keyboard interactive. The scope must be explicit, <code>0</code> is not a valid option.</li> </ul> </li> <li><code>cmd</code>, string. Path to the plugin executable.</li> <li><code>args</code>, list of strings. Optional arguments to pass to the plugin executable.</li> <li><code>sha256sum</code>, string. SHA256 checksum for the plugin executable. If not empty it will be used to verify the integrity of the executable.</li> <li><code>auto_mtls</code>, boolean. If enabled the client and the server automatically negotiate mutual TLS for transport authentication. This ensures that only the original client will be allowed to connect to the server, and all other connections will be rejected. The client will also refuse to connect to any server that isn't the original instance started by the client.</li> <li><code>env_prefix</code>, string. Defines the prefix for env vars to pass from the SFTPGo process environment to the plugin. Set to <code>none</code> to not pass any environment variable, set to <code>*</code> to pass all environment variables. If empty, the prefix is returned as the plugin name in uppercase with <code>-</code> replaced with <code>_</code> and a trailing <code>_</code>. For example if the plugin name is <code>sftpgo-plugin-eventsearch</code> the prefix will be <code>SFTPGO_PLUGIN_EVENTSEARCH_</code></li> <li><code>env_vars</code>, list of strings. Additional environment variable names to pass from the SFTPGo process environment to the plugin.</li> </ul>"},{"location":"custom-actions/","title":"Custom Actions","text":""},{"location":"custom-actions/#custom-actions","title":"Custom Actions","text":"<p>SFTPGo can notify filesystem and provider events using custom actions. A custom action can be an external program or an HTTP URL.</p>"},{"location":"custom-actions/#filesystem-events","title":"Filesystem events","text":"<p>The <code>actions</code> struct inside the <code>common</code> configuration section allows to configure the actions for file operations and SSH commands. The <code>hook</code> can be defined as the absolute path of your program or an HTTP URL.</p> <p>The following <code>actions</code> are supported:</p> <ul> <li><code>download</code></li> <li><code>first-download</code></li> <li><code>pre-download</code></li> <li><code>upload</code></li> <li><code>first-upload</code></li> <li><code>pre-upload</code></li> <li><code>delete</code></li> <li><code>pre-delete</code></li> <li><code>rename</code></li> <li><code>mkdir</code></li> <li><code>rmdir</code></li> <li><code>ssh_cmd</code></li> <li><code>copy</code></li> </ul> <p>The <code>upload</code> condition includes both uploads to new files and overwrite of existing ones. If an upload is aborted for quota limits SFTPGo tries to remove the partial file, so if the notification reports a zero size file and a quota exceeded error the file has been deleted. The <code>ssh_cmd</code> condition will be triggered after a command is successfully executed via SSH. <code>scp</code> will trigger the <code>download</code> and <code>upload</code> conditions and not <code>ssh_cmd</code>. The <code>first-download</code> and <code>first-upload</code> action are executed only if no error occour and they don't exclude the <code>download</code> and <code>upload</code> notifications, so you will get both the <code>first-upload</code> and <code>upload</code> notification after the first successful upload and the same for the first successful download. For cloud backends directories are virtual, they are created implicitly when you upload a file and are implicitly removed when the last file within a directory is removed. The <code>mkdir</code> and <code>rmdir</code> notifications are sent only when a directory is explicitly created or removed.</p> <p>The notification will indicate if an error is detected and so, for example, a partial file is uploaded.</p> <p>The <code>pre-delete</code>, <code>pre-download</code> and <code>pre-upload</code> actions, will be called before deleting, downloading and uploading files. If the external command completes with a zero exit status or the HTTP notification response code is <code>200</code>, SFTPGo will allow the operation, otherwise the client will get a permission denied error.</p> <p>If the <code>hook</code> defines a path to an external program, then this program can read the following environment variables:</p> <ul> <li><code>SFTPGO_ACTION</code>, supported action</li> <li><code>SFTPGO_ACTION_USERNAME</code></li> <li><code>SFTPGO_ACTION_PATH</code>, is the full filesystem path, can be empty for some ssh commands</li> <li><code>SFTPGO_ACTION_TARGET</code>, full filesystem path, non-empty for <code>rename</code> <code>SFTPGO_ACTION</code> and for some SSH commands</li> <li><code>SFTPGO_ACTION_VIRTUAL_PATH</code>, virtual path, seen by SFTPGo users</li> <li><code>SFTPGO_ACTION_VIRTUAL_TARGET</code>, virtual target path, seen by SFTPGo users</li> <li><code>SFTPGO_ACTION_SSH_CMD</code>, non-empty for <code>ssh_cmd</code> <code>SFTPGO_ACTION</code></li> <li><code>SFTPGO_ACTION_FILE_SIZE</code>, non-zero for <code>pre-upload</code>, <code>upload</code>, <code>download</code>, <code>delete</code>, and <code>copy</code> actions if the file size is greater than <code>0</code></li> <li><code>SFTPGO_ACTION_ELAPSED</code>, elapsed time as milliseconds</li> <li><code>SFTPGO_ACTION_FS_PROVIDER</code>, <code>0</code> for local filesystem, <code>1</code> for S3 backend, <code>2</code> for Google Cloud Storage (GCS) backend, <code>3</code> for Azure Blob Storage backend, <code>4</code> for local encrypted backend, <code>5</code> for SFTP backend</li> <li><code>SFTPGO_ACTION_BUCKET</code>, non-empty for S3, GCS and Azure backends</li> <li><code>SFTPGO_ACTION_ENDPOINT</code>, non-empty for S3, SFTP and Azure backend if configured</li> <li><code>SFTPGO_ACTION_STATUS</code>, integer. Status for <code>upload</code>, <code>download</code> and <code>ssh_cmd</code> actions. 1 means no error, 2 means a generic error occurred, 3 means quota exceeded error</li> <li><code>SFTPGO_ACTION_PROTOCOL</code>, string. Possible values are <code>SSH</code>, <code>SFTP</code>, <code>SCP</code>, <code>FTP</code>, <code>DAV</code>, <code>HTTP</code>, <code>HTTPShare</code>, <code>OIDC</code>, <code>DataRetention</code>, <code>EventAction</code></li> <li><code>SFTPGO_ACTION_IP</code>, the action was executed from this IP address</li> <li><code>SFTPGO_ACTION_SESSION_ID</code>, string. Unique protocol session identifier. For stateless protocols such as HTTP the session id will change for each request</li> <li><code>SFTPGO_ACTION_OPEN_FLAGS</code>, integer. File open flags, can be non-zero for <code>pre-upload</code> action. If <code>SFTPGO_ACTION_FILE_SIZE</code> is greater than zero and <code>SFTPGO_ACTION_OPEN_FLAGS&amp;512 == 0</code> the target file will not be truncated</li> <li><code>SFTPGO_ACTION_ROLE</code>, string. Role of the user who executed the action</li> <li><code>SFTPGO_ACTION_TIMESTAMP</code>, int64. Event timestamp as nanoseconds since epoch</li> <li><code>SFTPGO_ACTION_METADATA</code>, string. Object metadata serialized as JSON. Omitted if there is no metadata</li> </ul> <p>Global environment variables are cleared, for security reasons, when the script is called. You can set additional environment variables in the \"command\" configuration section. The program must finish within 30 seconds.</p> <p>If the <code>hook</code> defines an HTTP URL then this URL will be invoked as HTTP POST. The request body will contain a JSON serialized struct with the following fields:</p> <ul> <li><code>action</code>, string</li> <li><code>username</code>, string</li> <li><code>path</code>, string</li> <li><code>target_path</code>, string, included for <code>rename</code> action and <code>sftpgo-copy</code> SSH command</li> <li><code>virtual_path</code>, string, virtual path, seen by SFTPGo users</li> <li><code>virtual_target_path</code>, string, virtual target path, seen by SFTPGo users</li> <li><code>ssh_cmd</code>, string, included for <code>ssh_cmd</code> action</li> <li><code>file_size</code>, int64, included for <code>pre-upload</code>, <code>upload</code>, <code>download</code>, <code>delete</code> and <code>copy</code> actions if the file size is greater than <code>0</code></li> <li><code>elapsed</code>, int64, elapsed size as milliseconds</li> <li><code>fs_provider</code>, integer, <code>0</code> for local filesystem, <code>1</code> for S3 backend, <code>2</code> for Google Cloud Storage (GCS) backend, <code>3</code> for Azure Blob Storage backend, <code>4</code> for local encrypted backend, <code>5</code> for SFTP backend, <code>6</code> for HTTPFs backend</li> <li><code>bucket</code>, string, included for S3, GCS and Azure backends</li> <li><code>endpoint</code>, string, included for S3, SFTP and Azure backend if configured</li> <li><code>status</code>, integer. Status for <code>upload</code>, <code>download</code> and <code>ssh_cmd</code> actions. 1 means no error, 2 means a generic error occurred, 3 means quota exceeded error</li> <li><code>protocol</code>, string. Possible values are <code>SSH</code>, <code>SFTP</code>, <code>SCP</code>, <code>FTP</code>, <code>DAV</code>, <code>HTTP</code>, <code>HTTPShare</code>, <code>OIDC</code>, <code>DataRetention</code>, <code>EventAction</code></li> <li><code>ip</code>, string. The action was executed from this IP address</li> <li><code>session_id</code>, string. Unique protocol session identifier. For stateless protocols such as HTTP the session id will change for each request</li> <li><code>open_flags</code>, integer. File open flags, can be non-zero for <code>pre-upload</code> action. If <code>file_size</code> is greater than zero and <code>file_size&amp;512 == 0</code> the target file will not be truncated</li> <li><code>role</code>, string. Included if the user who executed the action has a role</li> <li><code>timestamp</code>, int64. Event timestamp as nanoseconds since epoch</li> <li><code>metadata</code>, struct. Object metadata. Both the keys and the values are string. Omitted if there is no metadata</li> </ul> <p>The HTTP hook will use the global configuration for HTTP clients and will respect the retry, TLS and headers configurations. See the HTTP Clients (<code>http</code>) section of the config reference.</p> <p>The <code>pre-*</code> actions are always executed synchronously while the other ones are asynchronous. You can specify the actions to run synchronously via the <code>execute_sync</code> configuration key. Executing an action synchronously means that SFTPGo will not return a result code to the client (which is waiting for it) until your hook have completed its execution. If your hook takes a long time to complete this could cause a timeout on the client side, which wouldn't receive the server response in a timely manner and eventually drop the connection. If you add the <code>upload</code> action to the <code>execute_sync</code> configuration key, SFTPGo will try to delete the uploaded file and return an error to the client if the hook fails. A hook is considered failed if the external command completes with a non-zero exit status or the HTTP notification response code is other than <code>200</code> (or the HTTP endpoint cannot be reached or times out). After a hook failure, the uploaded size is removed from the quota if SFTPGo is able to remove the file.</p>"},{"location":"custom-actions/#provider-events","title":"Provider events","text":"<p>The <code>actions</code> struct inside the <code>data_provider</code> configuration section allows you to configure actions on data provider objects add, update, delete.</p> <p>The supported object types are:</p> <ul> <li><code>user</code></li> <li><code>folder</code></li> <li><code>group</code></li> <li><code>admin</code></li> <li><code>api_key</code></li> <li><code>share</code></li> <li><code>event_action</code></li> <li><code>event_rule</code></li> </ul> <p>Actions will not be fired for internal updates, such as the last login or the user quota fields, or after external authentication.</p> <p>If the <code>hook</code> defines a path to an external program, then this program can read the following environment variables:</p> <ul> <li><code>SFTPGO_PROVIDER_ACTION</code>, supported values are <code>add</code>, <code>update</code>, <code>delete</code></li> <li><code>SFTPGO_PROVIDER_OBJECT_TYPE</code>, affected object type</li> <li><code>SFTPGO_PROVIDER_OBJECT_NAME</code>, unique identifier for the affected object, for example username or key id</li> <li><code>SFTPGO_PROVIDER_USERNAME</code>, the admin username that executed the action. There are two special usernames: <code>__self__</code> identifies a user/admin that updates itself and <code>__system__</code> identifies an action that does not have an explicit executor associated with it, for example users/admins can be added/updated by loading them from initial data</li> <li><code>SFTPGO_PROVIDER_IP</code>, the action was executed from this IP address</li> <li><code>SFTPGO_PROVIDER_ROLE</code>, the action was executed by an admin with this role</li> <li><code>SFTPGO_PROVIDER_TIMESTAMP</code>, event timestamp as nanoseconds since epoch</li> <li><code>SFTPGO_PROVIDER_OBJECT</code>, object serialized as JSON with sensitive fields removed</li> </ul> <p>Global environment variables are cleared, for security reasons, when the script is called. You can set additional environment variables in the \"command\" configuration section. The program must finish within 15 seconds.</p> <p>If the <code>hook</code> defines an HTTP URL then this URL will be invoked as HTTP POST. The action, username, ip, object_type and object_name and timestamp and role are added to the query string, for example <code>&lt;hook&gt;?action=update&amp;username=admin&amp;ip=127.0.0.1&amp;object_type=user&amp;object_name=user1&amp;timestamp=1633860803249</code>, and the full object is sent serialized as JSON inside the POST body with sensitive fields removed. The role is added only if not empty.</p> <p>The HTTP hook will use the global configuration for HTTP clients and will respect the retry, TLS and headers configurations. See the HTTP Clients (<code>http</code>) section of the config reference.</p> <p>The structure for SFTPGo objects can be found within the OpenAPI schema.</p>"},{"location":"custom-actions/#pubsub-services","title":"Pub/Sub services","text":"<p>You can forward SFTPGo events to several publish/subscribe systems using the sftpgo-plugin-pubsub. The notifiers SFTPGo plugins are not suitable for interactive actions such as <code>pre-*</code> events. Their scope is to simply forward events to external services. A custom hook is a better choice if you need to react to <code>pre-*</code> events.</p>"},{"location":"custom-actions/#database-services","title":"Database services","text":"<p>You can store SFTPGo events in database systems using the sftpgo-plugin-eventstore and you can search the stored events using the sftpgo-plugin-eventsearch.</p>"},{"location":"dare/","title":"Data At Rest Encryption","text":""},{"location":"dare/#data-at-rest-encryption-dare","title":"Data At Rest Encryption (DARE)","text":"<p>SFTPGo supports data at-rest encryption via its <code>cryptfs</code> virtual file system, in this mode SFTPGo transparently encrypts and decrypts data (to/from the local disk) on-the-fly during uploads and/or downloads, making sure that the files at-rest on the server-side are always encrypted.</p> <p>Data At Rest Encryption is supported for local filesystem, for cloud storage backends you can use their server side encryption feature.</p> <p>So, because of the way it works, as described here above, when you set up an encrypted filesystem for a user you need to make sure it points to an empty path/directory (that has no files in it). Otherwise, it would try to decrypt existing files that are not encrypted in the first place and fail.</p> <p>The SFTPGo's <code>cryptfs</code> is a tiny wrapper around sio therefore data is encrypted and authenticated using <code>AES-256-GCM</code> or <code>ChaCha20-Poly1305</code>. AES-GCM will be used if the CPU provides hardware support for it.</p> <p>The only required configuration parameter is a <code>passphrase</code>, each file will be encrypted using an unique, randomly generated secret key derived from the given passphrase using the HMAC-based Extract-and-Expand Key Derivation Function (HKDF) as defined in RFC 5869. It is important to note that the per-object encryption key is never stored anywhere: it is derived from your <code>passphrase</code> and a randomly generated initialization vector just before encryption/decryption. The initialization vector is stored with the file.</p> <p>The passphrase is stored encrypted itself according to your KMS configuration and is required to decrypt any file encrypted using an encryption key derived from it.</p> <p>The encrypted filesystem has some limitations compared to the local, unencrypted, one:</p> <ul> <li>Resuming uploads is not supported.</li> <li>Opening a file for both reading and writing at the same time is not supported and so clients that require advanced filesystem-like features such as <code>sshfs</code> are not supported too.</li> <li>Truncate is not supported.</li> <li>System commands are not supported: they will store data unencrypted.</li> </ul>"},{"location":"data-provider/","title":"Data provider management","text":""},{"location":"data-provider/#data-provider-initialization-and-management","title":"Data provider initialization and management","text":"<p>Before starting the SFTPGo server please make sure that the configured data provider is properly initialized/updated.</p> <p>For PostgreSQL, MySQL and CockroachDB providers, you need to create the configured database. For SQLite, the configured database will be automatically created at startup. Memory and bolt data providers do not require any initialization but they could require an update to the existing data after upgrading SFTPGo.</p> <p>SFTPGo will attempt to automatically detect if the data provider is initialized/updated and if not, will attempt to initialize/ update it on startup as needed.</p> <p>Alternately, you can create/update the required data provider structures yourself using the <code>initprovider</code> command.</p> <p>For example, you can simply execute the following command from the configuration directory:</p> <pre><code>sftpgo initprovider\n</code></pre> <p>Take a look at the CLI usage to learn how to specify a different configuration file:</p> <pre><code>sftpgo initprovider --help\n</code></pre> <p>You can disable automatic data provider checks/updates at startup by setting the <code>update_mode</code> configuration key to <code>1</code>.</p> <p> Please note that some data providers (e.g. MySQL and CockroachDB) do not support schema changes within a transaction, this means that you may end up with an inconsistent schema if migrations are forcibly aborted. CockroachDB doesn't support database-level locks, so make sure you don't execute migrations concurrently.</p>"},{"location":"data-provider/#upgrading","title":"Upgrading","text":"<p>SFTPGo supports upgrading from the previous release branch to the current one. Some examples for supported upgrade paths are:</p> <ul> <li>from 2.1.x to 2.2.x</li> <li>from 2.2.x to 2.3.x and so on.</li> </ul> <p>For supported upgrade paths, the data and schema are migrated automatically when SFTPGo starts, alternatively you can use the <code>initprovider</code> command before starting SFTPGo.</p> <p>So if, for example, you want to upgrade from 2.0.x to 2.2.x, you must first install version 2.1.x, update the data provider (automatically, by starting SFTPGo or manually using the <code>initprovider</code> command) and finally install the version 2.2.x. It is recommended to always install the latest available minor version, ie do not install 2.1.0 if 2.1.2 is available.</p> <p>Loading data from a provider independent JSON dump is supported from the previous release branch to the current one too. After upgrading SFTPGo it is advisable to regenerate the JSON dump from the new version.</p>"},{"location":"data-provider/#downgrading","title":"Downgrading","text":"<p>If you need to downgrade SFTPGo to a previous version, simply replacing the binary is not enough. You must also revert the database schema and data to make them compatible with the older version.</p> <p>Newer versions of SFTPGo often introduce changes to the data provider (database), such as new tables or columns. Older binaries do not know how to handle these changes and will fail to start if the database schema version is higher than what they expect.</p> <p>To handle this, you can use the <code>revertprovider</code> command.</p> <p> Before proceeding, strictly backup your database. You can also create a database-independent backup (JSON format) from the \"Maintenance\" section of the WebAdmin or using the REST API. Downgrading the schema involves dropping tables or columns added in the newer version, resulting in irreversible data loss for those specific fields.</p>"},{"location":"data-provider/#how-to-use-revertprovider","title":"How to use revertprovider","text":"<p>You must execute this command before uninstalling the current (newer) version of SFTPGo. The current binary contains the logic necessary to revert the changes it applied.</p> <p>Run the command from your configuration directory:</p> <pre><code>sftpgo revertprovider --to-version &lt;VERSION_NUMBER&gt;\n</code></pre> <p>You can verify the command options and defaults using:</p> <pre><code>sftpgo revertprovider --help\n</code></pre>"},{"location":"data-provider/#schema-versions","title":"Schema Versions","text":"<p>The <code>--to-version</code> parameter accepts an integer representing the internal schema version you want to target. The current schema version is 34.</p> <p>Here are the supported target versions for downgrading:</p> <ul> <li>34 (Current): The latest schema version.</li> <li>33 (v2.7.x): Default value. Target this version to downgrade to v2.7.x.</li> <li>30, 31, 32 (Intermediate): Intermediate schema versions between v2.6.x and v2.7.x.</li> <li>29 (v2.6.x): Target this version to downgrade to v2.6.x.</li> </ul>"},{"location":"data-provider/#example","title":"Example","text":"<p>If you are currently running the latest version (Schema 34) and want to downgrade to v2.6.x, you must revert the database schema to version 29.</p> <ul> <li>Stop the SFTPGo service.</li> <li>Run the revert command:</li> </ul> <pre><code>sftpgo revertprovider --to-version 29\n</code></pre> <ul> <li>Uninstall the current SFTPGo binary.</li> <li>Install SFTPGo v2.6.x.</li> <li>Start the service.</li> </ul> <p>Note: The <code>revertprovider</code> command is not supported (and not needed) for the memory provider, as data is not persisted.</p> <p>Support Policy: Please note that we officially support only the current release branch and the main branch. If you are downgrading because you found a bug, we strongly encourage you to report the issue so we can fix it, rather than reverting to an older, unsupported version.</p>"},{"location":"defender/","title":"Brute force protection","text":""},{"location":"defender/#defender","title":"Defender","text":"<p>The built-in <code>defender</code> allows you to configure an auto-blocking policy for SFTPGo and thus helps to prevent DoS (Denial of Service) and brute force password guessing.</p> <p>If enabled it will protect SFTP, HTTP, FTP and WebDAV services and it will automatically block hosts (IP addresses) that continually fail to log in or attempt to connect.</p> <p>You can configure a score for the following events:</p> <ul> <li><code>score_valid</code>, defines the score for valid login attempts, eg. user accounts that exist. Default <code>1</code>.</li> <li><code>score_invalid</code>, defines the score for invalid login attempts, eg. non-existent user accounts. Default <code>2</code>.</li> <li><code>score_no_auth</code>, defines the score for clients disconnected without any authentication attempt. Default <code>0</code>.</li> <li><code>score_limit_exceeded</code>, defines the score for hosts that exceeded the configured rate limits or the configured max connections per host. Default <code>3</code>.</li> </ul> <p>You can set the score to <code>0</code> to not penalize some events.</p> <p>And then you can configure:</p> <ul> <li><code>observation_time</code>, defines the time window, in minutes, for tracking client errors.</li> <li><code>threshold</code>, defines the threshold value before banning a host.</li> <li><code>ban_time</code>, defines the time to ban a client, as minutes</li> </ul> <p>So a host is banned, for <code>ban_time</code> minutes, if the sum of the scores has exceeded the defined threshold during the last observation time minutes.</p> <p>By defining the scores, each type of event can be weighted. Let's see an example: if <code>score_invalid</code> is 3 and <code>threshold</code> is 8, a host will be banned after 3 login attempts with an non-existent user within the configured <code>observation_time</code>.</p> <p>A banned IP has no score, it makes no sense to accumulate host events in memory for an already banned IP address.</p> <p>If an already banned client tries to log in again, its ban time will be incremented according the <code>ban_time_increment</code> configuration.</p> <p>The <code>ban_time_increment</code> is calculated as percentage of <code>ban_time</code>, so if <code>ban_time</code> is 30 minutes and <code>ban_time_increment</code> is 50 the host will be banned for additionally 15 minutes. You can also specify values greater than 100 for <code>ban_time_increment</code> if you want to increase the penalty for already banned hosts.</p> <p>SFTPGo can store host scores and banned hosts in memory or within the configured data provider according to the <code>driver</code> set in the <code>defender</code> configuration section. The available drivers are <code>memory</code> and <code>provider</code>. The <code>provider</code> driver is useful if you want to share the defender data across multiple SFTPGo instances and it requires a shared or distributed data provider: <code>MySQL</code>, <code>PostgreSQL</code> and <code>CockroachDB</code> are supported. If you set the <code>provider</code> driver, the defender implementation may do many database queries (at least one query every time a new client connects to check if it is banned), if you have a single SFTPGo instance the <code>memory</code> driver is recommended.</p> <p>For the <code>memory</code> driver, you can limit the memory usage using the <code>entries_soft_limit</code> and <code>entries_hard_limit</code> configuration keys.</p> <p>The <code>provider</code> driver will periodically clean up expired hosts and events.</p> <p>Using the WebAdmin UI or REST API you can:</p> <ul> <li>list hosts within the defender's lists</li> <li>remove hosts from the defender's lists</li> </ul> <p>The <code>defender</code> can also check permanent block and safe lists of IP addresses/networks. You can define these lists using the WebAdmin UI or the REST API. In multi-nodes setups, the list entries propagation between nodes may take some minutes.</p> <p>The <code>defender</code> also allow to delay reporting failed authentications as a way to slow down password guessing attempts.</p>"},{"location":"docker/","title":"Docker","text":""},{"location":"docker/#docker","title":"Docker","text":"<p>SFTPGo Enterprise is accessible through our Docker repository: <code>registry.sftpgo.com/sftpgo</code></p>"},{"location":"docker/#latest-tags","title":"Latest tags","text":"<ul> <li>registry.sftpgo.com/sftpgo/sftpgo:v2.7.20260120</li> <li>registry.sftpgo.com/sftpgo/sftpgo:v2.7.20260120-plugins</li> <li>registry.sftpgo.com/sftpgo/sftpgo:v2.7.20260120-distroless</li> <li>registry.sftpgo.com/sftpgo/sftpgo:v2.7.20260120-distroless-plugins</li> </ul>"},{"location":"docker/#how-to-use-the-sftpgo-image","title":"How to use the SFTPGo image","text":""},{"location":"docker/#start-a-sftpgo-server-instance","title":"Start a <code>sftpgo</code> server instance","text":"<p>Starting a SFTPGo instance is simple:</p> <pre><code>docker run --name some-sftpgo -p 8080:8080 -p 2022:2022 -d \"registry.sftpgo.com/sftpgo/sftpgo:&lt;tag&gt;\"\n</code></pre> <p>... where <code>some-sftpgo</code> is the name you want to assign to your container, and <code>tag</code> is the tag specifying the SFTPGo version you want. See the list above for relevant tags.</p> <p>Now visit http://localhost:8080/web/admin, replacing <code>localhost</code> with the appropriate IP address if SFTPGo is not reachable on localhost, create the first admin and a new SFTPGo user. The SFTP service is available on port 2022.</p> <p>If you don't want to persist any files, for example for testing purposes, you can run an SFTPGo instance like this:</p> <pre><code>docker run --rm --name some-sftpgo -p 8080:8080 -p 2022:2022 -d \"registry.sftpgo.com/sftpgo/sftpgo:&lt;tag&gt;\"\n</code></pre>"},{"location":"docker/#container-shell-access-and-viewing-sftpgo-logs","title":"Container shell access and viewing SFTPGo logs","text":"<p>The docker exec command allows you to run commands inside a Docker container. The following command line will give you a shell inside your <code>sftpgo</code> container:</p> <pre><code>docker exec -it some-sftpgo sh\n</code></pre> <p>The logs are available through Docker's container log:</p> <pre><code>docker logs some-sftpgo\n</code></pre>"},{"location":"docker/#container-graceful-shutdown","title":"Container graceful shutdown","text":"<pre><code>docker run --name some-sftpgo \\\n    -p 2022:2022 \\\n    -e SFTPGO_GRACE_TIME=32 \\\n    -d \"registry.sftpgo.com/sftpgo/sftpgo:&lt;tag&gt;\"\n</code></pre> <p>Setting the <code>SFTPGO_GRACE_TIME</code> environment variable to a non zero value when creating or running a container will enable a graceful shutdown period in seconds that will allow existing connections to hopefully complete before being forcibly closed when the time has passed.</p> <p>While the SFTPGo container is in graceful shutdown mode waiting for the last connection(s) to finish, no new connections will be allowed.</p> <p>If no connections are active or <code>SFTPGO_GRACE_TIME=0</code> (default value if unset) the container will shutdown immediately.</p> <p> The default docker grace time is 10 seconds, so if your SFTPGO_GRACE_TIME is larger than the docker grace time, then any <code>docker stop some-sftpgo</code> command will terminate your container once the docker grace time has passed. To ensure that the full SFTPGO_GRACE_TIME can be used, you can send a SIGINT or SIGTERM signal. Those signals can be sent using one of these commands: <code>docker kill --signal=SIGINT some-sftpgo</code> or <code>docker kill --signal=SIGTERM some-sftpgo</code>. Alternatively you can increase the default docker grace time to a value larger than your SFTPGO_GRACE_TIME. The default docker grace time can either be specified at creation/run time using <code>--stop-timeout &lt;value&gt;</code> or you can simply add <code>--time &lt;value&gt;</code> to the docker stop command like in this 60 seconds example <code>docker stop --time 60 some-sftpgo</code>.</p>"},{"location":"docker/#where-to-store-data","title":"Where to Store Data","text":"<p>Important note: There are several ways to store data used by applications that run in Docker containers. We encourage users of the SFTPGo images to familiarize themselves with the options available, including:</p> <ul> <li>Let Docker manage the storage for SFTPGo data by writing them to disk on the host system using its own internal volume management. This is the default and is easy and fairly transparent to the user. The downside is that the files may be hard to locate for tools and applications that run directly on the host system, i.e. outside containers.</li> <li>Create a data directory on the host system (outside the container) and mount this to a directory visible from inside the container. This places the SFTPGo files in a known location on the host system, and makes it easy for tools and applications on the host system to access the files. The downside is that the user needs to make sure that the directory exists, and that e.g. directory permissions and other security mechanisms on the host system are set up correctly. The SFTPGo image runs using <code>1000</code> as UID/GID by default.</li> </ul> <p>The Docker documentation is a good starting point for understanding the different storage options and variations, and there are multiple blogs and forum postings that discuss and give advice in this area. We will simply show the basic procedure here for the latter option above:</p> <ol> <li>Create a data directory on a suitable volume on your host system, e.g. <code>/my/own/sftpgodata</code>. The user with ID <code>1000</code> must be able to write to this directory. Please note that you don't need an actual user with ID <code>1000</code> on your host system: <code>chown -R 1000:1000 /my/own/sftpgodata</code> is enough even if there is no user/group with UID/GID <code>1000</code>.</li> <li>Create a home directory for the sftpgo container user on your host system e.g. <code>/my/own/sftpgohome</code>. As with the data directory above, make sure that the user with ID <code>1000</code> can write to this directory: <code>chown -R 1000:1000 /my/own/sftpgohome</code></li> <li>Start your SFTPGo container like this:</li> </ol> <pre><code>docker run --name some-sftpgo \\\n    -p 8080:8080 \\\n    -p 2022:2022 \\\n    --mount type=bind,source=/my/own/sftpgodata,target=/srv/sftpgo \\\n    --mount type=bind,source=/my/own/sftpgohome,target=/var/lib/sftpgo \\\n    -d \"registry.sftpgo.com/sftpgo/sftpgo:&lt;tag&gt;\"\n</code></pre> <p>As you can see SFTPGo uses two main volumes:</p> <ul> <li><code>/srv/sftpgo</code> to handle persistent data. The default home directory for SFTP/FTP/WebDAV users is <code>/srv/sftpgo/data/&lt;username&gt;</code>. Backups are stored in <code>/srv/sftpgo/backups</code></li> <li><code>/var/lib/sftpgo</code> is the home directory for the sftpgo system user defined inside the container. This is the container working directory too, host keys will be created here when using the default configuration.</li> </ul> <p>If you want to get fine grained control, you can also mount <code>/srv/sftpgo/data</code> and <code>/srv/sftpgo/backups</code> as separate volumes instead of mounting <code>/srv/sftpgo</code>.</p>"},{"location":"docker/#configuration","title":"Configuration","text":"<p>The runtime configuration can be customized via environment variables that you can set passing the <code>-e</code> option to the <code>docker run</code> command or inside the <code>environment</code> section if you are using docker stack deploy or docker-compose.</p> <p>Refer to the documentation to learn how to configure SFTPGo using environment variables.</p> <p>Alternately you can mount your custom configuration file to <code>/var/lib/sftpgo</code> or <code>/var/lib/sftpgo/.config/sftpgo</code>.</p>"},{"location":"docker/#running-as-an-arbitrary-user","title":"Running as an arbitrary user","text":"<p>The SFTPGo image runs using <code>1000</code> as UID/GID by default. If you know the permissions of your data and/or configuration directory are already set appropriately or you have need of running SFTPGo with a specific UID/GID, it is possible to invoke this image with <code>--user</code> set to any value (other than <code>root/0</code>) in order to achieve the desired access/configuration:</p> <pre><code>$ ls -lnd data\ndrwxr-xr-x 2 1100 1100 6  7 nov 09.09 data\n$ ls -lnd config\ndrwxr-xr-x 2 1100 1100 6  7 nov 09.19 config\n</code></pre> <p>With the above directory permissions, you can start a SFTPGo instance like this:</p> <pre><code>docker run --name some-sftpgo \\\n    --user 1100:1100 \\\n    -p 8080:8080 \\\n    -p 2022:2022 \\\n    --mount type=bind,source=\"${PWD}/data\",target=/srv/sftpgo \\\n    --mount type=bind,source=\"${PWD}/config\",target=/var/lib/sftpgo \\\n    -d \"registry.sftpgo.com/sftpgo/sftpgo:&lt;tag&gt;\"\n</code></pre> <p>Alternately build your own image using the official one as a base, here is a sample Dockerfile:</p> <pre><code>FROM registry.sftpgo.com/sftpgo/sftpgo:&lt;tag&gt;\nUSER root\nRUN chown -R 1100:1100 /etc/sftpgo &amp;&amp; chown 1100:1100 /var/lib/sftpgo /srv/sftpgo\nUSER 1100:1100\n</code></pre>"},{"location":"docker/#image-variants","title":"Image Variants","text":"<p>The <code>sftpgo</code> images comes in many flavors, each designed for a specific use case.</p>"},{"location":"docker/#sftpgoversion","title":"<code>sftpgo:&lt;version&gt;</code>","text":"<p>This is the defacto image, it is based on Debian, available in the <code>debian</code> official image. If you are unsure about what your needs are, you probably want to use this one.</p>"},{"location":"docker/#sftpgoversion-plugins","title":"<code>sftpgo:&lt;version&gt;-plugins</code>","text":"<p>These tags provide the standard image with the addition of plugins installed in <code>/usr/local/bin</code>.</p>"},{"location":"docker/#sftpgoversion-distroless","title":"<code>sftpgo:&lt;version&gt;-distroless</code>","text":"<p>This image is based on the popular Distroless project. We use the latest Debian based distroless image as base.</p> <p>Distroless variant contains only a statically linked sftpgo binary and its minimal runtime dependencies and so it doesn't allow shell access (no shell is installed). SQLite support is disabled since it requires CGO and so a C runtime which is not installed. The default data provider is <code>bolt</code>, all the supported data providers except <code>sqlite</code> work.</p>"},{"location":"docker/#sftpgoversion-distroless-plugins","title":"<code>sftpgo:&lt;version&gt;-distroless-plugins</code>","text":"<p>These tags provide the distroless image with the addition of open source and proprietary plugins installed in <code>/usr/local/bin</code>.</p>"},{"location":"docker/#helm-chart","title":"Helm Chart","text":"<p>An helm chart is available. You can customize the Docker image to use in the <code>values.yaml</code>.</p>"},{"location":"dynamic-user-mod/","title":"Dynamic user creation or modification","text":""},{"location":"dynamic-user-mod/#dynamic-user-creation-or-modification","title":"Dynamic user creation or modification","text":"<p>Dynamic user creation or modification is supported via an external program or an HTTP URL that can be invoked just before the user login. To enable dynamic user modification, you must set the absolute path of your program or an HTTP URL using the <code>pre_login_hook</code> key in your configuration file.</p> <p>The external program can read the following environment variables to get info about the user trying to login:</p> <ul> <li><code>SFTPGO_LOGIND_USER</code>, it contains the user trying to login serialized as JSON. A JSON serialized user id equal to zero means the user does not exist inside SFTPGo</li> <li><code>SFTPGO_LOGIND_METHOD</code>, possible values are: <code>password</code>, <code>publickey</code>, <code>keyboard-interactive</code>, <code>TLSCertificate</code>, <code>IDP</code> (external identity provider) or empty if the hook is executed after receiving the FTP <code>USER</code> command</li> <li><code>SFTPGO_LOGIND_IP</code>, ip address of the user trying to login</li> <li><code>SFTPGO_LOGIND_PROTOCOL</code>, possible values are <code>SSH</code>, <code>FTP</code>, <code>DAV</code>, <code>HTTP</code>, <code>OIDC</code> (OpenID Connect)</li> </ul> <p>The program must write, on its standard output:</p> <ul> <li>an empty string (or no response at all) if the user should not be created/updated</li> <li>or the SFTPGo user, JSON serialized, if you want to create or update the given user</li> </ul> <p>If the hook is an HTTP URL then it will be invoked as HTTP POST. The login method, the used protocol and the ip address of the user trying to login are added to the query string, for example <code>&lt;http_url&gt;?login_method=password&amp;ip=1.2.3.4&amp;protocol=SSH</code>. The request body will contain the user trying to login serialized as JSON. If no modification is needed the HTTP response code must be 204, otherwise the response code must be 200 and the response body a valid SFTPGo user serialized as JSON.</p> <p>Actions defined for user's updates will not be executed in this case and an already logged in user with the same username will not be disconnected, you have to handle these things yourself.</p> <p>The program hook must finish within 30 seconds, the HTTP hook will use the global configuration for HTTP clients.</p> <p>If an error happens while executing the hook then login will be denied.</p> <p>\"Dynamic user creation or modification\" and \"External Authentication\" are mutually exclusive, they are quite similar, the difference is that \"External Authentication\" returns an already authenticated user while using \"Dynamic users modification\" you simply create or update a user. The authentication will be checked inside SFTPGo. In other words while using \"External Authentication\" the external program receives the credentials of the user trying to login (for example the cleartext password) and it needs to validate them. While using \"Dynamic users modification\" the pre-login program receives the user stored inside the dataprovider (it includes the hashed password if any) and it can modify it, after the modification SFTPGo will check the credentials of the user trying to login.</p> <p>For SFTPGo users (not admins) authenticating using an external identity provider such as OpenID Connect, the pre-login hook will be executed after a successful authentication against the external IDP so that you can create/update the SFTPGo user matching the one authenticated against the identity provider. In this case where the pre-login hook is executed even if an external authentication hook is defined.</p> <p>If you enable FTP and allow both encrypted and plain text sessions, the pre-login hook is executed after receiving the FTP <code>USER</code> command. If you return an SFTPGo user with <code>ftp_security</code> set to <code>1</code> and the FTP session is not encrypted, it will be terminated. In this case where the pre-login hook is executed even if an external authentication hook is defined.</p> <p>You can disable the hook on a per-user basis.</p> <p>The structure for SFTPGo users can be found within the OpenAPI schema.</p>"},{"location":"env-vars/","title":"Environment variables","text":""},{"location":"env-vars/#environment-variables","title":"Environment variables","text":"<p>The configuration file can change between different versions and merging your custom settings with the default configuration file, after updating SFTPGo, may be time-consuming. For this reason we suggest to set your custom settings using environment variables. This eliminates the need to merge your changes with the default configuration file after each update, you have to just check that your custom configuration keys still exists.</p> <p>You can override all the available configuration options using environment variables.</p>"},{"location":"env-vars/#syntax","title":"Syntax","text":"<p>SFTPGo will check for environment variables with a name matching the key uppercased and prefixed with <code>SFTPGO_</code>. Use <code>__</code> to traverse into a struct. For example:</p> <ul> <li>To set <code>common.proxy_protocol</code> to <code>1</code>, define the env var <code>SFTPGO_COMMON__PROXY_PROTOCOL</code> with value <code>1</code>.</li> <li>To set <code>webdavd.cors.enabled</code> to <code>true</code>, define the env var <code>SFTPGO_WEBDAVD__CORS__ENABLED</code> with value <code>true</code>.</li> </ul> <p>For options that are list-like, use the following syntax depending on the item type:</p> <p>If the option is a list of simple values (booleans, numbers, strings), the list items should be comma-separated. For example:</p> <ul> <li>To set <code>common.actions.execute_on</code> to <code>[\"upload\", \"download\"]</code>, define the env var <code>SFTPGO_COMMON__ACTIONS__EXECUTE_ON</code> with value <code>upload,download</code>.</li> <li>To set <code>common.event_manager.enabled_commands</code> to <code>[\"/usr/bin/touch\", \"/usr/bin/mkdir\", \"/usr/bin/rm\"]</code>, define the env var <code>SFTPGO_COMMON__EVENT_MANAGER__ENABLED_COMMANDS</code> with value <code>/usr/bin/touch,/usr/bin/mkdir,/usr/bin/rm</code>.</li> </ul> <p>If the option is a list of structs, set each struct field with separate env vars, using the list index as the key to traverse into each item struct. For example:</p> <ul> <li>To set <code>sftpd.bindings[0].port</code> to <code>22</code>, define the env var <code>SFTPGO_SFTPD__BINDINGS__0__PORT</code> with value <code>22</code>.</li> <li>To set <code>command.commands</code> to <code>[{\"path\": \"/usr/bin/date\"}, {\"path: \"/usr/bin/ping\", \"args\": [\"-c5\", \"example.com\"]}]</code>, define the env vars:<ul> <li><code>SFTPGO_COMMAND__COMMANDS__0__PATH</code> with value <code>/usr/bin/date</code>,</li> <li><code>SFTPGO_COMMAND__COMMANDS__1__PATH</code> with value <code>/usr/bin/ping</code>, and</li> <li><code>SFTPGO_COMMAND__COMMANDS__1__ARGS</code> with value <code>-c5,example.com</code>.</li> </ul> </li> </ul> <p>Notice how <code>command.commands[1].args</code> is itself a list of strings, so the value of <code>SFTPGO_COMMAND__COMMANDS__1__ARGS</code> is a comma-separated list.</p>"},{"location":"env-vars/#variable-sources","title":"Variable sources","text":"<p>Setting configuration options from environment variables is natural in Docker/Kubernetes. If you install SFTPGo on Linux using the official deb/rpm packages you can set your custom environment variables in the file <code>/etc/sftpgo/sftpgo.env</code> (create this file if it does not exist, it is defined as <code>EnvironmentFile</code> in the SFTPGo systemd unit). SFTPGo also reads files inside the <code>env.d</code> directory relative to config dir and then exports the valid variables into environment variables if they are not already set. With this method you can override any configuration options, set environment variables for SFTPGo plugins but you cannot set command flags because these files are read after that SFTPGo starts and the config dir must already be set. Of course you can also set environment variables with the method provided by the operating system of your choice.</p> <p>The following escaping rules apply to environment variable files in the <code>env.d</code> directory:</p> <ul> <li>If you use single quotes nothing is escaped.</li> <li>If you use double quotes you can escape characters using a backslash (<code>\\</code>). <code>$</code> has special meaning and tries to expand to another environment variable if not escaped.</li> </ul> <p>Suppose you want to set the dataprovider password to <code>my$secret\\pwd</code>, you can use one of the following formats:</p> <ul> <li><code>SFTPGO_DATA_PROVIDER__PASSWORD='my$secret\\pwd'</code>.</li> <li><code>SFTPGO_DATA_PROVIDER__PASSWORD=\"my\\$secret\\\\pwd\"</code>.</li> </ul>"},{"location":"env-vars/#additional-environment-variables","title":"Additional environment variables","text":"<p>Some additional environment variables are available:</p> <ul> <li><code>SFTPGO_HOOK__MEMORY_PIPES__ENABLED</code> set to <code>1</code> to enable memory pipes. This allows fully in-memory transfers to and from cloud storage backends, eliminating the need for temporary disk files.</li> <li><code>SFTPGO_HOOK__WEBCLIENT_DISABLE_PREVIEW</code>, set to <code>1</code> to disable file preview in the WebClient UI.</li> <li><code>SFTPGO_HOOK__WEBCLIENT_DISABLE_EDITOR</code>, set to <code>1</code> to disable the built-in text editor in the WebClient UI.</li> <li><code>SFTPGO_HOOK__S3_CHECK_PARENT_DIR</code>, set to <code>1</code> to prevent uploads to non-existent directories when using S3 backends, emulating the behavior of a local filesystem. By default, uploads to non-existent directories are allowed on cloud storage backends due to their flat structure.</li> <li><code>SFTPGO_HOOK__GCS_CHECK_PARENT_DIR</code>, set to <code>1</code> to prevent uploads to non-existent directories when using Google Cloud Storage backends.</li> <li><code>SFTPGO_HOOK__AZBLOB_CHECK_PARENT_DIR</code>, set to <code>1</code> to prevent uploads to non-existent directories when using Azure Blob Storage backends.</li> <li><code>SFTPGO_HOOK__EXTRACT_MAX_COMPRESSION_RATIO</code>, sets the maximum allowed compression ratio for extracted ZIP files. Default: <code>60</code>.</li> <li><code>SFTPGO_HOOK__EXTRACT_MAX_FILES</code>, sets the maximum number of files allowed in a ZIP archive. Default: <code>1000</code>.</li> <li><code>SFTPGO_HOOK__EXTRACT_MAX_SIZE</code>, sets the maximum total uncompressed size allowed for a ZIP archive in MB. Default: <code>1024</code>.</li> <li><code>SFTPGO_HOOK__PASSWORD_EXPIRATION_EMAIL_SUBJECT</code>, allows customizing the subject line of the password expiration notification email. Default: <code>SFTPGo password expiration notification</code>.</li> <li><code>SFTPGO_HOOK__PASSWORD_FORGOT_EMAIL_SUBJECT</code>, allows customizing the subject line of the \u201cforgot password\u201d email sent to users. Default: <code>Email Verification Code for &lt;username&gt;</code>.</li> <li><code>SFTPGO_HOOK__SHARE_CODE_EMAIL_SUBJECT</code>, allows customizing the subject line of emails containing share codes for shares. Default: <code>Share access code</code>.</li> <li><code>SFTPGO_HOOK__DISABLE_DOT_ENTRIES</code>, set to <code>1</code> to hide <code>.</code> and <code>..</code> entries from SFTP directory listings.</li> <li><code>SFTPGO_HOOK__OAUTH2_DISABLE_PKCE</code>, set to <code>1</code> to disable PKCE for OAuth2 authentication flows used by IMAP and SMTP.</li> <li><code>SFTPGO_HOOK__HAS_SHARE_LEGAL_AGREEMENT</code>, set to <code>1</code> to display a legal agreement can be displayed before granting access to the share by external users.</li> <li><code>SFTPGO_HOOK_SHARE_LEGAL_TMPL_PATH</code>, set to the path of a custom HTML template for the share agreement. We recommend using the default template as a starting point, which is typically located at <code>/usr/share/sftpgo/templates/webclient/sharelegal.html</code> or an equivalent path depending on the installation method.</li> <li><code>SFTPGO_HOOK__ENABLE_OIDC_UI</code>, set to 1 to add the OpenID Connect configuration section for the first binding in the WebAdmin UI. If more than an OpenID Connect configuration is required, use the configuration file or environment variables to override it instead.</li> <li><code>SFTPGO_HOOK__HTTPD_MAX_REQUEST_SIZE</code>. Allows configuring the maximum size of HTTP requests in MB. Default: 1 MB.  Increasing this value may expose the server to large payloads, which can impact memory usage or allow denial-of-service attacks.</li> <li><code>SFTPGO_HOOK__HTTPD_MAX_RESTORE_SIZE</code>. Allows configuring the maximum size of a backup to restore in MB. Default: 20 MB.</li> <li><code>SFTPGO_HOOK__AUTO_FOLDERS</code>. Set to <code>1</code> to automatically create virtual folders based on the reply from pre-login and pre-auth hooks. This will cause a database upsert for each returned folder.</li> </ul>"},{"location":"eventmanager/","title":"Event Manager","text":""},{"location":"eventmanager/#event-manager","title":"Event Manager","text":"<p>The EventManager is a powerful feature that enables administrators to define automated responses based on specific events occurring within the system (e.g., file uploads, user creation, scheduled tasks, and more).</p> <p>Rules are the conditions that determine when an action should be executed. Each rule specifies:</p> <ul> <li>Which event(s) it applies to (e.g., file uploaded, file downloaded, etc.)</li> <li>Filters to narrow down the triggering events (e.g., only for a particular user or directory)</li> <li>Which action(s) to execute when the rule matches</li> </ul> <p>Think of a rule as a \"when this happens, and these conditions are met, then do that\" type of logic.</p> <p>Actions are the tasks performed when a rule is triggered. These actions can be dynamically customized using placeholders\u2014variables that represent contextual data related to the event (such as file name, username, or file size). To further tailor these values, SFTPGo provides helper functions that format or transform placeholders directly within your action templates.</p>"},{"location":"eventmanager/#rules","title":"Rules","text":"<p>Event rules are based on the premise that an event occours. To each rule you can associate one or more actions. The following trigger events are supported:</p> <ul> <li><code>Filesystem events</code>, for example <code>upload</code>, <code>download</code> etc.</li> <li><code>Provider events</code>, for example <code>add</code>, <code>update</code>, <code>delete</code> user or other resources.</li> <li><code>Schedules</code>. The scheduler uses UTC time.</li> <li><code>IP Blocked</code>, this event can be generated if you enable the defender.</li> <li><code>Certificate</code>, this event is generated when a certificate is renewed using the built-in ACME protocol. Both successful and failed renewals are notified.</li> <li><code>On demand</code>, this trigger is generated manually using the WebAdmin or the REST API.</li> <li><code>Identity Provider login</code>, this trigger is generated when a user/admin logs in using an external Identity Provider.</li> </ul> <p>You can further restrict a rule by specifying additional conditions that must be met before the rule\u2019s actions are taken. For example you can react to uploads only if they are performed by a particular user or using a specified protocol.</p> <p>Actions such as user quota reset, transfer quota reset, data retention check, folder quota reset and filesystem events are executed for all matching users if the trigger is a schedule or for the affected user if the trigger is a provider event or a filesystem action.</p> <p>Actions are executed in a sequential order except for sync actions that are executed before the others. For each action associated to a rule you can define the following settings:</p> <ul> <li><code>Stop on failure</code>, the next action will not be executed if the current one fails.</li> <li><code>Failure action</code>, this action will be executed only if at least another one fails.  Please note that a failure action isn't executed if the event fails, for example if a download fails the main action is executed. The failure action is executed only if one of the non-failure actions associated to a rule fails.</li> <li><code>Execute sync</code>, for upload events, you can execute the action(s) synchronously. Executing an action synchronously means that SFTPGo will not return a result code to the client (which is waiting for it) until your action have completed its execution. If your acion takes a long time to complete this could cause a timeout on the client side, which wouldn't receive the server response in a timely manner and eventually drop the connection. For pre-* events at least a sync action is required. If pre-delete,pre-upload, pre-download sync action(s) completes successfully, SFTPGo will allow the operation, otherwise the client will get a permission denied error.</li> </ul> <p>If you are running multiple SFTPGo instances connected to the same data provider, you can choose whether to allow simultaneous execution for scheduled actions.</p> <p>Some actions are not supported for some triggers, rules containing incompatible actions are skipped at runtime:</p> <ul> <li><code>Filesystem events</code>, folder quota reset cannot be executed, we don't have a direct way to get the affected folder.</li> <li><code>Provider events</code>, user quota reset, transfer quota reset, data retention check and filesystem actions can be executed only if  a user is updated. They will be executed for the affected user. Folder quota reset can be executed only for folders. Filesystem actions are not executed for <code>delete</code> user events because the actions is executed after the user deletion.</li> <li><code>IP Blocked</code>, user quota reset, folder quota reset, transfer quota reset, data retention check and filesystem actions cannot be executed, we only have an IP.</li> <li><code>Certificate</code>, user quota reset, folder quota reset, transfer quota reset, data retention check and filesystem actions cannot be executed.</li> <li><code>Email with attachments</code> are supported for filesystem events and provider events if a user is added/updated. We need a user to get the files to attach.</li> <li><code>HTTP multipart requests with files as attachments</code> are supported for filesystem events and provider events if a user is added/updated. We need a user to get the files to attach.</li> </ul>"},{"location":"eventmanager/#actions","title":"Actions","text":"<p>Supported actions:</p> <ul> <li><code>HTTP notification</code>. You can notify an HTTP/S endpoing via GET, POST, PUT, DELETE methods. You can define custom headers, query parameters and a body for POST and PUT request. Placeholders are supported for username, body, header and query parameter values.</li> <li><code>Command execution</code>. You can launch custom commands passing parameters via environment variables. Placeholders are supported for environment variable values.  Allowing any system command could pose a security risk, they are disabled by default.</li> <li><code>Email notification</code>. Placeholders are supported in subject and body. The email will be sent as plain text. For this action to work you have to configure an SMTP server in the SFTPGo configuration file.</li> <li><code>Backup</code>. A backup will be saved in the configured backup directory. The backup will contain the week day, the hour and the minute in the file name.</li> <li><code>Rotate log file</code>. If file logging is enabled, the log file will be rotated regardless of its size.</li> <li><code>User quota reset</code>. The quota used by users will be updated based on current usage.</li> <li><code>Folder quota reset</code>. The quota used by virtual folders will be updated based on current usage.</li> <li><code>Transfer quota reset</code>. The transfer quota values will be reset to <code>0</code>.</li> <li><code>Data retention check</code>. You can define per-folder retention policies.</li> <li><code>Password expiration check</code>. You can send an email notification to users whose password is about to expire.</li> <li><code>User expiration check</code>. You can receive notifications with expired users.</li> <li><code>User inactivity check</code>. Allow to disable or delete inactive users.</li> <li><code>Share expiration check</code>. Automated lifecycle management for shares based on inactivity, expiration or max tokens. You can configure an inactivity threshold, an advance notice period (to trigger events before expiration), and a grace period (soft delete). Use the Split events option to generate individual events for each share, enabling 1-to-1 notifications. For group shares, warning events are generated for all members, while the deletion event is executed for the share owner.</li> <li><code>Identity Provider account check</code>. You can create/update accounts for users/admins logging in using an Identity Provider.</li> <li><code>Filesystem</code>. For these actions, the required permissions are automatically granted. This is the same as executing the actions from an SFTP client and the same restrictions applies. Supported actions:<ul> <li><code>Rename</code>. You can rename one or more files or directories.</li> <li><code>Delete</code>. You can delete one or more files and directories.</li> <li><code>Create directories</code>. You can create one or more directories including sub-directories.</li> <li><code>Path exists</code>. Check if the specified path exists.</li> <li><code>Copy</code>. You can copy one or more files or directories.</li> <li><code>Compress</code>. You can compress (currently as zip) ore or more files and directories.</li> <li><code>Extract</code>. Allows extraction of ZIP archives. To mitigate common ZIP-based attacks, several limits are enforced, which can be adjusted via environment variables:<ul> <li>Maximum allowed compression ratio: 60.</li> <li>Maximum number of files: 1000.</li> <li>Maximum uncompressed size: 1 GB.</li> </ul> </li> <li><code>PGP</code> encryption and decryption, allowing you to secure your files using either password-based encryption or PGP key pairs. This includes the ability to sign and verify digital signatures, ensuring both the authenticity and integrity of your data throughout the process.</li> <li><code>Metadata Check</code> verifies whether a specified metadata key exists and matches a configured value, or whether it is absent. To check for non-existence, leave the value field empty. If the condition is not met, the check is retried until the specified timeout is reached (if greater than zero). This action is supported for cloud storage backends.</li> <li><code>IMAP</code>. Enables integration with IMAP mailboxes. This feature allows you to automatically fetch email attachments from IMAP mailboxes and make them available within SFTPGo, either inside a user\u2019s home directory or mapped into a virtual folder. Attachments can be periodically synchronized, enabling seamless ingestion of files delivered via email.</li> <li><code>ICAP</code>. Enables integration with ICAP servers to perform antivirus scanning and DLP checks as part of SFTPGo rules. After a file upload, the file can be streamed to an ICAP server for inspection. Depending on the scan result, different actions can be performed automatically, such as deleting the original file, moving it to a quarantine directory or virtual folder, or replacing it with the modified content returned by the ICAP server.</li> </ul> </li> </ul> <p>In actions, you can hard-code values such as file paths or email addresses. While this may work in some cases, it's generally better to use dynamic values that adapt to the specific context of the action. This is where dynamic placeholders come in. Placeholders allow you to insert values that are automatically replaced at runtime. They follow the format <code>{{.FieldName}}</code> and enable your actions to be more flexible and reusable.</p> <p>We use Go\u2019s template system under the hood. For a comprehensive overview, please refer to the official Go template documentation. If you need advanced logic, conditions and loops are supported.</p>"},{"location":"eventmanager/#placeholders","title":"Placeholders","text":"<ul> <li><code>{{.Name}}</code>. Username, virtual folder name, admin username for provider events, domain name for TLS certificate events. Format: string.</li> <li><code>{{.ExtName}}</code>: External username, set to the email address used for authenticating public shares configured with email authentication. Format: string.</li> <li><code>{{.Event}}</code>. Event name, for example <code>upload</code>, <code>download</code> for filesystem events or <code>add</code>, <code>update</code> for provider events. Format: string.</li> <li><code>{{.Status}}</code>. Status for filesystem events. 1 means no error, 2 means a generic error occurred, 3 means quota exceeded error. Format: integer.</li> <li><code>{{.Errors}}</code>. Error details. Format: list of strings.</li> <li><code>{{.VirtualPath}}</code>. Path seen by SFTPGo users, for example <code>/adir/afile.txt</code>. Format: string.</li> <li><code>{{.FsPath}}</code>. Full filesystem path, for example <code>/user/homedir/adir/afile.txt</code> or <code>C:/data/user/homedir/adir/afile.txt</code> on Windows. Format: string.</li> <li><code>{{.VirtualTargetPath}}</code>. Virtual target path for rename and copy operations. Format: string.</li> <li><code>{{.FsTargetPath}}</code>. Full filesystem target path for rename and copy operations. Format: string.</li> <li><code>{{.ObjectName}}</code>. File/directory name, for example <code>afile.txt</code>, or provider object name. For data retention actions, this represents the username of the affected user. Format: string.</li> <li><code>{{.ObjectType}}</code>. Object type for provider events: <code>user</code>, <code>group</code>, <code>admin</code> and so on. Format: string.</li> <li><code>{{.FileSize}}</code>. File size. Format: int64.</li> <li><code>{{.Elapsed}}</code>. Elapsed time as milliseconds for filesystem events. Format: int64.</li> <li><code>{{.Protocol}}</code>. Used protocol, for example <code>SFTP</code>, <code>FTP</code>. Format: string.</li> <li><code>{{.IP}}</code>. Client IP address. Format: string.</li> <li><code>{{.Role}}</code>. User or admin role. Format: string.</li> <li><code>{{.Email}}</code>. For filesystem events, this is the email associated with the user performing the action. For the provider events, this is the email associated with the affected user or admin. Blank in all other cases. Format: string.</li> <li><code>{{.Timestamp}}</code>. Event timestamp. Format: time object. A time object has several useful methods: <code>UTC</code>, <code>Local</code>, <code>Unix</code>, <code>UnixMilli</code>, <code>Year</code>, <code>Month</code>, <code>Day</code>, <code>Hour</code>, <code>Minute</code>, and <code>Second</code>.</li> <li><code>{{.UID}}</code>. Unique ID. Format: string.</li> <li><code>{{.Object}}</code>. Provider object data with sensitive fields removed. It\u2019s an object that includes a <code>JSON</code> method to get its JSON representation. For example, use <code>\"ObjectJSON\": {{.Object.JSON}}</code>. If you need the JSON as a string, use <code>\"ObjectString\": {{.Object.JSON | toJson}}</code>. This placeholder also allow to access some inner objects. The fields available for inner objects match those documented in the REST API, but use PascalCase, for example: <code>CreatedAt</code>, <code>Description</code>, and so on. The following objects can be used:<ul> <li><code>Share</code>, if the event is related to a share. For example <code>{{.Object.Share.ExpiresAt}}</code> or <code>{{.Object.Share.Scope}</code>.</li> <li><code>User</code>, if the event is related to a user.</li> <li><code>Admin</code>, if the event is related to an admin.</li> <li><code>Group</code>, if the event is related to a group.</li> </ul> </li> <li><code>{{.RetentionReports}}</code>. Data retention reports as zip compressed CSV files. Supported as email attachment, file path for multipart HTTP request and as single parameter for HTTP requests body. Data retention reports contain details on the number of files deleted and the total size deleted for each folder. Format: string</li> <li><code>{{.IDPFields}}</code>. Custom fields from the Identity Provider. Format: object. The structure depends on the specific custom claims configured in your Identity Provider.</li> <li><code>{{.Metadata}}</code>. Cloud storage metadata represented as key/value pairs, where both keys and values are strings. You can use <code>range</code> to iterate over the keys and values.</li> <li><code>{{.RetentionChecks}}</code>. List of executed retention checks. This placeholder is populated for the <code>Data retention check</code> action. Format: list of objects. Each item contains the following fields:<ul> <li><code>Username</code>, string.</li> <li><code>Email</code>, list of strings.</li> <li><code>ActionName</code> string.</li> <li><code>Type</code>, integer. Supported values: <code>0</code> (delete), <code>1</code> (archive).</li> <li><code>Results</code> list of objects, where each object represents the result for a specific folder and contains:<ul> <li><code>Path</code>, string.</li> <li><code>Retention</code>, integer (hours).</li> <li><code>DeletedFiles</code>, integer.</li> <li><code>DeletedSize</code>, integer (bytes)</li> <li><code>Elapsed</code>, integer (nanoseconds).</li> <li><code>Info</code>, string</li> <li><code>Error</code>, string</li> </ul> </li> </ul> </li> <li><code>{{.ShareExpirationChecks}}</code>. List of executed share expiration checks. This placeholder is populated for the <code>Share expiration check</code> action. Each item is an object containing two fields: <code>User</code> and <code>Results</code>. <code>Results</code> is a list of <code>ShareExpirationResult</code> objects (see <code>{{.ShareExpirationResult}}</code> below for the structure details). For the <code>User</code> struct and the <code>Share</code> struct inside <code>ShareExpirationResult</code>, the fields available match those documented in the REST API, but use PascalCase (e.g., <code>CreatedAt</code>, <code>Description</code>). Format: list of objects.</li> <li><code>{{.ShareExpirationResult}}</code>. The specific result of a share expiration check. This placeholder is available only when <code>Split events</code> is enabled for the <code>Share expiration check</code> action. In this mode, the event is triggered individually for each result, and standard placeholders like <code>{{.Name}}</code> and <code>{{.Email}}</code> are automatically updated to match the user associated with this result. The object contains the following fields:<ul> <li><code>Share</code>: The full share object. Fields match those documented in the REST API, but use PascalCase (e.g., <code>{{.ShareExpirationResult.Share.Name}}</code>, <code>{{.ShareExpirationResult.Share.UsedTokens}}</code>).</li> <li><code>Action</code>: The action taken (integer). Supported values: <code>1</code> (notify), <code>2</code> (delete).</li> <li><code>Reason</code>: The reason for the action (string). Possible values: <code>max_tokens</code>, <code>expiration_date</code>, <code>inactivity</code>.</li> <li><code>Expiration</code>: The calculated expiration time (time object).</li> </ul> </li> <li><code>{{.Shares}}</code>: A lazily populated field, rendered only for filesystem actions. It is populated with the shares associated with the path on which the filesystem action was executed. The <code>Load</code> method can be used to retrieve the shares. For example, to collect all email addresses associated with the shares where a new file is uploaded: <code>{{ range .Shares.Load }}{{ range .Options.Emails }}{{ . }},{{ end }}{{ end }}</code>.</li> </ul> <p>The <code>{{.Timestamp}}</code> time object provides several useful methods:</p> <ul> <li><code>UTC</code>: returns the time in UTC.</li> <li><code>Local</code>: returns the time in the local timezone.</li> <li><code>Unix</code>: returns the Unix timestamp in seconds.</li> <li><code>UnixMilli</code>: returns the Unix timestamp in milliseconds.</li> <li><code>Year</code>, <code>Month</code>, <code>Day</code>: return the date components.</li> <li><code>Hour</code>, <code>Minute</code>, <code>Second</code>: return the time components.</li> <li><code>Format(layout string)</code>: formats a time object using Go's layout reference <code>2006-01-02 15:04:05</code>.</li> </ul> <p>Some examples:</p> <ul> <li><code>{{ .Timestamp.Unix }}</code> returns the Unix timestamp in seconds.</li> <li>If <code>{{.Timestamp}}</code> is set to July 4, 2025 at 14:30, <code>{{ .Timestamp.Format \"2006-01-02\" }}</code> outputs <code>2025-07-04</code>, <code>{{ .Timestamp.Format \"02/01/2006 15:04\" }}</code> outputs <code>04/07/2025 14:30</code>, and <code>{{ .Timestamp.Format \"Monday, 02 Jan 2006 at 15:04\" }}</code> outputs <code>Friday, 04 Jul 2025 at 14:30</code>.</li> </ul>"},{"location":"eventmanager/#helper-functions","title":"Helper functions","text":"<p>You can use SFTPGo specific helper functions to transform or format the placeholder values. These functions allow you to do things like:</p> <ul> <li>Convert data to JSON: <code>{{ toJson .VirtualPath }}</code>.</li> <li>Format datetime: <code>{{ .Timestamp.UTC.Format \"2006-01-02T15:04:05.000\" }}</code>.</li> <li>Get the parent directory for a path: <code>{{ pathDir .VirtualPath }}</code>.</li> </ul> <p>They can be used in either of the following forms: <code>{{ toJson .VirtualPath }}</code> or <code>{{ .VirtualPath | toJson }}</code>.</p> <p>The first form calls the <code>toJson</code> function directly with <code>.VirtualPath</code> as its argument. The second form uses the pipe (<code>|</code>) operator, which passes the value on its left (<code>.VirtualPath</code>) as the input to the function on its right (<code>toJson</code>).</p> <p>The pipe syntax is particularly useful when chaining multiple functions together, allowing you to transform data step-by-step in a clear and readable way.</p> <p>Supported built-in functions:</p> <ul> <li><code>toJson</code> converts any value to its JSON representation; since <code>.VirtualPath</code> is a string, <code>{ \"path\": {{ toJson .VirtualPath }} }</code> outputs <code>{ \"path\": \"/mydir/myfile.txt\" }</code>, and since <code>.Metadata</code> is a map of strings, <code>{{ toJson .Metadata }}</code> outputs <code>{\"author\":\"alice\",\"version\":\"1.0\"}</code>. Using <code>toJson</code> ensures that strings are always correctly quoted and special characters properly escaped for safe inclusion in JSON.</li> <li><code>toJsonUnquoted</code> works like <code>toJson</code>, but if the input is a string, it returns the JSON value without the surrounding quotes; for other types it behaves like  <code>toJson</code>. This is useful when you want to concatenate a dynamic JSON string with fixed text without extra quotes. Example: <code>{ \"out_dir\": \"/basedir/{{ toJsonUnquoted .ObjectName }}\" }</code> outputs <code>{\"out_dir\": \"/basedir/myfile.txt\"}</code>.</li> <li><code>toBase64</code> converts a string value to its Base64 representation.</li> <li><code>toHex</code> converts a string value to its hexadecimal representation.</li> <li><code>urlEscape</code> encodes a string for safe use in query parameters Example: <code>{{ urlEscape .Email }}</code> outputs <code>user%40example.com</code>).</li> <li><code>urlPathEscape</code> encodes a string for safe use in URL paths. Exammple: <code>{{ urlPathEscape .VirtualPath }}</code> outputs: <code>folder%20name%2Ffile.txt</code>.</li> <li><code>pathDir</code> returns the directory part of a path. Example: if <code>.VirtualPath</code> is <code>/a/b/file.txt</code>, <code>{{ pathDir .VirtualPath }}</code> outputs <code>/a/b</code>.</li> <li><code>pathBase</code> returns the last element of a path. Example: if <code>.VirtualPath</code> is <code>/a/b/file.txt</code>, <code>{{ pathBase .VirtualPath }}</code> outputs <code>file.txt</code>.</li> <li><code>pathExt</code> returns the file extension. Example: if <code>.VirtualPath</code> is <code>/a/b/file.txt</code>, <code>{{ pathExt .VirtualPath }}</code> outputs <code>.txt</code>.</li> <li><code>pathJoin</code> joins multiple path segments into a clean path. Example: <code>{{ pathJoin (stringSlice \"/a\" .VirtualPath \"final\") }}</code> with <code>.VirtualPath</code> as <code>b/c</code> outputs <code>/a/b/c/final</code>.</li> <li><code>filePathJoin</code> joins multiple elements into a clean filesystem path using the correct separator for the OS. It\u2019s similar to pathJoin, but <code>filePathJoin</code> should be used for real filesystem paths like <code>.FsPath</code>, while <code>pathJoin</code> is for virtual paths like <code>.VirtualPath</code>.</li> <li><code>stringSlice</code> creates a list of strings. Example: <code>{{ pathJoin (stringSlice \"/a\" .VirtualPath \"final\") }}</code> with <code>.VirtualPath</code> as <code>b/c</code> outputs <code>/a/b/c/final</code>; it's useful when you need to pass multiple strings as a slice to functions like <code>pathJoin</code> or <code>filePathJoin</code>.</li> <li><code>stringJoin</code> joins a list of strings into one string with a specified separator. Example: <code>{{ stringJoin .Errors \", \" }}</code>.</li> <li><code>stringTrimSuffix</code> removes a specified suffix from a string if present. Example: <code>{{ stringTrimSuffix .VirtualPath \".jpg\" }}</code>.</li> <li><code>stringTrimPrefix</code> removes a specified prefix from a string if present.</li> <li><code>stringReplace</code> replaces all occurrences of a substring with another string. Example: <code>{{ stringReplace .VirtualPath \"/dir1\" \"/dir2\" }}</code>.</li> <li><code>stringHasPrefix</code> checks if a string starts with a specified prefix. Example: <code>{{- if stringHasPrefix .VirtualPath \"/dir2\" -}}found{{- end -}}</code>.</li> <li><code>stringHasSuffix</code> checks if a string ends with a specified suffix.</li> <li><code>stringToLower</code> converts a string to lowercase. Example: <code>{{ stringToLower .VirtualPath }}</code>.</li> <li><code>stringToUpper</code> converts a string to uppercase.</li> <li><code>createDict</code> builds a map from alternating key-value pairs. Example: <code>{{- $statusMap := createDict 1 \"OK\" 2 \"KO\" -}}</code> creates a map where 1 maps to \"OK\" and 2 maps to \"KO\".</li> <li><code>mapToString</code> looks up a value in a map by a given key. Example: <code>{{ (mapToString .Status $statusMap) | toJson }}</code> returns the string mapped to <code>.Status</code> in $statusMap, encoded as JSON.</li> <li><code>humanizeBytes</code> converts a numeric byte value into a human-readable string with appropriate units (e.g., KB, MB, GB). It formats the input size by scaling it down and appending the correct unit suffix to improve readability. For example, an input of 10000 bytes is rendered as 10 KB. Example: <code>{{ humanizeBytes .FileSize }}</code>.</li> <li><code>fromMillis</code> converts a Unix timestamp expressed in milliseconds into time object. Example: <code>(fromMillis $admin.CreatedAt).Format \"2006-01-02 15:04:05\"</code></li> </ul> <p>Some more examples.</p> <p>This example shows how to build a JSON object, such as the body of an HTTP request, using advanced template features.</p> <pre><code>{{- $statusMap := createDict 1 \"OK\" 2 \"KO\" -}}\n{\n  \"Name\": {{.Name | toJson}},\n  \"VirtualPath\": {{.VirtualPath | toJson}},\n  \"Status\": {{.Status}},\n  \"StatusString\": {{ (mapToString .Status $statusMap) | toJson }},\n  \"Metadata\": {{.Metadata | toJson}},\n  \"ObjectString\": {{.Object.JSON | toJson}},\n  \"ObjectJSON\": {{.Object.JSON}}\n}\n</code></pre> <p>First, a map <code>$statusMap</code> is created with <code>createDict</code> to translate status codes (1 and 2) into strings (\"OK\" and \"KO\").</p> <p>The JSON object includes several fields from the current context:</p> <ul> <li>\"Name\" and \"VirtualPath\" are converted to JSON strings with <code>toJson</code>.</li> <li>\"Status\" outputs the raw status code.</li> <li>\"StatusString\" uses <code>mapToString</code> to get the human-readable status from <code>$statusMap</code>, then converts it to a JSON string.</li> <li>\"Metadata\" outputs metadata as JSON.</li> <li>\"ObjectString\" outputs the JSON representation of <code>.Object</code> as a JSON string.</li> <li>\"ObjectJSON\" outputs the raw JSON object from <code>.Object.JSON</code>.</li> </ul> <p>This approach allows mixing raw values, JSON strings, and mapped values seamlessly in a structured JSON output.</p> <p>In Go templates, the <code>-</code> inside <code>{{-</code> or <code>-}}</code> trims whitespace immediately before or after the template tag. For example, <code>{{-</code> removes any whitespace to the left of the tag, and <code>-}}</code> removes whitespace to the right. This helps keep the generated output clean by avoiding unwanted spaces or newlines.</p> <p>Another example:</p> <pre><code>{{- $keyPrefix := stringJoin (stringSlice \"users\" .Name) \"/\" -}}\n{\n  \"username\": {{toJson .Name}},\n  \"status\": 1,\n  \"permissions\": {\"/\":[\"*\"]},\n  \"filesystem\": {\n    \"provider\": 1,\n    \"s3config\": {\n      \"bucket\": \"default\",\n      \"region\": \"default\",\n      \"key_prefix\": {{ $keyPrefix | toJson }}\n    }\n  },\n  \"groups\": [\n    {{- $roles := .IDPFields.sftpgo_role -}}\n    {{- range $i, $role := $roles -}}\n        {{- if ne $i 0}},{{end}}\n      {\"type\": {{if eq $i 0}}1{{else}}2{{end}},\n      \"name\": {{$role | toJson}}}\n    {{- end}}\n    ]\n}\n</code></pre> <p>This example builds a JSON object (for example, a user configuration) using advanced templating techniques:</p> <ul> <li><code>$keyPrefix</code> is created by joining \"users\" and <code>.Name</code> with a slash (<code>/</code>), e.g., if <code>.Name</code> is \"alice\", <code>$keyPrefix</code> becomes \"users/alice\".</li> <li>The JSON object includes fixed fields like \"username\" (JSON-encoded <code>.Name</code>), \"status\", \"permissions\", and \"filesystem\" settings.</li> <li>Inside \"filesystem\", the \"key_prefix\" is set to the value of <code>$keyPrefix</code>.</li> <li>The \"groups\" array is populated from the <code>.IDPFields.sftpgo_role</code> claim, which is a list of roles (e.g., <code>[\"group1\", \"group2\", \"group3\"]</code>). Using range, it loops over the roles: the first role gets <code>\"type\": 1</code> (primary group), the others <code>\"type\": 2</code> (secondary groups). Each group object includes \"name\" set to the role name, properly JSON-encoded.</li> </ul> <p>This template dynamically generates user-related JSON data by combining static values, computed fields, and information from identity provider claims. It can be used, for example, to automatically create SFTPGo users after a successful Identity Provider login.</p>"},{"location":"eventmanager/#virtual-folders","title":"Virtual folders","text":"<p>Virtual folders can be combined with filesystem actions. You can define:</p> <ul> <li>The source folder. Actions triggered by filesystem events, such as uploads or downloads, use the filesystem associated with the user. By specifying a source folder, you can control which filesystem is used. This is especially useful for events that aren't tied to a user, such as scheduled tasks and advanced workflows.</li> <li>The target folder. By specifying a target folder, you can use a different filesystem for target paths than the one associated with the user who triggered the action. This is useful for moving files to another storage backend, such as a different S3 bucket or an external SFTP server, accessing restricted areas of the same storage backend, supporting scheduled actions, or enabling more advanced workflows.</li> </ul>"},{"location":"eventmanager/#migration-from-previous-versions-or-the-open-source-edition","title":"Migration from Previous Versions or the Open-Source Edition","text":"<p>Starting with version <code>v2.7.20250726</code>, SFTPGo introduced a new, more powerful templating system for the EventManager.</p> <p>If you're upgrading from a version prior to <code>v2.7.20250726</code> or from the Open-Source version, you will need to manually migrate your existing actions to the new templating syntax to ensure correct behavior.</p> <p>In earlier versions (both Enterprise and open-source), event actions relied on simple placeholder replacement and attempted to automatically determine the output format, such as plain text or JSON, based on headers like <code>Content-Type</code>. This approach was limited and sometimes unreliable. Now, you need to be more explicit by using <code>toJson</code> and related functions where appropriate to ensure correct formatting.</p> <p>Additionally, some placeholders were removed because their functionality can now be easily achieved using the built-in functions.</p> <p>Removed placeholders:</p> <ul> <li><code>{{.StatusString}}</code>. Instead, create a template variable using <code>createDict</code>, for example: <code>{{- $statusMap := createDict 1 \"OK\" 2 \"KO\" 3 \"Quota exceeded\" -}}</code>. Then retrieve the status string with: <code>{{ mapToString .Status $statusMap }}</code>. Bonus: this approach lets you customize the status messages easily.</li> <li><code>{{.ErrorString}}</code>. Instead, use the <code>{{.Errors}}</code> placeholder, which contains the list of errors, and join them into a string with: <code>{{ stringJoin .Errors \", \" }}</code> to get the same output as the old placeholder.</li> <li><code>{{.EscapedVirtualPath}}</code>. Instead, use <code>{{ urlEscape .VirtualPath }}</code>. Bonus: you can apply <code>urlEscape</code> to any placeholder without needing separate escaped variants for each one.</li> <li><code>{{.VirtualDirPath}}</code>, <code>{{.VirtualTargetDirPath}}</code>. Instead, use <code>{{ pathDir .VirtualPath }}</code> and <code>{{ pathDir .VirtualTargetPath }}</code>.</li> <li><code>{{.Ext}}</code>. Instead use <code>{{ pathExt .VirtualPath }}</code>. Bonus: you can apply <code>pathExt</code> to any placeholder containing a path.</li> <li><code>{{.TargetName}}</code>. Instead use <code>{{ pathBase VirtualTargetPath }}</code>.</li> <li><code>{{.DateTime}}</code>, <code>{{.Year}}</code>, <code>{{.Month}}</code>, <code>{{.Day}}</code>, <code>{{.Hour}}</code>, <code>{{.Minute}}</code>: these individual placeholders are replaced by a single <code>{{.Timestamp}}</code> time object. You can format it as needed, for example: <code>{{ .Timestamp.UTC.Fomat \"2006-01-02T15:04:05.000\" }}</code>. Additionally, you can call any method supported by the Go time object on <code>.Timestamp</code>, such as <code>UTC</code>, <code>Local</code>, <code>Unix</code>, <code>UnixMilli</code>, <code>Year</code>, <code>Month</code>, <code>Day</code>, <code>Hour</code>, <code>Minute</code>, and <code>Second</code>.</li> <li><code>{{.ObjectData}}</code> and <code>{{.ObjectDataString}}</code>. These placeholders have been replaced by the <code>{{.Object}}</code> placeholder. Use <code>{{.Object.JSON}}</code> to get the equivalent of the old <code>{{.ObjectData}}</code>, and <code>{{.Object.JSON | toJson}}</code> to get the equivalent of <code>{{.ObjectDataString}}</code>.</li> <li><code>{{.Metadata}}</code>, <code>{{.MetadataString}}</code>. The <code>{{.Metadata}}</code> placeholder is now an object. Use <code>{{ toJson .Metadata }}</code> to get the equivalent of the old <code>{{.Metadata}}</code>, and <code>{{toJson .Metadata | toJson}}</code> to get the equivalent of <code>{{.MetadataString}}</code>.</li> <li><code>{{.IDPField&lt;fieldname&gt;}}</code>. These individual placeholders have been replaced by the generic <code>{{.IDPFields}}</code> object. You can now access fields using <code>{{ .IDPFields.fieldname }}</code>. Bonus: Previously, only string fields were available; now all fields are propagated with their original types as defined in your Identity Provider.</li> </ul> <p>If you need assistance migrating your actions, please don\u2019t hesitate to contact us.</p>"},{"location":"external-auth/","title":"External Authentication","text":""},{"location":"external-auth/#external-authentication","title":"External Authentication","text":"<p>To enable external authentication, you must set the absolute path of your authentication program or an HTTP URL using the <code>external_auth_hook</code> key in your configuration file.</p> <p>The external program can read the following environment variables to get info about the user trying to authenticate:</p> <ul> <li><code>SFTPGO_AUTHD_USERNAME</code></li> <li><code>SFTPGO_AUTHD_USER</code>, STPGo user serialized as JSON, empty if the user does not exist within the data provider</li> <li><code>SFTPGO_AUTHD_IP</code></li> <li><code>SFTPGO_AUTHD_PROTOCOL</code>, possible values are <code>SSH</code>, <code>FTP</code>, <code>DAV</code>, <code>HTTP</code></li> <li><code>SFTPGO_AUTHD_PASSWORD</code>, not empty for password authentication</li> <li><code>SFTPGO_AUTHD_PUBLIC_KEY</code>, not empty for public key authentication</li> <li><code>SFTPGO_AUTHD_KEYBOARD_INTERACTIVE</code>, not empty for keyboard interactive authentication</li> <li><code>SFTPGO_AUTHD_TLS_CERT</code>, TLS client certificate PEM encoded. Not empty for TLS certificate authentication</li> </ul> <p>Global environment variables are cleared, for security reasons, when the script is called. You can set additional environment variables in the \"command\" configuration section. The program can inspect the SFTPGo user, if it exists, using the <code>SFTPGO_AUTHD_USER</code> environment variable. The program must write, on its standard output:</p> <ul> <li>a valid SFTPGo user serialized as JSON if the authentication succeeds. The user will be added/updated within the defined data provider</li> <li>an empty string, or no response at all, if authentication succeeds and the existing SFTPGo user does not need to be updated. This means that the credentials already stored in SFTPGo must match those used for the current authentication.</li> <li>a user with an empty username if the authentication fails</li> </ul> <p>If the hook is an HTTP URL then it will be invoked as HTTP POST. The request body will contain a JSON serialized struct with the following fields:</p> <ul> <li><code>username</code></li> <li><code>ip</code></li> <li><code>user</code>, STPGo user, omitted if the user does not exist within the data provider</li> <li><code>protocol</code>, possible values are <code>SSH</code>, <code>FTP</code>, <code>DAV</code>, <code>HTTP</code></li> <li><code>password</code>, not empty for password authentication</li> <li><code>public_key</code>, not empty for public key authentication</li> <li><code>keyboard_interactive</code>, not empty for keyboard interactive authentication</li> <li><code>tls_cert</code>, TLS client certificate PEM encoded. Not empty for TLS certificate authentication</li> </ul> <p>If authentication succeeds the HTTP response code must be 200 and the response body can be:</p> <ul> <li>a valid SFTPGo user serialized as JSON. The user will be added/updated within the defined data provider</li> <li>empty, the existing SFTPGo user does not need to be updated. Please note that in versions 2.0.x and earlier an empty response was interpreted as an authentication error</li> </ul> <p>If the authentication fails the HTTP response code must be != 200 or the returned SFTPGo user must have an empty username.</p> <p>If the hook returns a user who is only allowed to authenticate using public key + password (multi step authentication), your hook will be invoked for each authentication step, so it must validate the public key and password separately. SFTPGo will take care that the client uses the allowed sequence.</p> <p>Actions defined for users added/updated will not be executed in this case and an already logged in user with the same username will not be disconnected.</p> <p>The program hook must finish within 30 seconds, the HTTP hook timeout will use the global configuration for HTTP clients.</p> <p>This method is slower than built-in authentication, but it's very flexible as anyone can easily write his own authentication hooks. You can also restrict the authentication scope for the hook using the <code>external_auth_scope</code> configuration key:</p> <ul> <li><code>0</code> means all supported authentication scopes. The external hook will be used for password, public key, keyboard interactive and TLS certificate authentication</li> <li><code>1</code> means passwords only</li> <li><code>2</code> means public keys only</li> <li><code>4</code> means keyboard interactive only</li> <li><code>8</code> means TLS certificate only</li> </ul> <p>You can combine the scopes. For example, 3 means password and public key, 5 means password and keyboard interactive, and so on.</p> <p>Let's see a very basic example. Our sample authentication program will only accept user <code>test_user</code> with any password or public key.</p> <pre><code>#!/bin/sh\n\nif test \"$SFTPGO_AUTHD_USERNAME\" = \"test_user\"; then\n  echo '{\"status\":1,\"username\":\"test_user\",\"expiration_date\":0,\"home_dir\":\"/tmp/test_user\",\"uid\":0,\"gid\":0,\"max_sessions\":0,\"quota_size\":0,\"quota_files\":100000,\"permissions\":{\"/\":[\"*\"],\"/somedir\":[\"list\",\"download\"]},\"upload_bandwidth\":0,\"download_bandwidth\":0,\"filters\":{\"allowed_ip\":[],\"denied_ip\":[]},\"public_keys\":[]}'\nelse\n  echo '{\"username\":\"\"}'\nfi\n</code></pre> <p>The structure for SFTPGo users can be found within the OpenAPI schema.</p> <p>You can instruct SFTPGo to cache the external user by setting an <code>external_auth_cache_time</code> in user object returned by your hook. The <code>external_auth_cache_time</code> defines the cache time in seconds.</p> <p>You can disable the hook on a per-user basis so that you can mix external and internal users.</p> <p>An example authentication program allowing to authenticate against an LDAP server can be found inside the source tree ldapauth directory.</p> <p>An example server, to use as HTTP authentication hook, allowing to authenticate against an LDAP server can be found inside the source tree ldapauthserver directory.</p> <p>If you have an external authentication hook that could be useful to others too, please let us know and/or please send a pull request.</p>"},{"location":"features/","title":"Main Features","text":""},{"location":"features/#main-features","title":"Main Features","text":"<ul> <li>Serving local filesystem, encrypted local filesystem, S3 Compatible Object Storage, Google Cloud Storage, Azure Blob Storage or other SFTP accounts over SFTP, SCP, FTP, WebDAV, HTTPS.</li> <li>Users are stored in a supported data provider\u2014such as SQLite, MySQL, PostgreSQL, CockroachDB, Bolt, or in-memory storage\u2014and each user\u2019s access is restricted to their own home directory or designated section of a storage bucket.</li> <li>Granular access control: per-user and per-directory permissions.</li> <li>Encryption at REST and in Motion.</li> <li>Audit logs and reporting.</li> <li>Password, public key and certificate authentication.</li> <li>Multi-factor and multi-step authentication. Authentication methods can be customized on a per-user basis.</li> <li>Per-user and per-directory data retention rules to automatically delete or archive old files.</li> <li>Real-time monitor of active connections.</li> <li>Quota Management: Each account can have a disk quota, defined by maximum total storage size and/or maximum number of files.</li> <li>Bandwidth Throttling: Upload and download speeds can be limited separately, with the ability to apply different settings based on the client\u2019s IP address.</li> <li>Data Transfer Limits: Total bandwidth usage can be restricted, either as a combined limit or with separate thresholds for uploads and downloads. These limits can also be customized per client IP and reset via the REST API or the EventManager.</li> <li>WebAdmin UI to easily manage users, groups, folders and connections.</li> <li>WebClient UI so that end users can change their credentials, manage and share their files in the browser.</li> <li>Virtual folders: these are special folders that connect to any supported storage backend, allowing you to make different types of storage available to users at specific folder paths. For example, a user might access an S3 bucket mapped to one folder path while also having an encrypted local filesystem available at another. Virtual folders can be either private (for a single user) or shared among multiple users. In addition, virtual folders can be used to automate actions based on events. For example, after a file is uploaded, it can be automatically copied or moved to an external SFTP server, an S3 bucket, or transferred on a set schedule. This makes it easier to manage files across different storage services without manual intervention.</li> <li>Simplified user administrations using groups: you assign settings once to a group, instead of multiple times to each individual user.</li> <li>Roles enable the creation of restricted administrators who are only permitted to create and manage users with the same assigned role. Allowing to delegate users administration.</li> <li>The Event Manager makes it possible to set up automated actions based on server activity\u2014such as when files are uploaded, downloaded, or deleted\u2014as well as on defined schedules. This feature can be used to streamline operations, for example by automatically sending notifications or moving files to other storage systems, without requiring manual intervention.</li> <li>LDAP/Active directory users.</li> <li>OpenID connect Single Sign-On supporting many Identity Providers including Microsoft Entra ID, Google Identity Platform, Amazon Cognito, Auth0, Okta, OneLogin, Jump Cloud, Ping Identity, Keycloak and many others.</li> <li>Custom authentication via external programs/HTTP API.</li> <li>Dynamic user creation or modification before login via external programs/HTTP API.</li> <li>Let\u2019s Encrypt TLS certificates for HTTPS and FTPS/FTPES.</li> <li>Geo-IP filtering.</li> <li>Per-user and global IP filters and trusted lists.</li> <li>Per-protocol rate limiting.</li> <li>Automatically disactivate or deleted inactive users.</li> <li>Automatically terminating idle connections.</li> <li>Automatic blocklist management using the built-in defender, which helps protect the server against brute-force attempts.</li> <li>Ability to configure and tune ciphers, host keys, key exchanges, message authentication codes and other algorithms.</li> <li>Support for strict Content Security Policies for WebAdmin and WebClient UI: no <code>unsafe-eval</code> and <code>usafe-inline</code> are required.</li> <li>Access time restrictions.</li> <li>Branding: custom logo and name in Web interfaces.</li> <li>REST API designed for both administrators and end users. Administrators can fully manage the system through the API\u2014creating and managing users, groups, virtual folders, and more\u2014while end users can access and interact with their files securely. This API allows for easy integration with other applications and supports automated workflows to streamline file handling and system administration.</li> <li>Infrastructure as Code: Terraform provider.</li> <li>Configurable custom commands and/or HTTP hooks on upload, pre-upload, download, pre-download, delete, pre-delete, rename, mkdir, rmdir on SSH commands and on user add, update and delete.</li> <li>Support for HAProxy PROXY protocol: you can proxy and/or load balance the SFTP/SCP/FTP service without losing the information about the client's address.</li> <li>Easy migration from Linux system user accounts.</li> <li>Portable mode: a convenient way to share a single directory on demand.</li> <li>Prometheus metrics.</li> <li>Performance analysis using built-in profiler.</li> </ul>"},{"location":"ftp/","title":"FTP","text":""},{"location":"ftp/#ftp","title":"FTP","text":"<p>The FTP server implementation supports RFC 959.</p> <p>Both password and client certificate authentication are supported.</p> <p>The following extensions are implemented:</p> <ul> <li>AUTH - Control session protection</li> <li>AUTH TLS - TLS session</li> <li>PROT - Transfer protection</li> <li>EPRT/EPSV - IPv6 support</li> <li>MDTM - File Modification Time</li> <li>SIZE - Size of a file</li> <li>REST - Restart of interrupted transfer</li> <li>MLST - Simple file listing for machine processing</li> <li>MLSD - Directory listing for machine processing</li> <li>HASH - Hashing of files</li> <li>AVLB - Available space</li> <li>COMB - Combine files</li> </ul>"},{"location":"google-cloud-storage/","title":"Google Cloud","text":""},{"location":"google-cloud-storage/#google-cloud-storage-backend","title":"Google Cloud Storage backend","text":"<p>To connect SFTPGo to Google Cloud Storage you can use use the Application Default Credentials (ADC) strategy to try to find your application's credentials automatically or you can explicitly provide a JSON credentials file that you can obtain from the Google Cloud Console. Take a look here for details.</p> <p>Specifying a different <code>key_prefix</code>, you can assign different \"folders\" of the same bucket to different users. This is similar to a chroot directory for local filesystem. Each SFTP/SCP user can only access the assigned folder and its contents. The folder identified by <code>key_prefix</code> does not need to be pre-created.</p> <p>You can optionally specify a storage class too. Leave it blank to use the default storage class.</p> <p>The configured bucket must exist.</p> <p>This backend is very similar to the S3 backend, and it has similar limitations.</p>"},{"location":"groups/","title":"Groups","text":""},{"location":"groups/#groups","title":"Groups","text":"<p>Using groups simplifies the administration of multiple accounts by letting you assign settings once to a group, instead of multiple times to each individual user.</p> <p>SFTPGo supports the following types of groups:</p> <ul> <li>primary groups</li> <li>secondary groups</li> <li>membership groups</li> </ul> <p>A user can be a member of a primary group and many secondary and membership groups. Depending on the group type, the settings are inherited differently.</p> <p> SFTPGo groups are completely unrelated to system groups. Therefore, it is not necessary to add Linux/Windows groups to use SFTPGo groups.</p> <p>The following settings are inherited from the primary group:</p> <ul> <li>home dir, if set for the group will replace the one defined for the user. The <code>%username%</code> placeholder is replaced with the username, the <code>%role%</code> placeholder will be replaced with the role name</li> <li>filesystem config, if the provider set for the group is different from the \"local provider\" will replace the one defined for the user. The <code>%username%</code> and <code>%role%</code> placeholders will be replaced with the username and role name within the defined \"prefix\", for any vfs, and the \"username\" for the SFTP filesystem config</li> <li>max sessions, quota size/files, upload/download bandwidth, upload/download/total data transfer, max upload size, external auth cache time, ftp_security, default shares expiration, max shares expiration, password expiration, password strength, passsord validation rules: if they are set to <code>0</code> for the user they are replaced with the value set for the group, if different from <code>0</code>. The password strength defined at group level is only enforce when users change their password</li> <li>expires_in, if defined and the user does not have an expiration date set, defines the expiration of the account in number of days from the creation date</li> <li>TLS username, check password hook disabled, pre-login hook disabled, external auth hook disabled, filesystem checks disabled, allow API key authentication, anonymous user: if they are not set for the user they are replaced with the value set for the group</li> <li>starting directory, if the user does not have a starting directory set, the value set for the group is used, if any. The <code>%username%</code> placeholder is replaced with the username, the <code>%role%</code> placeholder will be replaced with the role name</li> </ul> <p>The following settings are inherited from the primary and secondary groups:</p> <ul> <li>virtual folders, file patterns, permissions: they are added to the user configuration if the user does not already have a setting for the configured path. The <code>/</code> path is ignored for secondary groups. The <code>%username%</code>  and <code>%role%</code> placeholders are replaced with the username and role name within the virtual path, the defined \"prefix\", for any vfs, and the \"username\" for the SFTP and HTTP filesystem config</li> <li>per-source bandwidth limits</li> <li>per-source data transfer limits</li> <li>allowed/denied IPs</li> <li>denied login methods and protocols</li> <li>two factor auth protocols</li> <li>web client/REST API permissions</li> <li>Share Policy</li> </ul> <p>The settings from the primary group are always merged first. no setting is inherited from \"membership\" groups.</p> <p>The final settings are a combination of the user settings and the group ones. For example you can define the following groups:</p> <ul> <li>\"group1\", it has a virtual directory to mount on <code>/vdir1</code></li> <li>\"group2\", it has a virtual directory to mount on <code>/vdir2</code></li> <li>\"group3\", it has a virtual directory to mount on <code>/vdir3</code></li> </ul> <p>If you define users with a virtual directory to mount on <code>/vdir</code> and make them member of all the above groups, they will have virtual directories mounted on <code>/vdir</code>, <code>/vdir1</code>, <code>/vdir2</code>, <code>/vdir3</code>. If users already have a virtual directory to mount on <code>/vdir1</code>, the group's one will be ignored.</p> <p>Please note that if the same virtual path is set in more than one secondary group the behavior is undefined. For example if a user is a member of two secondary groups and each secondary group defines a virtual folder to mount on the <code>/vdir2</code> path, the virtual folder mounted on <code>/vdir2</code> may change with every login.</p>"},{"location":"httpfs/","title":"HTTPFs","text":""},{"location":"httpfs/#https-storage-backend","title":"HTTP/S storage backend","text":"<p>SFTPGo can use custom storage backend implementations compliant with the REST API documented here.</p> <p> HTTPFs is a work in progress and makes no API stability promises.</p> <p>The only required parameter is the HTTP/S endpoint that SFTPGo must use to make API calls. If you define <code>http://127.0.0.1:9999/api/v1</code> as endpoint, SFTPGo will add the API path, for example for the <code>stat</code> API it will invoke <code>http://127.0.0.1:9999/api/v1/stat/{name}</code>.</p> <p>You can set a <code>username</code> and/or a <code>password</code> to instruct SFTPGo to use the basic authentication, or you can set an API key to instruct SFTPGo to add it to each API call in the <code>X-API-KEY</code> HTTP header.</p> <p>Here is a mapping between HTTP response codes and protocol errors:</p> <ul> <li><code>401</code>, <code>403</code> mean permission denied error</li> <li><code>404</code>, means not found error</li> <li><code>501</code>, means not supported error</li> <li><code>200</code>, <code>201</code>, mean no error</li> <li>any other response code means a generic error</li> </ul> <p>HTTPFs can also connect to UNIX domain sockets. To use UNIX domain sockets you need to set an endpoint with the following conventions:</p> <ul> <li>the URL schema can be <code>http</code> or <code>https</code> as usual.</li> <li>The URL host must be <code>unix</code>.</li> <li>The socket path is mandatory and is set using the <code>socket_path</code> query parameter. The path must be query escaped.</li> <li>The optional API prefix can be set using the <code>api_prefix</code> query parameter. The prefix must be query escaped.</li> </ul> <p>Here is an example endpoint for UNIX domain socket connections: <code>http://unix?socket_path=%2Ftmp%2Fsftpgofs.sock&amp;api_prefix=%2Fapi%2Fv1</code>. In this case we are connecting using the <code>HTTP</code> protocol to the socket <code>/tmp/sftpgofs.sock</code> and we use the <code>/api/v1</code> prefix for API URLs.</p>"},{"location":"initial-configuration/","title":"Feature overview","text":""},{"location":"initial-configuration/#feature-overview","title":"Feature overview","text":"<p>We assume that you have installed SFTPGo and it is up and running, so let's explore the main features and concepts.</p>"},{"location":"initial-configuration/#initial-configuration","title":"Initial configuration","text":"<p>Before you can use SFTPGo you need to create an admin account, so open http://127.0.0.1:8080/web/admin in your web browser, replacing <code>127.0.0.1</code> with the appropriate IP address if SFTPGo is not running on localhost.</p> <p></p> <p>After creating the admin account you will be automatically logged in and redirected to the page to set up two-factor authentication. Setting up two-factor authentication is optional.</p> <p></p> <p>The web admin is now available at the following URL:</p> <p>http://127.0.0.1:8080/web/admin</p> <p>From the <code>Status</code> page you see the active services.</p> <p></p> <p>The default configuration enables the SFTP service on port <code>2022</code> and uses an embedded data provider (<code>SQLite</code> or <code>bolt</code> based on the target OS and architecture).</p>"},{"location":"initial-configuration/#adding-a-license-key","title":"Adding a license key","text":"<p>Without a valid license, the application will operate under the Starter license tier, with the following additional limitations:</p> <ul> <li>Concurrent transfers are limited to 2.</li> <li>Plugin support is disabled.</li> </ul> <p>You can view your license status and add a new license key from the WebAdmin UI by navigating to Server Manager =&gt; License.</p> <p></p> <p>For unattended or CLI-based setups, the license key can also be activated by setting the <code>SFTPGO_LICENSE_KEY</code> environment variable.</p> <pre><code>SFTPGO_LICENSE_KEY=XXXX-XXXX-XXXX-XXXX\n</code></pre>"},{"location":"initial-configuration/#creating-users","title":"Creating users","text":"<p>Let's create our first local user:</p> <ul> <li>from the <code>Users</code> page click the <code>+</code> icon to open the <code>Add user page</code></li> <li>the only required fields are the <code>Username</code> and a <code>Password</code> or a <code>Public key</code></li> <li>if you are on Windows or you installed SFTPGo manually and no <code>users_base_dir</code> is defined in your configuration file you also have to set a <code>Home Dir</code>. It must be an absolute path, for example <code>/srv/sftpgo/data/username</code> on Linux or <code>C:\\sftpgo\\data\\username</code> on Windows. SFTPGo will try to automatically create the home directory, if missing, when the user logs in. Each user can only access files and folders inside its home directory.</li> <li>click <code>Save</code></li> </ul> <p></p> <p> Please note that, on Linux, SFTPGo runs using a dedicated system user and group called <code>sftpgo</code>, for added security. If you want to be able to use directories outside the <code>/srv/sftpgo</code> path you need to set the appropriate system level permissions. For example if you define <code>/home/username/test</code> as home dir you have to create this directory yourself, if it doesn't exist, and set the appropriate system-level permissions:</p> <pre><code>sudo mkdir /home/username/test\nsudo chown sftpgo:sftpgo /home/username/test\n</code></pre> <p>You also need to make sure that the <code>sftpgo</code> system user has at least the read permission for any parent directory, so in the example above <code>/home/username</code> and <code>/home</code> must not have <code>0700</code> permissions.</p> <p>Now test the new user, we use the <code>sftp</code> CLI here, you can use any SFTP client.</p> <pre><code>$ sftp -P 2022 nicola@127.0.0.1\nnicola@127.0.0.1's password:\nConnected to 127.0.0.1.\nsftp&gt; ls\nsftp&gt; put file.txt\nUploading file.txt to /file.txt\nfile.txt                                      100% 4034     3.9MB/s   00:00\nsftp&gt; ls\nfile.txt\nsftp&gt; mkdir adir\nsftp&gt; cd adir/\nsftp&gt; put file.txt\nUploading file.txt to /adir/file.txt\nfile.txt                                      100% 4034     4.0MB/s   00:00\nsftp&gt; ls\nfile.txt\nsftp&gt; get file.txt\nFetching /adir/file.txt to file.txt\n/adir/file.txt                                100% 4034     1.9MB/s   00:00\n</code></pre> <p>It worked! We can upload/download files and create directories.</p>"},{"location":"initial-configuration/#creating-users-with-a-cloud-storage-backend","title":"Creating users with a Cloud Storage backend","text":"<p>The procedure is similar to the one described for local users, you have only specify the Cloud Storage backend and its credentials.</p> <p>The screenshot below shows an example configuration for an S3 backend.</p> <p> </p> <p>The screenshot below shows an example configuration for an Azure Blob Storage backend.</p> <p> </p> <p>The screenshot below shows an example configuration for a Google Cloud Storage backend.</p> <p></p> <p>The screenshot below shows an example configuration for an SFTP server as storage backend.</p> <p></p> <p>Setting a <code>Key Prefix</code> you restrict the user to a specific \"sub-folder\" in the bucket, so that the same bucket can be shared among different users.</p>"},{"location":"initial-configuration/#creating-users-with-a-local-encrypted-backend-data-at-rest-encryption","title":"Creating users with a local encrypted backend (Data At Rest Encryption)","text":"<p>The procedure is similar to the one described for local users, you have only specify the encryption passphrase. The screenshot below shows an example configuration.</p> <p></p> <p>More details about Data At Rest Encryption.</p>"},{"location":"initial-configuration/#webclient","title":"WebClient","text":"<p>Users created via the WebAdmin UI can also log in to the WebClient UI to browse and manage their files directly in the browser. They can update their credentials and enable two-factor authentication, which is compatible with Microsoft Authenticator, Google Authenticator, Authy, and other apps that support standard TOTP.</p> <p>From the WebClient, authorized users can securely share files and folders via HTTP/S links. Sharing options include setting download/upload limits, password protection, email-based authentication, IP address restrictions, and automatic expiration dates.</p> <p>The WebClient interface is available at the following URL:</p> <p>http://127.0.0.1:8080/web/client</p>"},{"location":"initial-configuration/#file-and-folder-management","title":"File and Folder Management","text":"<p>The WebClient allows users to easily manage files and folders within their SFTPGo storage from the \"Files\" section.</p> <p></p> <p>Key functionalities:</p> <ul> <li>Upload: Drag &amp; drop or use the upload button to add single or multiple files.</li> <li>Download: Download individual files or multiple items as a zipped archive.</li> <li>Folders: Create, rename, and delete folders to organize your content.</li> <li>Rename/Delete: Rename or delete files and folders via the context menu.</li> <li>Move/Copy: Move or copy files and folders.</li> <li>Search: Quickly find files and folders using the search bar.</li> <li>Preview: Preview supported file types directly in the browser.</li> </ul>"},{"location":"initial-configuration/#document-editing-collaboration","title":"Document Editing &amp; Collaboration","text":"<p>Document Editing &amp; Collaboration can be added as a separate add-on to any license.</p> <p>This feature enables seamless document editing, and real-time collaboration directly within the SFTPGo WebClient. Multiple users can work on the same document simultaneously, with live updates visible to everyone as changes are made.</p> <p>To use this feature, you will need to deploy a compatible WOPI document server in your environment, such as Collabora Online, the open-source office suite based on LibreOffice. We are an official partner of Collabora and offer first-class support for integrating with it.</p> <p>Virtual folders can be created for sharing among multiple users, enabling collaboration on the documents stored within them.</p> <p>To start editing and collaborating on a .docx, .xlsx, or .pptx files (or their open formats), simply click the 'eye' icon next to the file in the list.</p> <p></p> <p>The Collabora Online editor will open directly in your browser.</p> <p></p> <p>This powerful, web-based office suite allows you to view, edit, and collaborate on documents in real time, without needing to download or install anything. It supports rich editing features for text documents, spreadsheets and presentations, ensuring full compatibility with Microsoft Office formats.</p> <p>The licensing model is per-user. When a user opens a document, one of the available licenses is automatically assigned to them. If no document is opened for three consecutive days, the license is automatically released and available for a different users.</p> <p>If you've purchased the add-on for fewer users than the total number of users in your installation, you can restrict access by disabling WOPI for specific users or groups in the \"ACLs\" section.</p> <p></p>"},{"location":"initial-configuration/#two-factor-authentication","title":"Two factor authentication","text":"<p>For detailed, step-by-step instructions, please refer to the dedicated Two-Factor Authentication tutorial.</p> <p></p>"},{"location":"initial-configuration/#sharing","title":"Sharing","text":"<p>The WebClient allows users to securely share files and folders via HTTP/S links. Each share can be customized with advanced options to control access and improve security.</p> <p>To share a file or folder, select the desired item and click the three-dot menu on the left. Then choose the 'Share' option from the menu.</p> <p></p> <p>Configure the sharing options, such as the access scope\u2014read, write, or read/write\u2014to define what actions recipients are allowed to perform. You can also enable email-based authentication to restrict access to specific recipients.</p> <p></p> <p>Share the link with external users.</p> <p>Bonus: Configure an EventManager rule to automatically send email notifications to recipients whenever a new share is created.</p> <p>External users will be prompted to enter their email address and will receive a one-time authentication code, valid for a limited time, to access the shared content.</p> <p></p>"},{"location":"initial-configuration/#virtual-permissions","title":"Virtual permissions","text":"<p>SFTPGo supports per directory virtual permissions. For each user you have to specify global permissions and then override them on a per-directory basis.</p> <p>Take a look at the following screens.</p> <p></p> <p>This user has full access as default (<code>*</code>), can only list and download from <code>/read-only</code> path and has no permissions at all for the <code>/subdir</code> path.</p> <p>Let's test it. We use the <code>sftp</code> CLI here, you can use any SFTP client.</p> <pre><code>$ sftp -P 2022 nicola@127.0.0.1\nConnected to 127.0.0.1.\nsftp&gt; ls\nadir        file.txt    read-only   subdir\nsftp&gt; put file.txt\nUploading file.txt to /file.txt\nfile.txt                                                                  100% 4034    19.4MB/s   00:00\nsftp&gt; rm file.txt\nRemoving /file.txt\nsftp&gt; ls\nadir        read-only   subdir\nsftp&gt; cd read-only/\nsftp&gt; ls\nfile.txt\nsftp&gt; put file1.txt\nUploading file1.txt to /read-only/file1.txt\nremote open(\"/read-only/file1.txt\"): Permission denied\nsftp&gt; get file.txt\nFetching /read-only/file.txt to file.txt\n/read-only/file.txt                                                       100% 4034     2.2MB/s   00:00\nsftp&gt; cd ..\nsftp&gt; ls\nadir        read-only   subdir\nsftp&gt; cd /subdir\nsftp&gt; ls\nremote readdir(\"/subdir\"): Permission denied\n</code></pre> <p>as you can see it worked as expected.</p>"},{"location":"initial-configuration/#virtual-folders","title":"Virtual folders","text":"<p>A virtual folder is a mapping between a SFTPGo virtual path and a filesystem path outside the user home directory or on a different storage provider. Therefore, there is no need to create virtual folders for the users home directory or for directories within the users home directory.</p> <p>From the web admin interface click <code>Folders</code> and then the <code>+</code> icon.</p> <p></p> <p>To create a local folder you need to specify a <code>Name</code> and an <code>Absolute path</code>. For other backends you have to specify the backend type and its credentials, this is the same procedure already detailed for creating users with cloud backends.</p> <p>Suppose we created two virtual folders name <code>localfolder</code> and <code>minio</code> as you can see in the following screen.</p> <p></p> <ul> <li><code>localfolder</code> uses the local filesystem as storage backend</li> <li><code>minio</code> uses MinIO (S3 compatible) as storage backend</li> </ul> <p>Now, click <code>Users</code>, on the left menu, select a user and click the <code>Edit</code> icon, to update the user and associate the virtual folders.</p> <p>Virtual folders must be referenced using their unique name and you can map them on a configurable virtual path. Take a look at the following screenshot.</p> <p></p> <p>We mapped the folder named <code>localfolder</code> on the path <code>/vdirlocal</code> (this must be an absolute UNIX path on Windows too) and the folder named <code>minio</code> on the path <code>/vdirminio</code>. For <code>localfolder</code> the quota usage is included within the user quota, while for the <code>minio</code> folder we defined separate quota limits: at most 2 files and at most 100MB, whichever is reached first.</p> <p>The folder <code>minio</code> can be shared with other users and we can define different quota limits on a per-user basis. The folder <code>localfolder</code> is considered private since we have included its quota limits within those of the user, if we share them with other users we will break quota calculation.</p> <p>Let's test these virtual folders. We use the <code>sftp</code> CLI here, you can use any SFTP client.</p> <pre><code>$ sftp -P 2022 nicola@127.0.0.1\nnicola@127.0.0.1's password:\nConnected to 127.0.0.1.\nsftp&gt; ls\nadir        read-only   subdir      vdirlocal   vdirminio\nsftp&gt; cd vdirlocal\nsftp&gt; put file.txt\nUploading file.txt to /vdirlocal/file.txt\nfile.txt                                                                  100% 4034    17.3MB/s   00:00\nsftp&gt; ls\nfile.txt\nsftp&gt; cd ..\nsftp&gt; cd vdirminio/\nsftp&gt; put file.txt\nUploading file.txt to /vdirminio/file.txt\nfile.txt                                                                  100% 4034     4.8MB/s   00:00\nsftp&gt; ls\nfile.txt\nsftp&gt; put file.txt file1.txt\nUploading file.txt to /vdirminio/file1.txt\nfile.txt                                                                  100% 4034     2.8MB/s   00:00\nsftp&gt; put file.txt file2.txt\nUploading file.txt to /vdirminio/file2.txt\nremote open(\"/vdirminio/file2.txt\"): Failure\nsftp&gt; quit\n</code></pre> <p>The last upload failed since we exceeded the number of files quota limit.</p>"},{"location":"initial-configuration/#groups","title":"Groups","text":"<p>Using groups simplifies the administration of multiple SFTPGo users: you can assign settings once to a group, instead of multiple times to each individual user.</p> <p>SFTPGo supports the following types of groups:</p> <ul> <li>primary groups</li> <li>secondary groups</li> <li>membership groups</li> </ul> <p>A user can be a member of a primary group and many secondary and membership groups. Depending on the group type, the settings are inherited differently, more details.</p> <p> SFTPGo groups are completely unrelated to system groups. Therefore, it is not necessary to add Linux/Windows groups to use SFTPGo groups.</p>"},{"location":"initial-configuration/#usage-example","title":"Usage example","text":"<p>Suppose you have the following requirements:</p> <ul> <li>each user must be restricted to a local home directory containing the username as last element of the path, for example <code>/srv/sftpgo/data/&lt;username&gt;</code></li> <li>for each user, the maximum upload size for a single file must be limited to 1GB</li> <li>each user must have an S3 virtual folder available in the path <code>/s3&lt;username&gt;</code> and each user can only access a specified \"prefix\" of the S3 bucket. It must not be able to access other users' files</li> <li>each user must have an S3 virtual folder available in the path <code>/shared</code>. This is a folder shared with other users</li> <li>a group of users can only download and list contents in the <code>/shared</code> path while another group of users have full access</li> </ul> <p>We can easily meet these requirements by defining two groups.</p> <p>From the SFTPGo WebAdmin UI, click on <code>Folders</code> and then on the <code>+</code> icon.</p> <p>Create a folder named <code>S3private</code>. Set the storage to <code>AWS S3 (Compatible)</code> and fill the required parameters:</p> <ul> <li>bucket name</li> <li>region</li> <li>credentials: access key and access secret</li> </ul> <p></p> <p>The important part is the <code>Key Prefix</code>, set it to <code>users/%username%/</code></p> <p></p> <p>The placeholder <code>%username%</code> will be replaced with the associated username.</p> <p>Create another folder named <code>S3shared</code> with the same settings as <code>S3private</code> but this time set the <code>Key Prefix</code> to <code>shared/</code>. The <code>Key Prefix</code> has no placeholder, so the folder will operate on a static path that won't change based on the associated user.</p> <p>Now click on <code>Groups</code> and then on the <code>+</code> icon and add a group named <code>Primary</code>.</p> <p>Set the <code>Home Dir</code> to <code>/srv/sftpgo/data/%username%</code>.</p> <p></p> <p>As before, the placeholder <code>%username%</code> will be replaced with the associated username.</p> <p>Add the two virtual folders to this group and set the <code>Max file upload size</code> to 1GB.</p> <p></p> <p>Add a new group and name it <code>SharedReadOnly</code>, in the ACLs section set the permission on the <code>/shared</code> path so that read only access is granted.</p> <p></p> <p>The group setup is now complete. We can now create our users and set the primary group to <code>Primary</code>. For the users who need read-only access to the <code>/shared</code> path we also have to set <code>SharedReadOnly</code> as a secondary group.</p> <p>You can now login with any SFTP client like FileZilla, WinSCP etc. and verify that the requirements are met.</p>"},{"location":"initial-configuration/#simplify-user-page","title":"Simplify user page","text":"<p>The add/update user page has many configuration options and can be intimidating for some administrators. We can hide most of the settings and automatically add groups to newly created users. This way the hidden settings are inherited from the automatically assigned groups and therefore administrators can add new users simply by setting the username and credentials.</p> <p>Click on <code>Admins</code> and then on the <code>+</code> icon and add an admin named <code>simply</code>. In the <code>Groups for users</code> section set <code>Primary</code> as primary group and <code>SharedReadOnly</code> as <code>seconday</code> group. In the <code>User page preferences</code> section hide all the sections.</p> <p></p> <p>Log in using the newly created administrator and try to add a new user. The user page is simplified as you can see in the following screen.</p> <p></p>"},{"location":"initial-configuration/#custom-branding","title":"Custom branding","text":"<p>From the \"Server Manager\" section, select \"Configurations\" and then \"Branding\". You can change the name, logo, favicon and add a disclaimer in the login section for both WebAdmin and WebClient. The disclaimer might be a URL to your Privacy Policy or something like that.</p>"},{"location":"initial-configuration/#configuration-parameters","title":"Configuration parameters","text":"<p>Until now we used the default configuration, to change the global service parameters you have to edit the configuration file, or set appropriate environment variables, and restart SFTPGo to apply the changes.</p> <p>A full explanation of all configuration parameters is available in the dedicated configuration file section. Below, we\u2019ll explore some common use cases.</p> <p>Keep in mind that SFTPGo can also be configured using environment variables \u2014 a convenient option, especially when running it in Docker.</p> <p>The default configuration file is <code>sftpgo.json</code> and it can be found within the <code>/etc/sftpgo</code> directory if you installed from Linux distro packages. On Windows the configuration file can be found within the <code>{commonappdata}\\SFTPGo</code> directory where <code>{commonappdata}</code> is typically <code>C:\\ProgramData</code>. SFTPGo also supports reading from TOML and YAML configuration files.</p> <p>The configuration file can change between different versions and merging your custom settings with the default configuration file, after updating SFTPGo, may be time-consuming. For this reason we suggest to set your custom settings using environment variables. If you install SFTPGo on Linux using the official deb/rpm packages you can set your custom environment variables in the file <code>/etc/sftpgo/sftpgo.env</code>. SFTPGo also reads files inside the <code>env.d</code> directory relative to config dir (<code>/etc/sftpgo/env.d</code> on Linux and <code>{commonappdata}\\SFTPGo\\env.d</code> on Windows) and then exports the valid variables into environment variables if they are not already set. Of course you can also set environment variables with the method provided by the operating system of your choice.</p> <p>The following snippets assume your are running SFTPGo on Linux but they can be easily adapted for other operating systems.</p>"},{"location":"initial-configuration/#use-postgresql-data-provider","title":"Use PostgreSQL data provider","text":"<p>Create a PostgreSQL database named <code>sftpgo</code> and a PostgreSQL user with the correct permissions, for example using the <code>psql</code> CLI.</p> <pre><code>sudo -i -u postgres psql\nCREATE DATABASE \"sftpgo\" WITH ENCODING='UTF8' CONNECTION LIMIT=-1;\ncreate user \"sftpgo\" with encrypted password 'your password here';\ngrant all privileges on database \"sftpgo\" to \"sftpgo\";\n\\q\n</code></pre> <p>You can open the SFTPGo configuration file, search for the <code>data_provider</code> section and change it as follow.</p> <pre><code>  \"data_provider\": {\n    \"driver\": \"postgresql\",\n    \"name\": \"sftpgo\",\n    \"host\": \"127.0.0.1\",\n    \"port\": 5432,\n    \"username\": \"sftpgo\",\n    \"password\": \"your password here\",\n    ...\n}\n</code></pre> <p>Alternatively (recommended), you can use environment variables by creating the file <code>/etc/sftpgo/env.d/postgresql.env</code> with the following content.</p> <pre><code>SFTPGO_DATA_PROVIDER__DRIVER=postgresql\nSFTPGO_DATA_PROVIDER__NAME=sftpgo\nSFTPGO_DATA_PROVIDER__HOST=127.0.0.1\nSFTPGO_DATA_PROVIDER__PORT=5432\nSFTPGO_DATA_PROVIDER__USERNAME=sftpgo\nSFTPGO_DATA_PROVIDER__PASSWORD=your password here\n</code></pre> <p>Confirm that the database connection works by initializing the data provider.</p> <pre><code>$ sudo su - sftpgo -s /bin/bash -c 'sftpgo initprovider -c /etc/sftpgo'\n2021-05-19T22:21:54.000 INF Initializing provider: \"postgresql\" config file: \"/etc/sftpgo/sftpgo.json\"\n2021-05-19T22:21:54.000 INF updating database schema version: 8 -&gt; 9\n2021-05-19T22:21:54.000 INF Data provider successfully initialized/updated\n</code></pre> <p>Ensure that SFTPGo starts after the database service.</p> <pre><code>sudo systemctl edit sftpgo.service\n</code></pre> <p>And override the unit definition with the following snippet.</p> <pre><code>[Unit]\nAfter=postgresql.service\n</code></pre> <p>Restart SFTPGo to apply the changes.</p>"},{"location":"initial-configuration/#use-mysqlmariadb-data-provider","title":"Use MySQL/MariaDB data provider","text":"<p>Create a MySQL database named <code>sftpgo</code> and a MySQL user with the correct permissions, for example using the <code>mysql</code> CLI.</p> <pre><code>$ mysql -u root\nMariaDB [(none)]&gt; CREATE DATABASE sftpgo CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;\nQuery OK, 1 row affected (0.000 sec)\n\nMariaDB [(none)]&gt; grant all privileges on sftpgo.* to sftpgo@localhost identified by 'your password here';\nQuery OK, 0 rows affected (0.027 sec)\n\nMariaDB [(none)]&gt; quit\nBye\n</code></pre> <p>You can open the SFTPGo configuration file, search for the <code>data_provider</code> section and change it as follow.</p> <pre><code>  \"data_provider\": {\n    \"driver\": \"mysql\",\n    \"name\": \"sftpgo\",\n    \"host\": \"127.0.0.1\",\n    \"port\": 3306,\n    \"username\": \"sftpgo\",\n    \"password\": \"your password here\",\n    ...\n}\n</code></pre> <p>Alternatively (recommended), you can use environment variables by creating the file <code>/etc/sftpgo/env.d/mysql.env</code> with the following content.</p> <pre><code>SFTPGO_DATA_PROVIDER__DRIVER=mysql\nSFTPGO_DATA_PROVIDER__NAME=sftpgo\nSFTPGO_DATA_PROVIDER__HOST=127.0.0.1\nSFTPGO_DATA_PROVIDER__PORT=3306\nSFTPGO_DATA_PROVIDER__USERNAME=sftpgo\nSFTPGO_DATA_PROVIDER__PASSWORD=your password here\n</code></pre> <p>Confirm that the database connection works by initializing the data provider.</p> <pre><code>$ sudo su - sftpgo -s /bin/bash -c 'sftpgo initprovider -c /etc/sftpgo'\n2021-05-19T22:29:30.000 INF Initializing provider: \"mysql\" config file: \"/etc/sftpgo/sftpgo.json\"\n2021-05-19T22:29:30.000 INF updating database schema version: 8 -&gt; 9\n2021-05-19T22:29:30.000 INF Data provider successfully initialized/updated\n</code></pre> <p>Ensure that SFTPGo starts after the database service.</p> <pre><code>sudo systemctl edit sftpgo.service\n</code></pre> <p>And override the unit definition with the following snippet.</p> <pre><code>[Unit]\nAfter=mariadb.service\n</code></pre> <p>Restart SFTPGo to apply the changes.</p>"},{"location":"initial-configuration/#use-cockroachdb-data-provider","title":"Use CockroachDB data provider","text":"<p>We suppose you have installed CockroachDB this way:</p> <pre><code>sudo su\nexport CRDB_VERSION=22.1.8 # set the latest available version here\nwget -qO- https://binaries.cockroachdb.com/cockroach-v${CRDB_VERSION}.linux-amd64.tgz | tar xvz\ncp -i cockroach-v${CRDB_VERSION}.linux-amd64/cockroach /usr/local/bin/\nmkdir -p /usr/local/lib/cockroach\ncp -i cockroach-v${CRDB_VERSION}.linux-amd64/lib/libgeos.so /usr/local/lib/cockroach/\ncp -i cockroach-v${CRDB_VERSION}.linux-amd64/lib/libgeos_c.so /usr/local/lib/cockroach/\nmkdir /var/lib/cockroach\nchown sftpgo:sftpgo /var/lib/cockroach\nmkdir -p /etc/cockroach/{certs,ca}\nchmod 700 /etc/cockroach/ca\n/usr/local/bin/cockroach cert create-ca --certs-dir=/etc/cockroach/certs --ca-key=/etc/cockroach/ca/ca.key\n/usr/local/bin/cockroach cert create-node localhost $(hostname) --certs-dir=/etc/cockroach/certs --ca-key=/etc/cockroach/ca/ca.key\n/usr/local/bin/cockroach cert create-client root --certs-dir=/etc/cockroach/certs --ca-key=/etc/cockroach/ca/ca.key\nchown -R sftpgo:sftpgo /etc/cockroach/certs\nexit\n</code></pre> <p>and you are running it using a systemd unit like this one:</p> <pre><code>[Unit]\nDescription=Cockroach Database single node\nRequires=network.target\n[Service]\nType=notify\nWorkingDirectory=/var/lib/cockroach\nExecStart=/usr/local/bin/cockroach start-single-node --certs-dir=/etc/cockroach/certs --http-addr 127.0.0.1:8888 --listen-addr 127.0.0.1:26257 --cache=.25 --max-sql-memory=.25 --store=path=/var/lib/cockroach\nTimeoutStopSec=60\nRestart=always\nRestartSec=10\nStandardOutput=journal\nStandardError=journal\nUser=sftpgo\n[Install]\nWantedBy=default.target\n</code></pre> <p>Create a CockroachDB database named <code>sftpgo</code>.</p> <pre><code>$ sudo /usr/local/bin/cockroach sql --certs-dir=/etc/cockroach/certs -e 'create database \"sftpgo\"'\nCREATE DATABASE\n\nTime: 13ms\n</code></pre> <p>You can open the SFTPGo configuration file, search for the <code>data_provider</code> section and change it as follow.</p> <pre><code>  \"data_provider\": {\n    \"driver\": \"cockroachdb\",\n    \"name\": \"sftpgo\",\n    \"host\": \"localhost\",\n    \"port\": 26257,\n    \"username\": \"root\",\n    \"password\": \"\",\n    \"sslmode\": 3,\n    \"root_cert\": \"/etc/cockroach/certs/ca.crt\",\n    \"client_cert\": \"/etc/cockroach/certs/client.root.crt\",\n    \"client_key\": \"/etc/cockroach/certs/client.root.key\",\n    ...\n}\n</code></pre> <p>Alternatively (recommended), you can use environment variables by creating the file <code>/etc/sftpgo/env.d/cockroachdb.env</code> with the following content.</p> <pre><code>SFTPGO_DATA_PROVIDER__DRIVER=cockroachdb\nSFTPGO_DATA_PROVIDER__NAME=sftpgo\nSFTPGO_DATA_PROVIDER__HOST=localhost\nSFTPGO_DATA_PROVIDER__PORT=26257\nSFTPGO_DATA_PROVIDER__USERNAME=root\nSFTPGO_DATA_PROVIDER__SSLMODE=3\nSFTPGO_DATA_PROVIDER__ROOT_CERT=\"/etc/cockroach/certs/ca.crt\"\nSFTPGO_DATA_PROVIDER__CLIENT_CERT=\"/etc/cockroach/certs/client.root.crt\"\nSFTPGO_DATA_PROVIDER__CLIENT_KEY=\"/etc/cockroach/certs/client.root.key\"\n</code></pre> <p>Confirm that the database connection works by initializing the data provider.</p> <pre><code>$ sudo su - sftpgo -s /bin/bash -c 'sftpgo initprovider -c /etc/sftpgo'\n2022-06-02T14:54:04.510 INF Initializing provider: \"cockroachdb\" config file: \"/etc/sftpgo/sftpgo.json\"\n2022-06-02T14:54:04.554 INF creating initial database schema, version 15\n2022-06-02T14:54:04.698 INF updating database schema version: 15 -&gt; 16\n2022-06-02T14:54:07.093 INF updating database schema version: 16 -&gt; 17\n2022-06-02T14:54:07.672 INF updating database schema version: 17 -&gt; 18\n2022-06-02T14:54:07.699 INF updating database schema version: 18 -&gt; 19\n2022-06-02T14:54:07.721 INF Data provider successfully initialized/updated\n</code></pre> <p>Ensure that SFTPGo starts after the database service.</p> <pre><code>sudo systemctl edit sftpgo.service\n</code></pre> <p>And override the unit definition with the following snippet.</p> <pre><code>[Unit]\nAfter=cockroachdb.service\n</code></pre> <p>Restart SFTPGo to apply the changes.</p>"},{"location":"initial-configuration/#enable-ftp-service","title":"Enable FTP service","text":"<p>You can set the configuration options to enable the FTP service by opening the SFTPGo configuration file, looking for the <code>ftpd</code> section and editing it as follows.</p> <pre><code>  \"ftpd\": {\n    \"bindings\": [\n      {\n        \"port\": 2121,\n        \"address\": \"\",\n        \"apply_proxy_config\": true,\n        \"tls_mode\": 0,\n        \"certificate_file\": \"\",\n        \"certificate_key_file\": \"\",\n        \"min_tls_version\": 12,\n        \"force_passive_ip\": \"\",\n        \"passive_ip_overrides\": [],\n        \"client_auth_type\": 0,\n        \"tls_cipher_suites\": [],\n        \"passive_connections_security\": 0,\n        \"active_connections_security\": 0,\n        \"debug\": false\n      }\n    ],\n    \"banner\": \"\",\n    \"banner_file\": \"\",\n    \"active_transfers_port_non_20\": true,\n    \"passive_port_range\": {\n      \"start\": 50000,\n      \"end\": 50100\n    },\n    ...\n  }\n</code></pre> <p>Alternatively (recommended), you can use environment variables by creating the file <code>/etc/sftpgo/env.d/ftpd.env</code> with the following content.</p> <pre><code>SFTPGO_FTPD__BINDINGS__0__PORT=2121\n</code></pre> <p>Restart SFTPGo to apply the changes. The FTP service is now available on port <code>2121</code>.</p> <p>You can also configure the passive ports range (<code>50000-50100</code> by default), these ports must be reachable for passive FTP to work. If your FTP server is on the private network side of a NAT configuration you have to set <code>force_passive_ip</code> to your external IP address. You may also need to open the passive port range on your firewall.</p> <p>It is recommended that you provide a certificate and key file to allow FTP over TLS. You should prefer SFTP to FTP even if you configure TLS, please don't blindly enable the old FTP protocol.</p>"},{"location":"initial-configuration/#enable-webdav-service","title":"Enable WebDAV service","text":"<p>You can set the configuration options to enable the FTP service by opening the SFTPGo configuration file, looking for the <code>webdavd</code> section and editing it as follows.</p> <pre><code>  \"webdavd\": {\n    \"bindings\": [\n      {\n        \"port\": 10080,\n        \"address\": \"\",\n        \"enable_https\": false,\n        \"certificate_file\": \"\",\n        \"certificate_key_file\": \"\",\n        \"min_tls_version\": 12,\n        \"client_auth_type\": 0,\n        \"tls_cipher_suites\": [],\n        \"prefix\": \"\",\n        \"proxy_allowed\": [],\n        \"client_ip_proxy_header\": \"\",\n        \"client_ip_header_depth\": 0,\n        \"disable_www_auth_header\": false\n      }\n    ],\n    ...\n  }\n</code></pre> <p>Alternatively (recommended), you can use environment variables by creating the file <code>/etc/sftpgo/env.d/webdavd.env</code> with the following content.</p> <pre><code>SFTPGO_WEBDAVD__BINDINGS__0__PORT=10080\n</code></pre> <p>Restart SFTPGo to apply the changes. The WebDAV service is now available on port <code>10080</code>. It is recommended that you provide a certificate and key file to allow WebDAV over https.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#installation","title":"Installation","text":"<p>SFTPGo is compatible with Linux, Windows, macOS, and FreeBSD. Other BSD variants are likely to work as well, and the software can run on a wide range of systems\u2014from small embedded devices to large-scale Kubernetes clusters.</p> <p>The Enterprise edition is officially distributed and supported for Linux and Windows platforms, and is also available as a Docker image or through a Helm chart.</p> <p>If you'd prefer to focus on your core business without worrying about the maintenance and security of your file transfer solution, consider opting for our fully managed SaaS offerings. With a dedicated installation tailored specifically to your needs, you'll receive a secure, high-performance solution fully managed by us. We handle everything from security patches to upgrades, ensuring your service runs smoothly at all times.</p> <p> Note: Only the installation methods explicitly documented here provide access to SFTPGo Enterprise. Community distributions, including unofficial Docker images and pre-packaged solutions from third-party platforms, even if offered as paid services, provide the open-source edition of SFTPGo. These versions do not include Enterprise features and are not supported by the SFTPGo team.</p>"},{"location":"installation/#requirements","title":"Requirements","text":"<p>The only (optional) requirement is a suitable SQL server to use as data provider:</p> <ul> <li>upstream supported versions of PostgreSQL, MySQL and MariaDB.</li> <li>CockroachDB stable.</li> </ul> <p>You can remove this requirement by using an embedded SQLite, bolt or in memory data provider.</p>"},{"location":"installation/#commercial-marketplaces","title":"Commercial Marketplaces","text":"<p>SFTPGo Enterprise is available on major cloud marketplaces, allowing you to quickly deploy pre-configured instances in your preferred environment. These offerings simplify installation and come with default settings, which can be easily adjusted to match your specific requirements.</p> <p>Marketplace offerings are available in plans that correspond to our Starter and Premium on-premises tiers. For advanced requirements, a private offer can be arranged to provide the full capabilities of the Ultimate tier.</p>"},{"location":"installation/#aws","title":"AWS","text":"<p>SFTPGo Enterprise offerings on AWS Marketplace:</p> <ul> <li>SFTPGo Enterprise - Starter</li> <li>SFTPGo Enterprise - Premium</li> <li>SFTPGo Enterprise - Starter (arm64)</li> <li>SFTPGo Enterprise - Premium (arm64)</li> <li>SFTPGo Enterprise - Container</li> </ul> <p>Prior to the general availability of SFTPGo Enterprise, we released some offerings based on the open-source version of SFTPGo. While these remain fully supported, we recommend migrating to the Enterprise edition for improved performance and more advanced features. You can view all of our supported offerings using this link.</p>"},{"location":"installation/#azure","title":"Azure","text":"<p>SFTPGo Enterprise offerings on Azure Marketplace:</p> <ul> <li>SFTPGo Enterprise for Linux</li> <li>SFTPGo Enterprise for Windows</li> <li>SFTPGo Enterprise for AKS</li> </ul> <p>Prior to the general availability of SFTPGo Enterprise, we released some offerings based on the open-source version of SFTPGo. While these remain fully supported, we recommend migrating to the Enterprise edition for improved performance and more advanced features. Here is the list of additional supported offer:</p> <ul> <li>SFTPGo Open Source for Linux</li> <li>SFTPGo Open Source for Windows</li> <li>SFTPGo Open Source for AKS</li> </ul>"},{"location":"installation/#google-cloud","title":"Google Cloud","text":"<p>SFTPGo Enterprise offerings on Google Cloud Marketplace:</p> <ul> <li>SFTPGo Enterprise - Starter</li> <li>SFTPGo Enterprise - Premium</li> </ul> <p>Prior to the general availability of SFTPGo Enterprise, we released some offerings based on the open-source version of SFTPGo. While these remain fully supported, we recommend migrating to the Enterprise edition for improved performance and more advanced features. You can view all of our supported offerings using this link.</p>"},{"location":"installation/#linux-windows-docker","title":"Linux, Windows, Docker","text":"<p>SFTPGo Enterprise can be installed on Linux, Windows, and in containerized environments using Docker.</p> <ul> <li>APT and YUM repositories are available for Debian-based and RHEL-based distributions.</li> <li>Windows installers are provided for direct setup on Windows systems.</li> <li>A Docker registry is available.</li> </ul> <p>A license key is required to unlock advanced features and to access our Docker repository. Licenses can be purchased or a free trial activated directly from our website.</p> <p>Without a valid license, the application will operate under the Starter license tier, with the following additional limitations:</p> <ul> <li>Concurrent transfers are limited to 2.</li> <li>Plugin support is disabled.</li> </ul>"},{"location":"installation/#apt-repo","title":"APT repo","text":"<p>Supported distributions:</p> <ul> <li>Debian 11 \"bullseye\"</li> <li>Debian 12 \"bookworm\"</li> <li>Debian 13 \"trixie\"</li> <li>Ubuntu 20.04 \"focal\"</li> <li>Ubuntu 22.04 \"jammy\"</li> <li>Ubuntu 24.04 \"noble\"</li> </ul> <p>Import the public key used by the package management system:</p> <pre><code>curl -sS https://download.sftpgo.com/apt/gpg.key | sudo gpg --dearmor -o /usr/share/keyrings/sftpgo-archive-keyring.gpg\n</code></pre> <p>If you receive an error indicating that <code>gnupg</code> is not installed, you can install it using the following command:</p> <pre><code>sudo apt install gnupg\n</code></pre> <p>Create the SFTPGo source list file:</p> <pre><code>CODENAME=`lsb_release -c -s`\necho \"deb [signed-by=/usr/share/keyrings/sftpgo-archive-keyring.gpg] https://download.sftpgo.com/apt ${CODENAME} main\" | sudo tee /etc/apt/sources.list.d/sftpgo.list\n</code></pre> <p>Reload the package database and install SFTPGo:</p> <pre><code>sudo apt update\nsudo apt install sftpgo\n</code></pre>"},{"location":"installation/#yum-repo","title":"Yum repo","text":"<p>The YUM repository can be used on generic Red Hat based distributions as well as on Suse/OpenSuse.</p>"},{"location":"installation/#red-hat-based-distributions","title":"Red Hat based distributions","text":"<p>Create the SFTPGo repository:</p> <pre><code>ARCH=`uname -m`\ncurl -sS https://download.sftpgo.com/yum/${ARCH}/sftpgo.repo | sudo tee /etc/yum.repos.d/sftpgo.repo\n</code></pre> <p>Reload the package database and install SFTPGo:</p> <pre><code>sudo yum update\nsudo yum install sftpgo\n</code></pre> <p>Start the SFTPGo service and enable it to start at system boot:</p> <pre><code>sudo systemctl start sftpgo\nsudo systemctl enable sftpgo\n</code></pre>"},{"location":"installation/#suseopensuse","title":"Suse/OpenSUSE","text":"<p>Import the public key used by the package management system:</p> <pre><code>sudo rpm --import https://download.sftpgo.com/yum/gpg.key\n</code></pre> <p>Add the SFTPGo repository:</p> <pre><code>ARCH=`uname -m`\nsudo zypper addrepo -f \"https://download.sftpgo.com/yum/${ARCH}\" sftpgo\n</code></pre> <p>Reload the package database and install SFTPGo:</p> <pre><code>sudo zypper refresh\nsudo zypper install sftpgo\n</code></pre> <p>Start the SFTPGo service and enable it to start at system boot:</p> <pre><code>sudo systemctl start sftpgo\nsudo systemctl enable sftpgo\n</code></pre>"},{"location":"installation/#windows","title":"Windows","text":"<p>You can download the latest Windows installer using this link. The installer includes the plugins and will automatically register SFTPGo as a Windows service, starting it immediately after installation. Alternatively, SFTPGo can also be installed using winget with the following command: <code>winget install -e --id drakkan.SFTPGoEnterprise</code>.</p> <p>By default, the service runs under the Local System account. However, you can configure it to run under a different user account either through the built-in Windows Services UI or via the command line, as shown below:</p> <pre><code>C:\\Program Files\\SFTPGo&gt;sftpgo.exe service uninstall\nC:\\Program Files\\SFTPGo&gt;sftpgo.exe service install -c \"C:\\ProgramData\\SFTPGo Enterprise\" -l \"logs\\sftpgo.log\" --service-user \"DOMAIN\\username\" --service-password password\n</code></pre> <p>The installer registers SFTPGo as a Windows service only during the initial installation. Future updates will not modify the existing service configuration.</p> <p>To install on systems without a GUI (e.g., Windows Server Core), run the installer with the following flag:</p> <pre><code>sftpgo_windows_x86_64.exe /VERYSILENT\n</code></pre> <p>No progress or confirmation will be shown during installation. To confirm it completed successfully, check that the Windows service was registered:</p> <pre><code>Get-Service -Name \"sftpgo\"\n</code></pre> <p>The installer is built with Inno Setup. For a full list of supported command-line options, see the official documentation.</p>"},{"location":"installation/#docker","title":"Docker","text":"<p>For setup instructions, image details, and access to our Docker registry, please refer to the dedicated Docker page.</p>"},{"location":"installation/#adding-a-license-key","title":"Adding a license key","text":"<p>Without a valid license, the application will operate under the Starter license tier, with the following additional limitations:</p> <ul> <li>Concurrent transfers are limited to 2.</li> <li>Plugin support is disabled.</li> </ul> <p>You can view your license status and add a new license key from the WebAdmin UI by navigating to Server Manager =&gt; License.</p> <p></p> <p>For unattended or CLI-based setups, the license key can also be activated by setting the <code>SFTPGO_LICENSE_KEY</code> environment variable.</p> <pre><code>SFTPGO_LICENSE_KEY=XXXX-XXXX-XXXX-XXXX\n</code></pre>"},{"location":"keyboard-interactive/","title":"Keyboard Interactive Authentication","text":""},{"location":"keyboard-interactive/#keyboard-interactive-authentication","title":"Keyboard Interactive Authentication","text":"<p>Keyboard interactive authentication is, in general, a series of questions asked by the server with responses provided by the client. This authentication method is typically used for multi-factor authentication. There are no restrictions on the number of questions asked on a particular authentication stage; there are also no restrictions on the number of stages involving different sets of questions.</p> <p>To enable keyboard interactive authentication, you must set the absolute path of your authentication program or an HTTP URL using the  <code>keyboard_interactive_auth_hook</code> key in your configuration file.</p> <p>The external program can read the following environment variables to get info about the user trying to authenticate:</p> <ul> <li><code>SFTPGO_AUTHD_USERNAME</code></li> <li><code>SFTPGO_AUTHD_IP</code></li> <li><code>SFTPGO_AUTHD_PASSWORD</code>, this is the hashed password as stored inside the data provider</li> </ul> <p>Global environment variables are cleared, for security reasons, when the script is called. You can set additional environment variables in the \"command\" configuration section.</p> <p>The program must write the questions on its standard output, in a single line, using the following struct JSON serialized:</p> <ul> <li><code>instruction</code>, string. A short description to show to the user that is trying to authenticate. Can be empty or omitted</li> <li><code>questions</code>, list of questions to be asked to the user</li> <li><code>echos</code> list of boolean flags corresponding to the questions (so the lengths of both lists must be the same) and indicating whether user's reply for a particular question should be echoed on the screen while they are typing: true if it should be echoed, or false if it should be hidden.</li> <li><code>check_password</code> optional integer. Ask exactly one question and set this field to <code>1</code> if the expected answer is the user password and you want that SFTPGo checks it for you or to <code>2</code> if the user has the SFTPGo built-in TOTP enabled and the expected answer is the user one time passcode. If the password/passcode is correct, the returned response to the program is <code>OK</code>. If the password is wrong, the program will be terminated and an authentication error will be returned to the user that is trying to authenticate.</li> <li><code>auth_result</code>, integer. Set this field to 1 to indicate successful authentication. 0 is ignored. Any other value means authentication error. If this field is found and it is different from 0 then SFTPGo will not read any other questions from the external program, and it will finalize the authentication.</li> </ul> <p>SFTPGo writes the user answers to the program standard input, one per line, in the same order as the questions. Please be sure that your program receives the answers for all the issued questions before asking for the next ones.</p> <p>Keyboard interactive authentication can be chained to the external authentication. The authentication must finish within 60 seconds.</p> <p>Let's see a very basic example. Our sample keyboard interactive authentication program will ask for 2 sets of questions and accept the user if the answer to the last question is <code>answer3</code>.</p> <pre><code>#!/bin/sh\n\necho '{\"questions\":[\"Question1: \",\"Question2: \"],\"instruction\":\"This is a sample for keyboard interactive authentication\",\"echos\":[true,false]}'\n\nread ANSWER1\nread ANSWER2\n\necho '{\"questions\":[\"Question3: \"],\"instruction\":\"\",\"echos\":[true]}'\n\nread ANSWER3\n\nif test \"$ANSWER3\" = \"answer3\"; then\n  echo '{\"auth_result\":1}'\nelse\n  echo '{\"auth_result\":-1}'\nfi\n</code></pre> <p>and here is an example where SFTPGo checks the user password for you:</p> <pre><code>#!/bin/sh\n\necho '{\"questions\":[\"Password: \"],\"instruction\":\"This is a sample for keyboard interactive authentication\",\"echos\":[false],\"check_password\":1}'\n\nread ANSWER1\n\nif test \"$ANSWER1\" != \"OK\"; then\n  exit 1\nfi\n\necho '{\"questions\":[\"One time token: \"],\"instruction\":\"\",\"echos\":[false]}'\n\nread ANSWER2\n\nif test \"$ANSWER2\" = \"token\"; then\n  echo '{\"auth_result\":1}'\nelse\n  echo '{\"auth_result\":-1}'\nfi\n</code></pre> <p>If the hook is an HTTP URL then it will be invoked as HTTP POST multiple times for each login request. The request body will contain a JSON struct with the following fields:</p> <ul> <li><code>request_id</code>, string. Unique request identifier</li> <li><code>step</code>, integer. Counter starting from 1</li> <li><code>username</code>, string</li> <li><code>ip</code>, string</li> <li><code>password</code>, string. This is the hashed password as stored inside the data provider</li> <li><code>answers</code>, list of string. It will be null for the first request</li> <li><code>questions</code>, list of string. It will contain the previously asked questions. It will be null for the first request</li> </ul> <p>The HTTP response code must be 200 and the body must contain the same JSON struct described for the program.</p> <p>Let's see a basic sample, the configured hook is <code>http://127.0.0.1:8000/keyIntHookPwd</code>, as soon as the user tries to login, SFTPGo makes this HTTP POST request:</p> <pre><code>POST /keyIntHookPwd HTTP/1.1\nHost: 127.0.0.1:8000\nUser-Agent: Go-http-client/1.1\nContent-Length: 189\nContent-Type: application/json\nAccept-Encoding: gzip\n\n{\"request_id\":\"bq1r5r7cdrpd2qtn25ng\",\"username\":\"a\",\"ip\":\"127.0.0.1\",\"step\":1,\"password\":\"$pbkdf2-sha512$150000$ClOPkLNujMTL$XktKy0xuJsOfMYBz+f2bIyPTdbvDTSnJ1q+7+zp/HPq5Qojwp6kcpSIiVHiwvbi8P6HFXI/D3UJv9BLcnQFqPA==\"}\n</code></pre> <p>as you can see in this first requests <code>answers</code> and <code>questions</code> are null.</p> <p>Here is the response that instructs SFTPGo to ask for the user password and to check it:</p> <pre><code>HTTP/1.1 200 OK\nDate: Tue, 31 Mar 2020 21:15:24 GMT\nServer: WSGIServer/0.2 CPython/3.8.2\nContent-Type: application/json\nX-Frame-Options: SAMEORIGIN\nContent-Length: 143\n\n{\"questions\": [\"Password: \"], \"check_password\": 1, \"instruction\": \"This is a sample for keyboard interactive authentication\", \"echos\": [false]}\n</code></pre> <p>The user enters the correct password and so SFTPGo makes a new HTTP POST, please note that the <code>request_id</code> is the same of the previous request, this time the asked <code>questions</code> and the user's <code>answers</code> are not null:</p> <pre><code>POST /keyIntHookPwd HTTP/1.1\nHost: 127.0.0.1:8000\nUser-Agent: Go-http-client/1.1\nContent-Length: 233\nContent-Type: application/json\nAccept-Encoding: gzip\n\n{\"request_id\":\"bq1r5r7cdrpd2qtn25ng\",\"step\":2,\"username\":\"a\",\"ip\":\"127.0.0.1\",\"password\":\"$pbkdf2-sha512$150000$ClOPkLNujMTL$XktKy0xuJsOfMYBz+f2bIyPTdbvDTSnJ1q+7+zp/HPq5Qojwp6kcpSIiVHiwvbi8P6HFXI/D3UJv9BLcnQFqPA==\",\"answers\":[\"OK\"],\"questions\":[\"Password: \"]}\n</code></pre> <p>Here is the HTTP response that instructs SFTPGo to ask for a new question:</p> <pre><code>HTTP/1.1 200 OK\nDate: Tue, 31 Mar 2020 21:15:27 GMT\nServer: WSGIServer/0.2 CPython/3.8.2\nContent-Type: application/json\nX-Frame-Options: SAMEORIGIN\nContent-Length: 66\n\n{\"questions\": [\"Question2: \"], \"instruction\": \"\", \"echos\": [true]}\n</code></pre> <p>As soon as the user answer to this question, SFTPGo will make a new HTTP POST request with the user's answers:</p> <pre><code>POST /keyIntHookPwd HTTP/1.1\nHost: 127.0.0.1:8000\nUser-Agent: Go-http-client/1.1\nContent-Length: 239\nContent-Type: application/json\nAccept-Encoding: gzip\n\n{\"request_id\":\"bq1r5r7cdrpd2qtn25ng\",\"step\":3,\"username\":\"a\",\"ip\":\"127.0.0.1\",\"password\":\"$pbkdf2-sha512$150000$ClOPkLNujMTL$XktKy0xuJsOfMYBz+f2bIyPTdbvDTSnJ1q+7+zp/HPq5Qojwp6kcpSIiVHiwvbi8P6HFXI/D3UJv9BLcnQFqPA==\",\"answers\":[\"answer2\"],\"questions\":[\"Question2: \"]}\n</code></pre> <p>Here is the final HTTP response that allows the user login:</p> <pre><code>HTTP/1.1 200 OK\nDate: Tue, 31 Mar 2020 21:15:29 GMT\nServer: WSGIServer/0.2 CPython/3.8.2\nContent-Type: application/json\nX-Frame-Options: SAMEORIGIN\nContent-Length: 18\n\n{\"auth_result\": 1}\n</code></pre> <p>An example keyboard interactive program allowing to authenticate using Twilio Authy 2FA can be found inside the source tree authy directory.</p>"},{"location":"kms/","title":"Key Management Services","text":""},{"location":"kms/#key-management-services","title":"Key Management Services","text":"<p>SFTPGo stores sensitive data such as Cloud account credentials or passphrases to derive per-object encryption keys. These data are stored as ciphertext and only loaded to RAM in plaintext when needed.</p>"},{"location":"kms/#supported-services-for-encryption-and-decryption","title":"Supported Services for encryption and decryption","text":"<p>The <code>secrets</code> section of the <code>kms</code> configuration allows to configure how to encrypt and decrypt sensitive data. The following configuration parameters are available:</p> <ul> <li><code>url</code> defines the URI to the KMS service</li> <li><code>master_key</code>, defines the master encryption key as string. If not empty, it takes precedence over <code>master_key_path</code>.</li> <li><code>master_key_path</code> defines the absolute path to a file containing the master encryption key. This could be, for example, a docker secret or a file protected with filesystem level permissions.</li> </ul>"},{"location":"kms/#local-provider","title":"Local provider","text":"<p>If the <code>url</code> is empty SFTPGo uses local encryption for keeping secrets. Internally, it uses the NaCl secret box algorithm to perform encryption and authentication.</p> <p>We first generate a random key, then the per-object encryption key is derived from this random key in the following way:</p> <ol> <li>a master key is provided: the encryption key is derived using the HMAC-based Extract-and-Expand Key Derivation Function (HKDF) as defined in RFC 5869</li> <li>no master key is provided: the encryption key is derived as simple hash of the random key. This is the default configuration.</li> </ol> <p>For compatibility with SFTPGo versions 1.2.x and before we also support encryption based on <code>AES-256-GCM</code>. The data encrypted with this algorithm will never use the master key to keep backward compatibility. You can activate it using <code>builtin://</code> as <code>url</code> but this is not recommended.</p>"},{"location":"kms/#cloud-providers","title":"Cloud providers","text":"<p>Several cloud providers are supported using the sftpgo-plugin-kms.</p>"},{"location":"kms/#notes","title":"Notes","text":"<ul> <li>The KMS configuration is global.</li> <li>If you set a master key you will be unable to decrypt the data without this key and the SFTPGo users that need the data as plain text will be unable to login.</li> <li>You can start using the local provider and then switch to an external one but you can't switch between external providers and still be able to decrypt the data encrypted using the previous provider.</li> </ul>"},{"location":"localfs/","title":"Local filesystem","text":""},{"location":"localfs/#local-filesystem","title":"Local filesystem","text":"<p>SFTPGo allow to restrict users to a specified directory on local filesystem, their \"Home Dir\".</p> <p>To add a mapping for a directory outside the Home Dir you have to create a virtual folder, symbolic links outside the home directory are not allowed.</p>"},{"location":"logs/","title":"Logs","text":""},{"location":"logs/#logs","title":"Logs","text":"<p>SFTPGo logs a stream of JSON structs. Each struct has a <code>sender</code> field that identifies the log type. SFTPGo logging options are set either by cli options or environment variables, not in the configuration file. More details.</p> <p>The logs can be divided into the following categories:</p> <p>app logs, internal logs used to debug SFTPGo:</p> <ul> <li><code>sender</code> string. This is generally the package name that emits the log</li> <li><code>time</code> string. Date/time with millisecond precision</li> <li><code>level</code> string</li> <li><code>connection_id</code>, string, optional</li> <li><code>message</code> string</li> </ul> <p>transfer logs, SFTP/SCP transfer logs:</p> <ul> <li><code>sender</code> string. <code>Upload</code> or <code>Download</code></li> <li><code>time</code> string. Date/time with millisecond precision</li> <li><code>level</code> string</li> <li><code>local_addr</code> string. IP/port of the local address the connection arrived on. For FTP protocol this is the address for the control connection. For example <code>127.0.0.1:1234</code></li> <li><code>remote_addr</code> string. IP and, optionally, port of the remote client. For example <code>127.0.0.1:1234</code> or <code>127.0.0.1</code></li> <li><code>elapsed_ms</code>, int64. Elapsed time, as milliseconds, for the upload/download</li> <li><code>size_bytes</code>, int64. Size, as bytes, of the download/upload</li> <li><code>username</code>, string</li> <li><code>file_path</code> string</li> <li><code>connection_id</code> string. Unique connection identifier</li> <li><code>protocol</code> string. <code>SFTP</code>, <code>SCP</code>, <code>SSH</code>, <code>FTP</code>, <code>HTTP</code>, <code>HTTPShare</code>, <code>DAV</code>, <code>DataRetention</code>, <code>EventAction</code></li> <li><code>ftp_mode</code>, string. <code>active</code> or <code>passive</code>. Included only for <code>FTP</code> protocol</li> <li><code>error</code>, string. Included if there is a transfer error</li> </ul> <p>command logs, SFTP/SCP command logs:</p> <ul> <li><code>sender</code> string. <code>Rename</code>, <code>Rmdir</code>, <code>Mkdir</code>, <code>Symlink</code>, <code>Remove</code>, <code>Chmod</code>, <code>Chown</code>, <code>Chtimes</code>, <code>Truncate</code>, <code>Copy</code>, <code>SSHCommand</code></li> <li><code>level</code> string-</li> <li><code>local_addr</code> string. IP/port of the local address the connection arrived on. For example <code>127.0.0.1:1234</code></li> <li><code>remote_addr</code> string. IP and, optionally, port of the remote client. For example <code>127.0.0.1:1234</code> or <code>127.0.0.1</code></li> <li><code>username</code>, string</li> <li><code>file_path</code> string</li> <li><code>target_path</code> string</li> <li><code>filemode</code> string. Valid for sender <code>Chmod</code> otherwise empty</li> <li><code>uid</code> integer. Valid for sender <code>Chown</code> otherwise -1</li> <li><code>gid</code> integer. Valid for sender <code>Chown</code> otherwise -1</li> <li><code>access_time</code> datetime as YYYY-MM-DDTHH:MM:SS. Valid for sender <code>Chtimes</code> otherwise empty</li> <li><code>modification_time</code> datetime as YYYY-MM-DDTHH:MM:SS. Valid for sender <code>Chtimes</code> otherwise empty</li> <li><code>size</code> int64. Valid for sender <code>Truncate</code> otherwise -1</li> <li><code>elapsed</code>, int64. Elapsed time, as milliseconds</li> <li><code>ssh_command</code>, string. Valid for sender <code>SSHCommand</code> otherwise empty</li> <li><code>connection_id</code> string. Unique connection identifier</li> <li><code>protocol</code> string. <code>SFTP</code>, <code>SCP</code>, <code>SSH</code>, <code>FTP</code>, <code>HTTP</code>, <code>DAV</code>, <code>DataRetention</code>, <code>EventAction</code></li> </ul> <p>http logs, REST API logs:</p> <ul> <li><code>sender</code> string. <code>httpd</code></li> <li><code>level</code> string</li> <li><code>time</code> string. Date/time with millisecond precision</li> <li><code>local_addr</code> string. IP/port of the local address the connection arrived on. For example <code>127.0.0.1:1234</code></li> <li><code>remote_addr</code> string. IP and, optionally, port of the remote client. For example <code>127.0.0.1:1234</code> or <code>127.0.0.1</code></li> <li><code>proto</code> string, for example <code>HTTP/1.1</code></li> <li><code>method</code> string. HTTP method (<code>GET</code>, <code>POST</code>, <code>PUT</code>, <code>DELETE</code> etc.)</li> <li><code>request_id</code> string. Omitted in telemetry logs</li> <li><code>user_agent</code> string</li> <li><code>uri</code> string. Full uri</li> <li><code>resp_status</code> integer. HTTP response status code</li> <li><code>resp_size</code> integer. Size in bytes of the HTTP response</li> <li><code>elapsed_ms</code> int64. Elapsed time, as milliseconds, to complete the request</li> <li><code>request_id</code> string. Unique request identifier</li> <li><code>tls_ver</code> string. TLS version. Added for HTTPS</li> <li><code>cipher_suite</code> string. Negotiated cipher suite. Added for HTTPS</li> <li><code>kex</code> string. Key exchange mechanism. Added for HTTPS</li> </ul> <p>connection failed logs, logs for failed attempts to initialize a connection. A connection can fail for an authentication error or other errors such as a client abort or a timeout</p> <ul> <li><code>sender</code> string. <code>connection_failed</code></li> <li><code>level</code> string. <code>debug</code></li> <li><code>time</code> string. Date/time with millisecond precision</li> <li><code>username</code>, string. Can be empty if the connection is closed before an authentication attempt</li> <li><code>client_ip</code> string.</li> <li><code>protocol</code> string. Possible values are <code>SSH</code>, <code>FTP</code>, <code>DAV</code></li> <li><code>login_type</code> string. Can be <code>publickey</code>, <code>password</code>, <code>keyboard-interactive</code>, <code>publickey+password</code>, <code>publickey+keyboard-interactive</code> or <code>no_auth_tried</code></li> <li><code>error</code> string. Optional error description</li> </ul> <p>login logs, logs for successful logins</p> <ul> <li><code>sender</code> string. <code>login</code></li> <li><code>level</code> string. <code>info</code></li> <li><code>time</code> string. Date/time with millisecond precision</li> <li><code>username</code>, string.</li> <li><code>ip</code> string.</li> <li><code>protocol</code> string.</li> <li><code>method</code> string.</li> <li><code>connection_id</code> string. Optional.</li> <li><code>client</code> string. Client software name if available.</li> <li><code>encrypted</code>, boolean</li> <li><code>info</code> string. Optional additional information.</li> </ul>"},{"location":"metrics/","title":"Metrics","text":""},{"location":"metrics/#metrics","title":"Metrics","text":"<p>SFTPGo supports Prometheus metrics at the <code>/metrics</code> HTTP endpoint of the telemetry server. Several counters and gauges are available, for example:</p> <ul> <li>Total uploads and downloads</li> <li>Total upload and download size</li> <li>Total upload and download errors</li> <li>Total executed SSH commands</li> <li>Total SSH command errors</li> <li>Number of active connections</li> <li>Data provider availability</li> <li>Total successful and failed logins using password, public key, keyboard interactive authentication or supported multi-step authentications</li> <li>Total HTTP requests served and totals for response code</li> <li>Go's runtime details about GC, number of goroutines and OS threads</li> <li>Process information like CPU, memory, file descriptor usage and start time</li> </ul> <p>Please check the <code>/metrics</code> page for more details.</p> <p>The telemetry server is disabled by default. To enable check the configuration for details.</p>"},{"location":"oidc/","title":"OpenID Connect","text":""},{"location":"oidc/#openid-connect","title":"OpenID Connect","text":"<p>OpenID Connect integration allows you to map your identity provider users to SFTPGo admins/users, so you can login to SFTPGo Web Client and Web Admin user interfaces, using your own identity provider.</p> <p>SFTPGo allows to configure per-binding OpenID Connect configurations. The supported configuration parameters are documented within the <code>oidc</code> section here.</p> <p>Let's see a basic integration with the Keycloak identify provider. Other OpenID connect compatible providers should work by configuring them in a similar way.</p> <p>We'll not go through the complete process of creating a realm/clients/users in Keycloak. You can look this up here.</p> <p>Here is just an outline:</p> <ul> <li>create a realm named <code>sftpgo</code></li> <li>in \"Realm Settings\" -&gt; \"Login\" adjust the \"Require SSL\" setting as per your requirements and make sure \"Unmanaged Attributes\" are allowed if you want to add custom attributes</li> <li>create a client named <code>sftpgo-client</code></li> <li>for the <code>sftpgo-client</code> set the <code>Access Type</code> to <code>confidential</code> and a valid redirect URI, for example if your SFTPGo instance is running on <code>http://192.168.1.50:8080</code> a valid redirect URI is <code>http://192.168.1.50:8080/*</code></li> <li>for the <code>sftpgo-client</code>, in the <code>Mappers</code> settings, make sure that the username and the sftpgo role are added to the ID token. For example you can add the user attribute <code>sftpgo_role</code> as JSON string to the ID token and the <code>username</code> as <code>preferred_username</code> JSON string to the ID token</li> <li>for your users who need to be mapped as SFTPGo administrators add a custom attribute specifying <code>sftpgo_role</code> as key and <code>admin</code> as value</li> </ul> <p>The resulting JSON configuration for the <code>sftpgo-client</code> that you can obtain from the \"Installation\" tab is something like this:</p> <pre><code>{\n  \"realm\": \"sftpgo\",\n  \"auth-server-url\": \"http://192.168.1.12:8086/auth/\",\n  \"ssl-required\": \"none\",\n  \"resource\": \"sftpgo-client\",\n  \"credentials\": {\n    \"secret\": \"jRsmE0SWnuZjP7djBqNq0mrf8QN77j2c\"\n  },\n  \"confidential-port\": 0\n}\n</code></pre> <p>Add the following configuration parameters to the SFTPGo configuration file.</p> <pre><code>...\n    \"oidc\": {\n      \"client_id\": \"sftpgo-client\",\n      \"client_secret\": \"jRsmE0SWnuZjP7djBqNq0mrf8QN77j2c\",\n      \"config_url\": \"http://192.168.1.12:8086/auth/realms/sftpgo\",\n      \"redirect_base_url\": \"http://192.168.1.50:8080\",\n      \"scopes\": [\n        \"openid\",\n        \"profile\",\n        \"email\"\n      ],\n      \"username_field\": \"preferred_username\",\n      \"role_field\": \"sftpgo_role\",\n      \"implicit_roles\": false,\n      \"custom_fields\": []\n    }\n...\n</code></pre> <p>Alternatively (recommended), you can use environment variables by creating the file <code>oidc.env</code> in the <code>env.d</code> directory with the following content.</p> <pre><code>SFTPGO_HTTPD__BINDINGS__0__OIDC__CLIENT_ID=\"sftpgo-client\"\nSFTPGO_HTTPD__BINDINGS__0__OIDC__CLIENT_SECRET=\"jRsmE0SWnuZjP7djBqNq0mrf8QN77j2c\"\nSFTPGO_HTTPD__BINDINGS__0__OIDC__CONFIG_URL=\"http://192.168.1.12:8086/auth/realms/sftpgo\"\nSFTPGO_HTTPD__BINDINGS__0__OIDC__REDIRECT_BASE_URL=\"http://192.168.1.50:8080\"\nSFTPGO_HTTPD__BINDINGS__0__OIDC__USERNAME_FIELD=\"preferred_username\"\nSFTPGO_HTTPD__BINDINGS__0__OIDC__ROLE_FIELD=\"sftpgo_role\"\n</code></pre> <p>SFTPGo will automatically add the <code>/.well-known/openid-configuration</code> suffix to the provided <code>config_url</code> and uses OpenID Connect Discovery specifications to obtain information needed to interact with it, including its OAuth 2.0 endpoint locations.</p> <p>From SFTPGo login page click <code>Login with OpenID</code> button, you will be redirected to the Keycloak login page, after a successful authentication Keycloack will redirect back to SFTPGo Web Admin or SFTPGo Web Client.</p> <p>Please note that the ID token returned from Keycloak must contain the <code>username_field</code> specified in the SFTPGo configuration and optionally the <code>role_field</code>. The mapped usernames must exist in SFTPGo. If you don't want to explicitly define SFTPGo roles in your identity provider, you can set <code>implicit_roles</code> to <code>true</code>. With this configuration, the SFTPGo role is assumed based on the login link used.</p> <p>Here is an example ID token which allows the SFTPGo admin <code>root</code> to access to the Web Admin UI.</p> <pre><code>{\n    \"exp\": 1644758026,\n    \"iat\": 1644757726,\n    \"auth_time\": 1644757647,\n    \"jti\": \"c6cf172d-08d6-41cf-8e5d-20b7ac0b8011\",\n    \"iss\": \"http://192.168.1.12:8086/auth/realms/sftpgo\",\n    \"aud\": \"sftpgo-client\",\n    \"sub\": \"48b0de4b-3090-4315-bbcb-be63c48be1d2\",\n    \"typ\": \"ID\",\n    \"azp\": \"sftpgo-client\",\n    \"nonce\": \"XLxfYDhMmWwiYctgLTCZjC\",\n    \"session_state\": \"e20ab97c-d3a9-4e53-872d-09d104cbd286\",\n    \"at_hash\": \"UwubF1W8H0XItHU_DIpjfQ\",\n    \"acr\": \"0\",\n    \"sid\": \"e20ab97c-d3a9-4e53-872d-09d104cbd286\",\n    \"email_verified\": false,\n    \"preferred_username\": \"root\",\n    \"sftpgo_role\": \"admin\"\n}\n</code></pre> <p>And the following is an example ID token which allows the SFTPGo user <code>user1</code> to access to the Web Client UI.</p> <pre><code>{\n    \"exp\": 1644758183,\n    \"iat\": 1644757883,\n    \"auth_time\": 1644757647,\n    \"jti\": \"939de932-f941-4b04-90fc-7071b7cc6b10\",\n    \"iss\": \"http://192.168.1.12:8086/auth/realms/sftpgo\",\n    \"aud\": \"sftpgo-client\",\n    \"sub\": \"48b0de4b-3090-4315-bbcb-be63c48be1d2\",\n    \"typ\": \"ID\",\n    \"azp\": \"sftpgo-client\",\n    \"nonce\": \"wxcWPPi3H7ktembUdeToqQ\",\n    \"session_state\": \"e20ab97c-d3a9-4e53-872d-09d104cbd286\",\n    \"at_hash\": \"RSDpwzVG_6G2haaNF0jsJQ\",\n    \"acr\": \"0\",\n    \"sid\": \"e20ab97c-d3a9-4e53-872d-09d104cbd286\",\n    \"email_verified\": false,\n    \"preferred_username\": \"user1\"\n}\n</code></pre> <p>SFTPGo users (not admins) can be created/updated after successful OpenID authentication by defining a pre-login hook. Users and admins can also be created/updated after successful OpenID authentication using the EventManager. You can use <code>scopes</code> configuration to request additional information (claims) about authenticated users (See your provider's own documentation for more information). By default the scopes <code>\"openid\", \"profile\", \"email\"</code> are retrieved. The <code>custom_fields</code> configuration parameter can be used to define claim field names to pass to the pre-login hook, these fields can be used e.g. for implementing custom logic when creating/updating the SFTPGo user within the hook. For example, if you have created a scope with name <code>sftpgo</code> in your identity provider to provide a claim for <code>sftpgo_home_dir</code> , then you can add it to the <code>custom_fields</code> in the SFTPGo configuration like this:</p> <pre><code>...\n    \"oidc\": {\n      \"client_id\": \"sftpgo-client\",\n      \"client_secret\": \"jRsmE0SWnuZjP7djBqNq0mrf8QN77j2c\",\n      \"config_url\": \"http://192.168.1.12:8086/auth/realms/sftpgo\",\n      \"redirect_base_url\": \"http://192.168.1.50:8080\",\n      \"username_field\": \"preferred_username\",\n      \"scopes\": [ \"openid\", \"profile\", \"email\", \"sftpgo\" ],\n      \"role_field\": \"sftpgo_role\",\n      \"custom_fields\": [\"sftpgo_home_dir\"]\n    }\n...\n</code></pre> <p>Alternatively (recommended), you can use environment variables by creating the file <code>oidc.env</code> in the <code>env.d</code> directory with the following content.</p> <pre><code>SFTPGO_HTTPD__BINDINGS__0__OIDC__CLIENT_ID=\"sftpgo-client\"\nSFTPGO_HTTPD__BINDINGS__0__OIDC__CLIENT_SECRET=\"jRsmE0SWnuZjP7djBqNq0mrf8QN77j2c\"\nSFTPGO_HTTPD__BINDINGS__0__OIDC__CONFIG_URL=\"http://192.168.1.12:8086/auth/realms/sftpgo\"\nSFTPGO_HTTPD__BINDINGS__0__OIDC__REDIRECT_BASE_URL=\"http://192.168.1.50:8080\"\nSFTPGO_HTTPD__BINDINGS__0__OIDC__USERNAME_FIELD=\"preferred_username\"\nSFTPGO_HTTPD__BINDINGS__0__OIDC__SCOPES=\"openid,profile,email,sftpgo\"\nSFTPGO_HTTPD__BINDINGS__0__OIDC__ROLE_FIELD=\"sftpgo_role\"\nSFTPGO_HTTPD__BINDINGS__0__OIDC__CUSTOM_FIELDS=\"sftpgo_home_dir\"\n</code></pre> <p>The pre-login hook will receive a JSON serialized user with the following field:</p> <pre><code>...\n  \"oidc_custom_fields\": {\n    \"sftpgo_home_dir\": \"configured value\"\n  },\n...\n</code></pre> <p>In EventManager actions you can use the placeholder <code>{{.IDPFieldsftpgo_home_dir}}</code> for string-based custom fields.</p>"},{"location":"password/","title":"Password Hashing","text":""},{"location":"password/#supported-password-hashing-algorithms","title":"Supported Password Hashing Algorithms","text":"<p>SFTPGo can verify passwords in several formats and uses, by default, the <code>bcrypt</code> algorithm to hash passwords in plain-text before storing them inside the data provider. Each hashing algorithm is identified by a prefix. Supported hash algorithms:</p> <ul> <li>bcrypt, prefix <code>$2a$</code></li> <li>argon2id, prefix <code>$argon2id$</code></li> <li>PBKDF2 sha1, prefix <code>$pbkdf2-sha1$</code></li> <li>PBKDF2 sha256, prefix <code>$pbkdf2-sha256$</code></li> <li>PBKDF2 sha512, prefix <code>$pbkdf2-sha512$</code></li> <li>PBKDF2 sha256 with base64 salt, prefix <code>$pbkdf2-b64salt-sha256$</code></li> <li>MD5 crypt, prefix <code>$1$</code></li> <li>MD5 crypt APR1, prefix <code>$apr1$</code></li> <li>SHA256 crypt, prefix <code>$5$</code></li> <li>SHA512 crypt, prefix <code>$6$</code></li> <li>yescrypt, prefix <code>$y$</code></li> <li>MD5 digest, prefix <code>{MD5}</code></li> <li>SHA256 digest, prefix <code>{SHA256}</code></li> <li>SHA512 digest, prefix <code>{SHA512}</code></li> </ul> <p>If you set a password with one of these prefixes it will not be hashed. When users log in, if their passwords are stored with anything other than the preferred algorithm, SFTPGo will automatically upgrade the algorithm to the preferred one.</p>"},{"location":"performance/","title":"Performance","text":""},{"location":"performance/#performance","title":"Performance","text":"<p>SFTPGo can easily saturate a Gigabit connection on low end hardware with no special configuration, this is generally enough for most use cases.</p> <p>For Multi-Gig connections, some performance improvements and comparisons with OpenSSH have been discussed here, most of them have been included in the main branch. To summarize:</p> <ul> <li>In current state with all performance improvements applied, SFTP performance is very close to OpenSSH however CPU usage is higher. SCP performance match OpenSSH.</li> <li>The main bottlenecks are the encryption and the messages authentication, so if you can use a fast cipher with implicit messages authentication, such as <code>aes128-gcm@openssh.com</code>, you will get a big performance boost.</li> <li>SCP protocol is much simpler than SFTP and so, the multi-platform, SFTPGo's SCP implementation performs better than SFTP.</li> <li>Load balancing with HAProxy can greatly improve the performance if CPU not become the bottleneck.</li> </ul>"},{"location":"performance/#benchmark","title":"Benchmark","text":""},{"location":"performance/#hardware-specification","title":"Hardware specification","text":"Server OS Debian 10.2 x64 CPU Ryzen5 3600 RAM 64GB 2400MHz ECC Disk Ramdisk Ethernet Mellanox ConnectX-3 40GbE Client OS Ubuntu 19.10 x64 CPU Threadripper 1920X RAM 64GB 2400MHz ECC Disk Ramdisk Ethernet Mellanox ConnectX-3 40GbE"},{"location":"performance/#test-configurations","title":"Test configurations","text":"<ul> <li><code>Baseline</code>: SFTPGo version 0.9.6.</li> <li><code>Devel</code>: SFTPGo commit b0ed1905918b9dcc22f9a20e89e354313f491734, compiled with Golang 1.14.2. This is basically the same as v1.0.0 as far as performance is concerned.</li> <li><code>Optimized</code>: Various optimizations applied on top of <code>Devel</code>.</li> <li><code>Balanced</code>: Two optimized instances, running on localhost, load balanced by HAProxy 2.1.3.</li> <li><code>OpenSSH</code>: OpenSSH_7.9p1 Debian-10+deb10u2, OpenSSL 1.1.1d  10 Sep 2019</li> </ul> <p>Server's CPU is in Eco mode, you can expect better results in certain cases with a stronger CPU, especially multi-stream HAProxy balanced load.</p>"},{"location":"performance/#cipher-aes128-ctr","title":"Cipher aes128-ctr","text":"<p>The Message Authentication Code (MAC) used is <code>hmac-sha2-256</code>.</p>"},{"location":"performance/#sftp","title":"SFTP","text":"<p>Download:</p> Stream Baseline MB/s Devel MB/s Optimized MB/s Balanced MB/s OpenSSH MB/s 1 150 243 319 412 452 2 267 452 600 740 735 3 351 637 802 991 1045 4 414 811 1002 1192 1265 8 536 1451 1742 1552 1798 <p>Upload:</p> Stream Baseline MB/s Devel MB/s Optimized MB/s Balanced MB/s OpenSSH MB/s 1 172 273 343 407 426 2 284 469 595 673 738 3 368 644 820 881 1090 4 446 851 1041 1026 1244 8 605 1210 1368 1273 1820"},{"location":"performance/#scp","title":"SCP","text":"<p>Download:</p> Stream Baseline MB/s Devel MB/s Optimized MB/s Balanced MB/s OpenSSH MB/s 1 220 369 525 611 558 2 437 659 941 1048 856 3 635 1000 1365 1363 1201 4 787 1272 1664 1610 1415 8 1297 2129 2690 2100 1959 <p>Upload:</p> Stream Baseline MB/s Devel MB/s Optimized MB/s Balanced MB/s OpenSSH MB/s 1 208 312 400 458 508 2 360 516 647 745 926 3 476 678 861 935 1254 4 576 836 1080 1099 1569 8 857 1161 1416 1433 2271"},{"location":"performance/#cipher-aes128-gcmopensshcom","title":"Cipher aes128-gcm@openssh.com","text":"<p>With this cipher the messages authentication is implicit, no SHA256 computation is needed.</p>"},{"location":"performance/#sftp_1","title":"SFTP","text":"<p>Download:</p> Stream Baseline MB/s Devel MB/s Optimized MB/s Balanced MB/s OpenSSH MB/s 1 332 423 &lt;-- 583 443 2 533 755 &lt;-- 970 809 3 666 1045 &lt;-- 1249 1098 4 762 1276 &lt;-- 1461 1351 8 886 2064 &lt;-- 1825 1933 <p>Upload:</p> Stream Baseline MB/s Devel MB/s Optimized MB/s Balanced MB/s OpenSSH MB/s 1 348 410 &lt;-- 527 469 2 596 729 &lt;-- 842 930 3 778 974 &lt;-- 1088 1341 4 886 1192 &lt;-- 1232 1494 8 1042 1578 &lt;-- 1433 1893"},{"location":"performance/#scp_1","title":"SCP","text":"<p>Download:</p> Stream Baseline MB/s Devel MB/s Optimized MB/s Balanced MB/s OpenSSH MB/s 1 776 793 &lt;-- 832 578 2 1343 1415 &lt;-- 1435 938 3 1815 1878 &lt;-- 1877 1279 4 2192 2205 &lt;-- 2056 1567 8 3237 3287 &lt;-- 2493 2036 <p>Upload:</p> Stream Baseline MB/s Devel MB/s Optimized MB/s Balanced MB/s OpenSSH MB/s 1 528 545 &lt;-- 608 584 2 872 849 &lt;-- 975 1019 3 1121 1138 &lt;-- 1217 1412 4 1367 1387 &lt;-- 1368 1755 8 1733 1744 &lt;-- 1664 2510"},{"location":"performance/#optimizations-applied","title":"Optimizations applied","text":"<ul> <li>AES-CTR optimization of Go compiler for x86_64, there is a patch that hasn't been merged yet.</li> </ul>"},{"location":"performance/#haproxy-configuration","title":"HAProxy configuration","text":"<p>Here is the relevant HAProxy configuration used for the <code>Balanced</code> test configuration:</p> <pre><code>frontend sftp\n    bind   :2222\n    mode   tcp\n    timeout  client  600s\n    default_backend sftpgo\n\nbackend sftpgo\n    mode    tcp\n    balance roundrobin\n    timeout connect 10s\n    timeout server  600s\n    timeout queue   30s\n    option  tcp-check\n    tcp-check expect string SSH-2.0-\n\n    server sftpgo1 127.0.0.1:2022 check send-proxy-v2 weight 10 inter 10s rise 2 fall 3\n    server sftpgo2 127.0.0.1:2024 check send-proxy-v2 weight 10 inter 10s rise 2 fall 3\n</code></pre>"},{"location":"plugins/","title":"Plugin system","text":""},{"location":"plugins/#plugin-system","title":"Plugin system","text":"<p>SFTPGo's plugins are completely separate, standalone applications that SFTPGo executes and communicates with over RPC. This means the plugin process does not share the same memory space as SFTPGo and therefore can only access the interfaces and arguments given to it. This also means a crash in a plugin can not crash the entirety of SFTPGo.</p>"},{"location":"plugins/#configuration","title":"Configuration","text":"<p>The plugins are configured via the <code>plugins</code> section in the main SFTPGo configuration file. You basically have to set the path to your plugin, the plugin type and any plugin specific configuration parameters. If you set the SHA256 checksum for the plugin executable, SFTPGo will verify the plugin integrity before starting it.</p> <p>For added security you can enable the automatic TLS. In this way, the client and the server automatically negotiate mutual TLS for transport authentication. This ensures that only the original client will be allowed to connect to the server, and all other connections will be rejected. The client will also refuse to connect to any server that isn't the original instance started by the client.</p> <p>The following plugin types are supported:</p> <ul> <li><code>auth</code>, allows to authenticate users.</li> <li><code>notifier</code>, allows to receive notifications for supported filesystem events such as file uploads, downloads etc. and provider events such as objects add, update, delete.</li> <li><code>kms</code>, allows to support additional KMS providers.</li> <li><code>ipfilter</code>, allows to allow/deny access based on client IP.</li> </ul> <p>Full configuration details can be found here.</p> <p> Please note that the plugin system is experimental, the configuration parameters and interfaces may change in a backward incompatible way in future.</p>"},{"location":"plugins/#available-plugins","title":"Available plugins","text":"<p>Some \"official\" supported plugins can be found here.</p>"},{"location":"plugins/#plugin-development","title":"Plugin Development","text":"<p> Advanced topic! Plugin development is a highly advanced topic in SFTPGo, and is not required knowledge for day-to-day usage. If you don't plan on writing any plugins, we recommend not reading this section of the documentation.</p> <p>Because SFTPGo communicates to plugins over a RPC interface, you can build and distribute a plugin for SFTPGo without having to rebuild SFTPGo itself.</p> <p>In theory, because the plugin interface is HTTP, you could even develop a plugin using a completely different programming language! (Disclaimer, you would also have to re-implement the plugin API which is not a trivial amount of work).</p> <p>Developing a plugin is simple. The only knowledge necessary to write a plugin is basic command-line skills and basic knowledge of the Go programming language.</p> <p>Your plugin implementation needs to satisfy the interface for the plugin type you want to build. You can find these definitions in the docs.</p> <p>The SFTPGo plugin system uses the HashiCorp go-plugin library. Please refer to its documentation for more in-depth information on writing plugins.</p>"},{"location":"post-connect-hook/","title":"Post-connect","text":""},{"location":"post-connect-hook/#post-connect-hook","title":"Post-connect hook","text":"<p>This hook is executed as soon as a new connection is established. It notifies the connection's IP address and protocol. Based on the received response, the connection is accepted or rejected. Combining this hook with the Post-login hook you can implement your own (even for Protocol) blocklist/allowlist of IP addresses.</p> <p>The <code>post_connect_hook</code> can be defined as the absolute path of your program or an HTTP URL.</p> <p>If the hook defines an external program it can read the following environment variables:</p> <ul> <li><code>SFTPGO_CONNECTION_IP</code></li> <li><code>SFTPGO_CONNECTION_PROTOCOL</code>, possible values are <code>SSH</code>, <code>FTP</code>, <code>DAV</code>, <code>HTTP</code>, <code>OIDC</code> (OpenID Connect)</li> </ul> <p>If the external command completes with a zero exit status the connection will be accepted otherwise rejected.</p> <p>Global environment variables are cleared, for security reasons, when the script is called. You can set additional environment variables in the \"command\" configuration section. The program must finish within 20 seconds.</p> <p>If the hook defines an HTTP URL then this URL will be invoked as HTTP GET with the following query parameters:</p> <ul> <li><code>ip</code></li> <li><code>protocol</code>, possible values are <code>SSH</code>, <code>FTP</code>, <code>DAV</code>, <code>HTTP</code>, <code>HTTPShare</code>, <code>OIDC</code> (OpenID Connect)</li> </ul> <p>The connection is accepted if the HTTP response code is <code>200</code> otherwise rejected.</p> <p>The HTTP hook will use the global configuration for HTTP clients and will respect the retry, TLS and headers configurations. See the HTTP Clients (<code>http</code>) section of the config reference.</p>"},{"location":"post-disconnect-hook/","title":"Post-disconnect","text":""},{"location":"post-disconnect-hook/#post-disconnect-hook","title":"Post-disconnect hook","text":"<p>This hook is executed as soon as a SSH/FTP connection is closed. SSH is a multiplexing protocol, a client can open multiple channels on a single connection or can disconnect without opening any channels. For SSH-based connections (SFTP/SCP/SSH commands), SFTPGo notifies the disconnection of the channel so there is no exact match with the post-connect hook.</p> <p>The hook is not executed for stateless protocols such as HTTP and WebDAV.</p> <p>The <code>post_disconnect_hook</code> can be defined as the absolute path of your program or an HTTP URL.</p> <p>If the hook defines an external program it can read the following environment variables:</p> <ul> <li><code>SFTPGO_CONNECTION_IP</code></li> <li><code>SFTPGO_CONNECTION_PROTOCOL</code>, possible values are <code>SSH</code>, <code>FTP</code>, <code>DAV</code>, <code>HTTP</code>, <code>OIDC</code> (OpenID Connect)</li> <li><code>SFTPGO_CONNECTION_USERNAME</code>, can be empty if the channel is closed before user authentication</li> <li><code>SFTPGO_CONNECTION_DURATION</code>, connection duration in milliseconds</li> </ul> <p>Global environment variables are cleared, for security reasons, when the script is called. You can set additional environment variables in the \"command\" configuration section. The program must finish within 20 seconds.</p> <p>If the hook defines an HTTP URL then this URL will be invoked as HTTP GET with the following query parameters:</p> <ul> <li><code>ip</code></li> <li><code>protocol</code>, possible values are <code>SSH</code>, <code>FTP</code>, <code>DAV</code>, <code>HTTP</code>, <code>OIDC</code> (OpenID Connect)</li> <li><code>username</code>, can be empty if the channel is closed before user authentication</li> <li><code>connection_duration</code>, connection duration in milliseconds</li> </ul> <p>The HTTP hook will use the global configuration for HTTP clients and will respect the retry, TLS and headers configurations. See the HTTP Clients (<code>http</code>) section of the config reference.</p>"},{"location":"post-login-hook/","title":"Post-login","text":""},{"location":"post-login-hook/#post-login-hook","title":"Post-login hook","text":"<p>This hook is executed after a login or after closing a connection for authentication timeout. Defining an appropriate <code>post_login_scope</code> you can get notifications for failed logins, successful logins or both.</p> <p>The <code>post-login-hook</code> can be defined as the absolute path of your program or an HTTP URL.</p> <p>If the hook defines an external program it can reads the following environment variables:</p> <ul> <li><code>SFTPGO_LOGIND_USER</code>, it contains the user serialized as JSON. The username is empty if the connection is closed for authentication timeout</li> <li><code>SFTPGO_LOGIND_IP</code></li> <li><code>SFTPGO_LOGIND_METHOD</code>, possible values are <code>publickey</code>, <code>password</code>, <code>keyboard-interactive</code>, <code>publickey+password</code>, <code>publickey+keyboard-interactive</code>, <code>TLSCertificate</code>, <code>TLSCertificate+password</code> or <code>no_auth_tried</code>, <code>IDP</code> (external identity provider)</li> <li><code>SFTPGO_LOGIND_STATUS</code>, 1 means login OK, 0 login KO</li> <li><code>SFTPGO_LOGIND_PROTOCOL</code>, possible values are <code>SSH</code>, <code>FTP</code>, <code>DAV</code>, <code>HTTP</code>, <code>OIDC</code> (OpenID Connect)</li> </ul> <p>Global environment variables are cleared, for security reasons, when the script is called. You can set additional environment variables in the \"command\" configuration section. The program must finish within 20 seconds.</p> <p>If the hook is an HTTP URL then it will be invoked as HTTP POST. The login method, the used protocol, the ip address and the status of the user are added to the query string, for example <code>&lt;http_url&gt;?login_method=password&amp;ip=1.2.3.4&amp;protocol=SSH&amp;status=1</code>. The request body will contain the user serialized as JSON.</p> <p>The structure for SFTPGo users can be found within the OpenAPI schema.</p> <p>The HTTP hook will use the global configuration for HTTP clients and will respect the retry, TLS and headers configurations. See the HTTP Clients (<code>http</code>) section of the config reference.</p> <p>The <code>post_login_scope</code> supports the following configuration values:</p> <ul> <li><code>0</code> means notify both failed and successful logins</li> <li><code>1</code> means notify failed logins. Connections closed for authentication timeout are notified as failed logins. You will get an empty username in this case</li> <li><code>2</code> means notify successful logins</li> </ul>"},{"location":"profiling/","title":"Profiling","text":""},{"location":"profiling/#profiling-sftpgo","title":"Profiling SFTPGo","text":"<p>The built-in profiler lets you collect CPU profiles, traces, allocations and heap profiles that allow to identify and correct specific bottlenecks. You can enable the built-in profiler using <code>telemetry</code> configuration section inside the configuration file.</p> <p>Profiling data are available via HTTP/HTTPS in the format expected by the pprof visualization tool. You can find the index page at the URL <code>/debug/pprof/</code>.</p> <p>The following profiles are available, you can obtain them via HTTP GET requests:</p> <ul> <li><code>allocs</code>, a sampling of all past memory allocations</li> <li><code>block</code>, stack traces that led to blocking on synchronization primitives</li> <li><code>goroutine</code>, stack traces of all current goroutines</li> <li><code>heap</code>, a sampling of memory allocations of live objects. You can specify the <code>gc</code> GET parameter to run GC before taking the heap sample</li> <li><code>mutex</code>, stack traces of holders of contended mutexes</li> <li><code>profile</code>, CPU profile. You can specify the duration in the <code>seconds</code> GET parameter. After you get the profile file, use the <code>go tool pprof</code> command to investigate the profile</li> <li><code>threadcreate</code>, stack traces that led to the creation of new OS threads</li> <li><code>trace</code>, a trace of execution of the current program. You can specify the duration in the <code>seconds</code> GET parameter. After you get the trace file, use the <code>go tool trace</code> command to investigate the trace</li> </ul> <p>For example you can:</p> <ul> <li>download a 30 seconds CPU profile from the URL <code>/debug/pprof/profile?seconds=30</code></li> <li>download a sampling of memory allocations of live objects from the URL <code>/debug/pprof/heap?gc=1</code></li> <li>download a sampling of all past memory allocations from the URL <code>/debug/pprof/allocs</code></li> </ul>"},{"location":"rate-limiting/","title":"Rate limiting","text":""},{"location":"rate-limiting/#rate-limiting","title":"Rate limiting","text":"<p>Rate limiting allows to control the number of requests going to the SFTPGo services.</p> <p>SFTPGo implements a token bucket initially full and refilled at the configured rate. The <code>burst</code> configuration parameter defines the size of the bucket. The rate is defined by dividing <code>average</code> by <code>period</code>, so for a rate below 1 req/s, one needs to define a period larger than a second.</p> <p>Requests that exceed the configured limit will be delayed or denied if they exceed the maximum delay time.</p> <p>SFTPGo allows to define per-protocol rate limiters so you can have different configurations for different protocols.</p> <p>The supported protocols are:</p> <ul> <li><code>SSH</code>, includes SFTP and SSH commands</li> <li><code>FTP</code>, includes FTP, FTPES, FTPS</li> <li><code>DAV</code>, WebDAV</li> <li><code>HTTP</code>, REST API and web admin</li> </ul> <p>You can also define two types of rate limiters:</p> <ul> <li>global, it is independent from the source host and therefore define an aggregate limit for the configured protocol/s</li> <li>per-host, this type of rate limiter can be connected to the built-in defender and generate <code>score_limit_exceeded</code> events and thus hosts that repeatedly exceed the configured limit can be automatically blocked</li> </ul> <p>If you configure a per-host rate limiter, SFTPGo will keep a rate limiter in memory for each host that connects to the service, you can limit the memory usage using the <code>entries_soft_limit</code> and <code>entries_hard_limit</code> configuration keys.</p> <p>You can exclude a list of IP addresses and IP ranges from rate limiters by adding them to rate limites allow list using the WebAdmin UI or the REST API. In multi-nodes setups, the list entries propagation between nodes may take some minutes.</p> <p>You can define as many rate limiters as you want, but keep in mind that if you define multiple rate limiters each request will be checked against all the configured limiters and so it can potentially be delayed multiple times. Let's clarify with an example, here is a configuration that defines a global rate limiter and a per-host rate limiter for the SSH and FTP protocols:</p> <pre><code>\"rate_limiters\": [\n    {\n      \"average\": 100,\n      \"period\": 1000,\n      \"burst\": 1,\n      \"type\": 1,\n      \"protocols\": [\n        \"SSH\",\n        \"FTP\",\n        \"DAV\",\n        \"HTTP\"\n      ],\n      \"generate_defender_events\": false,\n      \"entries_soft_limit\": 100,\n      \"entries_hard_limit\": 150\n    },\n    {\n      \"average\": 10,\n      \"period\": 1000,\n      \"burst\": 1,\n      \"type\": 2,\n      \"protocols\": [\n        \"SSH\",\n        \"FTP\"\n      ],\n      \"generate_defender_events\": true,\n      \"entries_soft_limit\": 100,\n      \"entries_hard_limit\": 150\n    }\n]\n</code></pre> <p>Alternatively (recommended), you can use environment variables by creating the file <code>/etc/sftpgo/env.d/rate-limiting.env</code> with the following content.</p> <pre><code>SFTPGO_COMMON__RATE_LIMITERS__0__AVERAGE=100\nSFTPGO_COMMON__RATE_LIMITERS__0__PERIOD=1000\nSFTPGO_COMMON__RATE_LIMITERS__0__BURST=1\nSFTPGO_COMMON__RATE_LIMITERS__0__TYPE=1\nSFTPGO_COMMON__RATE_LIMITERS__0__PROTOCOLS=SSH,FTP,DAV,HTTP\nSFTPGO_COMMON__RATE_LIMITERS__0__GENERATE_DEFENDER_EVENTS=0\nSFTPGO_COMMON__RATE_LIMITERS__0__ENTRIES_SOFT_LIMIT=100\nSFTPGO_COMMON__RATE_LIMITERS__0__ENTRIES_HARD_LIMIT=150\nSFTPGO_COMMON__RATE_LIMITERS__1__AVERAGE=10\nSFTPGO_COMMON__RATE_LIMITERS__1__PERIOD=1000\nSFTPGO_COMMON__RATE_LIMITERS__1__BURST=1\nSFTPGO_COMMON__RATE_LIMITERS__1__TYPE=2\nSFTPGO_COMMON__RATE_LIMITERS__1__PROTOCOLS=SSH,FTP\nSFTPGO_COMMON__RATE_LIMITERS__1__GENERATE_DEFENDER_EVENTS=1\nSFTPGO_COMMON__RATE_LIMITERS__1__ENTRIES_SOFT_LIMIT=100\nSFTPGO_COMMON__RATE_LIMITERS__1__ENTRIES_HARD_LIMIT=150\n</code></pre> <p>We have a global rate limiter that limit the aggregate rate for the all the services to 100 req/s and an additional rate limiter that limits <code>SSH</code> and <code>FTP</code> protocols to 10 req/s per host. With this configuration, when a client connects via SSH and FTP will be limited first by the global rate limiter and then by the per host rate limiter. Clients connecting via WebDAV or HTTP will be checked only against the global rate limiter.</p>"},{"location":"rest-api/","title":"REST API","text":""},{"location":"rest-api/#rest-api","title":"REST API","text":"<p>SFTPGo provides a comprehensive REST API that enables full programmatic control of the system. The API is divided into two distinct areas:</p> <ul> <li>Admin API: When authenticated as an administrator, you can manage users, groups, virtual folders, quotas, and system settings.</li> <li>User API: When authenticated as a regular user, you can perform file uploads and downloads, manage shares, and handle other file-related operations programmatically.</li> </ul>"},{"location":"rest-api/#security-and-authentication","title":"Security and Authentication","text":"<p>The REST API is secured using JSON Web Tokens (JWT) or API key authentication. We strongly recommend to enable HTTPS to protect data in transit. For enhanced security, client certificate authentication can also be configured in conjunction with JWT, adding an additional layer of trust verification.</p>"},{"location":"rest-api/#configuration","title":"Configuration","text":"<p>The REST API feature can be enabled or disabled through the <code>httpd</code> configuration section on a per-binding basis, giving you flexibility in controlling API availability.</p>"},{"location":"rest-api/#documentation-and-client-generation","title":"Documentation and Client Generation","text":"<p>Complete and up-to-date API documentation is available in OpenAPI format, allowing developers to explore all endpoints, request parameters, and response formats.</p> <p>Using this OpenAPI specification, you can easily generate client libraries or custom integrations in your preferred programming languages. Tools such as Swagger Codegen and OpenAPI Generator support generating clients ranging from Python, Java, and JavaScript to simple bash scripts, streamlining the integration process.</p>"},{"location":"rest-api/#examples","title":"Examples","text":"<p>Below are practical examples using <code>curl</code> and <code>jq</code> to interact with the API.</p>"},{"location":"rest-api/#admin-api-creating-a-user","title":"Admin API: Creating a User","text":"<p>To perform administrative tasks, you must first obtain an access token. Below are two examples: creating a user with direct configuration and creating a user that inherits settings from a group.</p>"},{"location":"rest-api/#authentication-common-step","title":"Authentication (Common Step)","text":"<p>First, obtain the JWT token using your admin credentials. You will need this token for all subsequent requests.</p> <pre><code># SFTPGo endpoint and credentials\nENDPOINT=\"https://sftpgo.example.com\"\nADMIN_USER=\"admin\"\nADMIN_PASSWORD=\"your_admin_password\"\n\n# Get the JWT Token\nTOKEN=$(curl --anyauth -s -u \"${ADMIN_USER}:${ADMIN_PASSWORD}\" \\\n  \"${ENDPOINT}/api/v2/token\" | jq -r .access_token)\n\necho \"Token acquired.\"\n</code></pre>"},{"location":"rest-api/#case-a-creating-a-standalone-user-no-group","title":"Case A: Creating a Standalone User (No Group)","text":"<p>In this scenario, you explicitly define the file system settings (S3 bucket, region, and key prefix) directly in the user payload.</p> <pre><code># Define the payload for a standalone user\n# We configure the S3 backend explicitly here.\nUSER_PAYLOAD=$(cat &lt;&lt;EOF\n{\n  \"status\": 1,\n  \"username\": \"testuser_standalone\",\n  \"password\": \"clear_text_complex_password\",\n  \"permissions\": {\n    \"/\": [\"*\"]\n  },\n  \"filesystem\": {\n    \"provider\": 1,\n    \"s3config\": {\n      \"bucket\": \"testbucket\",\n      \"region\": \"eu-central-1\",\n      \"access_key\": \"myaccesskey\",\n      \"access_secret\": {\n        \"status\": \"Plain\",\n        \"payload\": \"myaccesssecret\"\n      },\n      \"key_prefix\": \"users/testuser_standalone/\"\n    }\n  }\n}\nEOF\n)\n\n# Create the user\ncurl -X POST \\\n  -H \"Authorization: Bearer ${TOKEN}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d \"${USER_PAYLOAD}\" \\\n  \"${ENDPOINT}/api/v2/users\"\n</code></pre>"},{"location":"rest-api/#case-b-creating-a-user-with-group-membership","title":"Case B: Creating a User with Group Membership","text":"<p>In this scenario, the user inherits the file system configuration from a Primary Group. Note: The group specified in the payload (e.g., <code>BasicUsers</code>) must already exist in SFTPGo.</p> <pre><code>GROUP_NAME=\"BasicUsers\"\n\n# Define the payload for a group-based user\n# Note:\n# 1. We assign the user to a Primary Group (type: 1).\n# 2. Since the Group handles the filesystem, we can pass dummy/invalid values \n#    for the user's explicit filesystem configuration.\nUSER_PAYLOAD=$(cat &lt;&lt;EOF\n{\n  \"status\": 1,\n  \"username\": \"testuser_group\",\n  \"password\": \"clear_text_complex_password\",\n  \"groups\": [\n    {\n      \"type\": 1, \n      \"name\": \"${GROUP_NAME}\"\n    }\n  ],\n  \"permissions\": {\n    \"/\": [\"*\"]\n  },\n  \"filesystem\": {\n    \"provider\": 1,\n    \"s3config\": {\n      \"bucket\": \"invalid\",\n      \"region\": \"invalid\"\n    }\n  }\n}\nEOF\n)\n\n# Create the user\ncurl -X POST \\\n  -H \"Authorization: Bearer ${TOKEN}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d \"${USER_PAYLOAD}\" \\\n  \"${ENDPOINT}/api/v2/users\"\n</code></pre>"},{"location":"rest-api/#user-api-file-operations","title":"User API: File Operations","text":"<p>Regular users can also use the API to manage their own files. The authentication endpoint for users is different from the admin one (<code>/api/v2/user/token</code>).</p> <p>Important: URL Encoding When specifying file paths in the path query parameter (e.g., for files inside subdirectories or filenames with spaces), you must URL encode the value.</p> <ul> <li>Example: <code>my_dir/file.txt</code> becomes <code>my_dir%2Ffile.txt</code></li> <li>Example: <code>my file.txt</code> becomes <code>my%20file.txt</code></li> </ul> <p>The following example shows how to list directories, upload a file, and download it back.</p> <pre><code>#!/bin/bash\n\n# SFTPGo endpoint and user credentials\nENDPOINT=\"https://sftpgo.example.com\"\nUSERNAME=\"testuser\"\nPASSWORD=\"clear_text_complex_password\"\n\n# 1. Get the User JWT Token\n# Note the endpoint is /api/v2/user/token\nTOKEN=$(curl --anyauth -s -u \"${USERNAME}:${PASSWORD}\" \\\n  \"${ENDPOINT}/api/v2/user/token\" | jq -r .access_token)\n\necho \"User Token acquired.\"\n\n# 2. List directory contents\necho \"--- Home Directory Contents ---\"\ncurl -s -H \"Authorization: Bearer ${TOKEN}\" \"${ENDPOINT}/api/v2/user/dirs\" | jq .\necho \"-------------------------------\"\n\n# 3. Upload a file to a subdirectory\n# We want to upload to: \"my_subdir/uploaded_file.txt\"\n# We must URL encode the path separator '/' to '%2F'\n# The path parameter becomes: \"my_subdir%2Fuploaded_file.txt\"\n\necho \"Uploading file...\"\necho \"Hello SFTPGo\" &gt; local_file.txt\n\n# 'mkdir_parents=true' ensures 'my_subdir' is created automatically if it doesn't exist\ncurl -X POST \\\n  -H \"Authorization: Bearer ${TOKEN}\" \\\n  -d \"@local_file.txt\" \\\n  \"${ENDPOINT}/api/v2/user/files/upload?path=my_subdir%2Fuploaded_file.txt&amp;mkdir_parents=true\"\n\n# 4. Download the file from the subdirectory\n# Again, we use the URL encoded path: \"my_subdir%2Fuploaded_file.txt\"\n\necho \"Downloading file...\"\ncurl -s -H \"Authorization: Bearer ${TOKEN}\" \\\n  \"${ENDPOINT}/api/v2/user/files?path=my_subdir%2Fuploaded_file.txt\" &gt; downloaded_file.txt\n\necho \"Download complete. Content:\"\ncat downloaded_file.txt\n</code></pre>"},{"location":"roles/","title":"Roles","text":""},{"location":"roles/#roles","title":"Roles","text":"<p>Roles can be assigned to users and administrators. Administrators with an assigned role are considered limited administrators: they can view and manage only the users who share their role and they cannot have the following permissions:</p> <ul> <li>manage_admins</li> <li>manage_system</li> <li>manage_event_rules</li> <li>manage_roles</li> <li>view_events</li> </ul> <p>When a user is created by a role-based administrator, the user automatically inherits that administrator\u2019s role.</p> <p>Administrators without a role are global administrators: they have full access to manage all users (with or without a role) and can assign roles to other users.</p>"},{"location":"s3/","title":"S3","text":""},{"location":"s3/#s3-compatible-object-storage-backends","title":"S3 Compatible Object Storage backends","text":"<p>To connect SFTPGo to AWS, you need to specify credentials, a <code>bucket</code> and a <code>region</code>. Here is the list of available AWS regions. For example, if your bucket is at <code>Frankfurt</code>, you have to set the region to <code>eu-central-1</code>. You can specify an AWS storage class too. Leave it blank to use the default AWS storage class. An endpoint is required if you are connecting to a Compatible AWS Storage such as MinIO.</p> <p>AWS SDK has different options for credentials. We support:</p> <ol> <li>Providing Access Keys.</li> <li>Use IAM roles for Amazon EC2</li> <li>Use IAM roles for tasks if your application uses an ECS task definition</li> <li>Utilizing IAM roles for service accounts (IRSA) if you operate SFTPGo atop AWS EKS.</li> <li>Assuming specific IAM role by setting its ARN.</li> </ol> <p>So, you need to provide access keys to activate option 1, or leave them blank to use the other ways to specify credentials.</p> <p>You can also use a temporary session token or assume a role by setting its ARN.</p> <p>Specifying a different <code>key_prefix</code>, you can assign different \"folders\" of the same bucket to different users. This is similar to a chroot directory for local filesystem. Each SFTP/SCP user can only access the assigned folder and its contents. The folder identified by <code>key_prefix</code> does not need to be pre-created.</p> <p>SFTPGo uses multipart uploads and parallel downloads for storing and retrieving files from S3.</p> <p>For multipart uploads you can customize the parts size and the upload concurrency. Please note that if the upload bandwidth between the client and SFTPGo is greater than the upload bandwidth between SFTPGo and S3 then the client should wait for the last parts to be uploaded to S3 after finishing uploading the file to SFTPGo, and it may time out. Keep this in mind if you customize these parameters.</p> <p>The configured bucket must exist.</p> <p>Some SFTP commands don't work over S3:</p> <ul> <li><code>chown</code> and <code>chmod</code> will fail. If you want to silently ignore these commands set <code>setstat_mode</code> to <code>1</code> or <code>2</code> in your configuration file</li> <li><code>truncate</code>, <code>symlink</code>, <code>readlink</code> are not supported</li> <li>opening a file for both reading and writing at the same time is not supported</li> <li>resuming uploads is tricky and disabled by default</li> </ul> <p>Other notes:</p> <ul> <li><code>rename</code> is a two step operation: server-side copy and then deletion. So, it is not atomic as for local filesystem.</li> <li>We don't support renaming non empty directories since we should rename all the contents too and this could take a long time: think about directories with thousands of files: for each file we should do an AWS API call.</li> <li>For server side encryption, you have to configure the mapped bucket to automatically encrypt objects.</li> <li>A local home directory is still required to store temporary files, unless the environment variable <code>SFTPGO_HOOK__MEMORY_PIPES__ENABLED</code> is set to <code>1</code>, which allows you to avoid this requirement by using in-memory pipes.</li> <li>Clients that require advanced filesystem-like features such as <code>sshfs</code> are not supported.</li> <li><code>chtime</code> not supported.</li> </ul>"},{"location":"sftpfs/","title":"SFTP","text":""},{"location":"sftpfs/#sftp-as-storage-backend","title":"SFTP as storage backend","text":"<p>An SFTP account on another server can be used as storage for an SFTPGo account, so the remote SFTP server can be accessed in a similar way to the local file system.</p> <p>Here are the supported configuration parameters:</p> <ul> <li><code>Endpoint</code>, ssh endpoint as <code>host:port</code></li> <li><code>Username</code></li> <li><code>Password</code></li> <li><code>PrivateKey</code> and optionally the <code>Passphrase</code> used to protect it</li> <li><code>Fingerprints</code></li> <li><code>SFTP root directory</code></li> <li><code>SOCKS proxy</code>, optional SOCKS4, SOCKS4a, or SOCKS5 proxy.</li> <li><code>BufferSize</code></li> </ul> <p>The mandatory parameters are the endpoint, the username and a password or a private key. If you define both a password and a private key the key is tried first. The provided private key should be PEM encoded, something like this:</p> <pre><code>-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\nQyNTUxOQAAACA8LWc4SahqKkAr4L3rS19w1Vt8/IAf4th2FZmf+PJ/vwAAAJBvnZIJb52S\nCQAAAAtzc2gtZWQyNTUxOQAAACA8LWc4SahqKkAr4L3rS19w1Vt8/IAf4th2FZmf+PJ/vw\nAAAEBE6F5Az4wzNfNYLRdG8blDwvPBYFXE8BYDi4gzIhnd9zwtZzhJqGoqQCvgvetLX3DV\nW3z8gB/i2HYVmZ/48n+/AAAACW5pY29sYUBwMQECAwQ=\n-----END OPENSSH PRIVATE KEY-----\n</code></pre> <p>The password and the private key are stored as ciphertext according to your KMS configuration.</p> <p>SHA256 fingerprints for remote server host keys are optional but highly recommended: if you provide one or more fingerprints the server host key will be verified against them and the connection will be denied if none of the fingerprints provided match that for the server host key.</p> <p>Specifying a prefix you can restrict all operations to a given path within the remote SFTP server. If you set a prefix make sure it is not inside a symlinked directory or it is a symlink itself.</p> <p>Buffering can be enabled by setting a buffer size (in MB) greater than 0. By enabling buffering, the reads and writes, from/to the remote SFTP server, are split in multiple concurrent requests and this allows data to be transferred at a faster rate, over high latency networks, by overlapping round-trip times. With buffering enabled, resuming uploads and truncate are not supported and a file cannot be opened for both reading and writing at the same time. 0 means disabled.</p> <p>Some SFTP servers (eg. AWS Transfer) do not support opening files read/write at the same time, you can enable buffering to work with them.</p>"},{"location":"ssh/","title":"SSH","text":""},{"location":"ssh/#ssh","title":"SSH","text":"<p>SFTPGo is mainly an SFTP server only a minimal set of SSH commands are supported. Shell login and forwarding are not currently supported.</p>"},{"location":"ssh/#sftp","title":"SFTP","text":"<p>The SFTP implementation supports the SFTP sever protocol version 3, the same as OpenSSH.</p>"},{"location":"ssh/#ssh-commands","title":"SSH commands","text":"<p>SFTPGo supports the following built-in SSH commands:</p> <ul> <li><code>scp</code>, SFTPGo implements the SCP protocol so we can support it for cloud filesystems too and we can avoid the other system commands limitations. SCP between two remote hosts is supported using the <code>-3</code> scp option. Wildcard expansion is not supported.</li> <li><code>md5sum</code>, <code>sha1sum</code>, <code>sha256sum</code>, <code>sha384sum</code>, <code>sha512sum</code>. Useful to check message digests for uploaded files.</li> <li><code>cd</code>, <code>pwd</code>. Some SFTP clients do not support the SFTP SSH_FXP_REALPATH packet type, so they use <code>cd</code> and <code>pwd</code> SSH commands to get the initial directory. Currently <code>cd</code> does nothing and <code>pwd</code> always returns the <code>/</code> path. These commands will work with any storage backend but keep in mind that to calculate the hash we need to read the whole file, for remote backends this means downloading the file, for the encrypted backend this means decrypting the file.</li> <li><code>sftpgo-copy</code>. This is a built-in copy implementation. It allows server side copy for files and directories. The first argument is the source file/directory and the second one is the destination file/directory, for example <code>sftpgo-copy &lt;src&gt; &lt;dst&gt;</code>.</li> <li><code>sftpgo-remove</code>. This is a built-in remove implementation. It allows to remove single files and to recursively remove directories. The first argument is the file/directory to remove, for example <code>sftpgo-remove &lt;dst&gt;</code>. Removing directories spanning virtual folders is not supported.</li> </ul> <p>The following SSH commands are enabled by default:</p> <ul> <li><code>md5sum</code></li> <li><code>sha1sum</code></li> <li><code>sha256sum</code></li> <li><code>cd</code></li> <li><code>pwd</code></li> <li><code>scp</code></li> </ul>"},{"location":"virtual-folders/","title":"Virtual Folders","text":""},{"location":"virtual-folders/#virtual-folders","title":"Virtual Folders","text":"<p>Virtual folders act as flexible links to any supported storage backend, making that storage accessible to users at specific folder paths within their file system. This means you can present different storage systems\u2014like local disks, cloud buckets, or external SFTP servers\u2014as if they were simple folders, tailored to each user\u2019s needs.</p> <p>To illustrate, a user might have a virtual folder mapped to an Amazon S3 bucket, allowing them to interact with cloud storage seamlessly. Conversely, another user could have a virtual folder backed by a local encrypted filesystem. This flexibility lets you mix and match storage backends, providing a unified and convenient experience regardless of where the actual data resides. There is no fixed limit to the number of virtual folders that can be assigned to a single user.</p> <p>Beyond simple access, virtual folders can be integrated with the EventManager to automate file transfers between storage backends. For example, after a file upload or on a scheduled basis, files can be automatically moved or copied from one storage backend to another, simplifying workflows and ensuring data is where it needs to be without manual intervention.</p> <p>SFTPGo will try to automatically create any missing parent directory for the configured virtual folders at user login.</p> <p>For each virtual folder, the following properties can be configured:</p> <ul> <li><code>folder_name</code>, is the ID for an existing folder. The folder structure contains the absolute filesystem path to map as virtual folder</li> <li><code>filesystem</code>, local, cloud storage backend or a different SFTP server.</li> <li><code>virtual_path</code>, absolute path seen by SFTPGo users where the mapped path is accessible.</li> <li><code>quota_size</code>, maximum size allowed as bytes. 0 means unlimited, -1 included in user quota,</li> <li><code>quota_files</code>, maximum number of files allowed. 0 means unlimited, -1 included in user quota.</li> </ul> <p>For example if a folder is configured to use <code>/tmp/mapped</code> or <code>C:\\mapped</code> as filesystem path and <code>/vfolder</code> as virtual path then SFTPGo users can access <code>/tmp/mapped</code> or <code>C:\\mapped</code> via the <code>/vfolder</code> virtual path.</p> <p>Nested SFTP folders using the same SFTPGo instance (identified using the host keys) are not allowed as they could cause infinite SFTP loops.</p> <p>The same virtual folder can be shared among multiple users, and you can set different quota limits for each user on that shared folder. Alternatively, folder quotas can be included within a user\u2019s overall quota. In this case, the folder is considered \u201cprivate,\u201d and sharing it with others will cause incorrect quota calculations for the users involved.</p> <p>Folders that use dynamic paths (set through groups) must always be private to keep storage limits accurate.</p> <p>When calculating a user\u2019s quota, the system sums the sizes of all files in their home directory plus the files contained in each virtual folder that contributes to their quota.</p> <p>For private folders, the storage limit counts only for the individual user who owns it, not for the folder itself. So sharing these folders with others can cause errors in tracking storage use.</p> <p>If you create virtual folders that point to nested or overlapping paths, the quota calculations may become inaccurate. For example:</p> <ul> <li><code>folder1</code> uses <code>/srv/data/mapped</code> or <code>C:\\mapped</code> as mapped path</li> <li><code>folder2</code> uses <code>/srv/data/mapped/subdir</code> or <code>C:\\mapped\\subdir</code> as mapped path</li> </ul> <p>When you upload a file to folder2, only its quota will be updated, while the quota for folder1 will not reflect this change. This behavior is allowed to provide greater flexibility, but if you want to enforce accurate disk quotas in SFTPGo, it\u2019s best to avoid using folders with nested paths. Although this example refers to local folders, the same principle applies to cloud storage backends.</p> <p>It is allowed to mount a virtual folder in the user's root path (<code>/</code>). This might be useful if you want to share the same virtual folder between different users. In this case the user's root filesystem is hidden from the virtual folder.</p> <p>Using the REST API you can:</p> <ul> <li>monitor folders quota usage</li> <li>scan quota for folders</li> <li>inspect the relationships among users and folders</li> <li>delete a virtual folder. SFTPGo removes folders from the data provider, no files deletion will occur</li> </ul> <p>If you remove a folder, from the data provider, any users relationships will be cleared up. If the deleted folder is mounted on the user's root (<code>/</code>) path, the user is still valid and its root filesystem will no longer be hidden. If the deleted folder is included inside the user quota you need to do a user quota scan to update its quota. An orphan virtual folder will not be automatically deleted since if you add it again later, then a quota scan is needed, and it could be quite expensive, anyway you can easily list the orphan folders using the REST API and delete them if they are not needed anymore.</p>"},{"location":"web-interfaces/","title":"Web User Interfaces","text":""},{"location":"web-interfaces/#web-user-interfaces","title":"Web User Interfaces","text":"<p>SFTPGo provides two distinct web interfaces:</p> <ul> <li>WebAdmin UI.</li> <li>WebClient UI.</li> </ul> <p>Both Web UIs can be configured to require two-factor authentication, compatible with Microsoft Authenticator, Google Authenticator, Authy, and other similar apps.</p> <p>Single Sign-On (SSO) is supported through OpenID Connect, enabling seamless and secure authentication. Additionally, strict Content Security Policies (CSP) can be enforced\u2014excluding the use of <code>unsafe-eval</code> and <code>unsafe-inline</code>\u2014to enhance protection against cross-site scripting and other web-based attacks.</p>"},{"location":"web-interfaces/#webadmin","title":"WebAdmin","text":"<p>The WebAdmin UI allows administrators to easily create and manage users, folders, groups, and other resources. Available with dark and light themes.</p> <p></p> <p>With the default <code>httpd</code> configuration, the web admin is available at the following URL:</p> <p>http://127.0.0.1:8080/web/admin</p> <p>If no admin user is found within the data provider, typically after the initial installation, SFTPGo will ask you to create the first admin. You can also pre-create an admin user by loading initial data or by configuration/environment variables.</p> <p>The web interface can be configured over HTTPS and to require mutual TLS authentication in addition to administrator credentials.</p>"},{"location":"web-interfaces/#webclient","title":"WebClient","text":"<p>The WebClient UI allows end users to change their credentials, browse and manage their files in the browser, and set up two-factor authentication.</p> <p></p> <p>From the WebClient each authorized user can also create HTTP/S links to externally share files and folders securely, by setting limits to the number of downloads/uploads, protecting the share with a password or email authentication, limiting access by source IP address, setting an automatic expiration date. Available with dark and light themes.</p> <p>The web interface can be globally disabled within the <code>httpd</code> configuration via the <code>enable_web_client</code> key or on a per-user basis by adding <code>HTTP</code> to the denied protocols. Public keys management can be disabled, per-user, using a specific permission. The WebClient allows you to download multiple files or folders as a single zip file, any non regular files (for example symlinks) will be silently ignored.</p> <p>With the default <code>httpd</code> configuration, the WebClient is available at the following URL:</p> <p>http://127.0.0.1:8080/web/client</p>"},{"location":"web-interfaces/#internationalization","title":"Internationalization","text":"<p>SFTPGo uses the i18next framework for managing translating phrases in WebAdmin and WebClient.</p> <p>Support for internationalization is experimental. We currently support English, German, French and Italian.</p> <p>The translations are available via Crowdin, who have granted us an open source license.</p>"},{"location":"webdav/","title":"WebDAV","text":""},{"location":"webdav/#webdav","title":"WebDAV","text":"<p>The <code>WebDAV</code> support can be enabled by configuring one or more <code>bindings</code> inside the <code>webdavd</code> configuration section.</p> <p>Each user can access their home directory using the path <code>http/s://&lt;SFTPGo ip&gt;:&lt;WevDAVPORT&gt;/&lt;prefix&gt;</code>. By default <code>prefix</code> is empty. If you define a prefix it must be an absolute URI, for example <code>/dav</code>.</p> <p>WebDAV is quite a different protocol than SFTP/FTP, there is no session concept, each command is a separate HTTP request and must be authenticated, to improve performance SFTPGo caches authenticated users. This way SFTPGo don't need to do a dataprovider query and a password check for each request.</p> <p>The user caching configuration allows to set:</p> <ul> <li><code>expiration_time</code> in minutes. If a user is cached for more than the specified minutes it will be removed from the cache and a new dataprovider query will be performed. Please note that the <code>last_login</code> field will not be updated and <code>external_auth_hook</code>, <code>pre_login_hook</code> and <code>check_password_hook</code> will not be executed if the user is obtained from the cache.</li> <li><code>max_size</code>. Maximum number of users to cache. When this limit is reached the user with the oldest expiration date will be removed from the cache. 0 means no limit however the cache size cannot exceed the number of users so if you have a small number of users you can set this value to 0.</li> </ul> <p>Users are automatically removed from the cache after an update/delete.</p> <p>WebDAV protocol requires the MIME type for each file. SFTPGo will first try to guess the MIME type by extension. If this fails it will send a <code>HEAD</code> request for Cloud backends and, as last resort, it will try to guess the MIME type reading the first 512 bytes of the file. This may slow down the directory listing, especially for Cloud based backends, if you have directories containing many files with unregistered extensions. To mitigate this problem, you can enable caching of MIME types so that the MIME type detection is done only once.</p> <p>The MIME types caching configurations allows to set the maximum number of MIME types to cache. Once the cache reaches the configured maximum size no new MIME types will be added. The MIME types cache  is a non-persistent in-memory cache. If you need a persistent cache add your MIME types to <code>/etc/mime.types</code> on Linux or inside the registry on Windows.</p> <p>WebDAV should work as expected for most use cases but there are some minor issues and some missing features.</p> <p>If you use WebDAV behind a reverse proxy ensure to preserve the <code>Host</code> header or <code>COPY</code>/<code>MOVE</code> operations will fail. For example for apache you have to set <code>ProxyPreserveHost On</code>.</p> <p>Know issues:</p> <ul> <li>removing a directory tree on Cloud Storage backends could generate a <code>not found</code> error when removing the last (virtual) directory. This happens if the client cycles the directories tree itself and removes files and directories one by one instead of issuing a single remove command</li> <li>to be able to properly list a directory you need to grant both <code>list</code> and <code>download</code> permissions and to be able to upload files you need to gran both <code>list</code> and <code>upload</code> permissions</li> <li>if a file or a directory cannot be accessed, for example due to OS permissions issues or because a mapped path for a virtual folder is a missing, it will be omitted from the directory listing. If there is a different error then the whole directory listing will fail. This behavior is different from SFTP/FTP where you will be able to see the problematic file/directory in the directory listing, you will only get an error if you try to access it</li> <li>if you use the native Windows client please check its usage and pay particular attention to the registry settings. The default file size limit is 50MB and if you don't configure SFTPGo to use HTTPS you have to set <code>BasicAuthLevel</code> to <code>2</code></li> </ul> <p>SFTPGo has a minimal implementation for Dead Properties. We support setting the last modification time and we return the value in the \"live\" properties, so basically we don't store anything.</p> <p>To properly support dead properties we need a design decision, probably the best solution is to write a plugin and store them inside a supported data provider.</p> <p>SFTPGo also supports setting the modification time using the <code>X-OC-Mtime</code> header. Nextcloud compatible clients set this header.</p>"},{"location":"tutorials/eventmanager/","title":"Event Manager","text":""},{"location":"tutorials/eventmanager/#event-manager","title":"Event Manager","text":"<p>The Event Manager enables administrators to automate server operations by configuring HTTP notifications, executing commands, sending email alerts, and more\u2014based on server events or scheduled triggers.</p> <p>At its core, the Event Manager consists of two main components: rules and actions.</p> <ul> <li>Rules define the conditions that determine when an action should be executed. Think of a rule as a \"when this happens, and these conditions are met, then do that\" type of logic.</li> <li>Actions are the tasks carried out when a rule is triggered. These actions can be dynamically customized using placeholders\u2014variables that represent contextual data related to the event (such as file name, username, or file size). To further tailor these values, SFTPGo provides helper functions that format or transform placeholders directly within your templates. For a complete list of placeholders and helper functions, see the documentation.</li> </ul> <p>Let's see some common use cases.</p>"},{"location":"tutorials/eventmanager/#preliminary-note","title":"Preliminary Note","text":"<p>We will use email actions in the following paragraphs, so let's assume you have a working SMTP configuration. You can adapt the following snippet to configure an SMTP server using environment variables.</p> <pre><code>SFTPGO_SMTP__HOST=\"your smtp server host\"\nSFTPGO_SMTP__FROM=\"SFTPGo &lt;sftpgo@example.com&gt;\"\nSFTPGO_SMTP__USER=sftpgo@example.com\nSFTPGO_SMTP__PASSWORD=\"your password\"\nSFTPGO_SMTP__AUTH_TYPE=1 # change based on what your server supports\nSFTPGO_SMTP__ENCRYPTION=2 # change based on what your server supports\n</code></pre> <p>SFTPGo supports several placeholders for event actions. You can see all supported placeholders by clicking on the \"info\" icon at the top right of the add/update action page.</p> <p> The SMTP server can also be configured directly through the WebAdmin UI by navigating to Server Manager -&gt; Configurations -&gt; SMTP.</p>"},{"location":"tutorials/eventmanager/#daily-backups","title":"Daily backups","text":"<p>You can schedule SFTPGo data backups (users, folders, groups, admins etc.) on a regular basis, such as daily.</p> <p>From the WebAdmin expand the <code>Event Manager</code> section, select <code>Event actions</code> and add a new action. Create an action named <code>backup</code> and set the type to <code>Backup</code>.</p> <p></p> <p>Create another action named <code>backup notification</code>, set the type to <code>Email</code> and fill the recipient/s. As email subject set <code>Backup notification</code>. As email body set <code>Backup done {{ stringJoin .Errors \", \" }}</code>. The <code>stringJoin</code> function joins all error messages in the <code>.Errors</code> list using a comma and space as a separator. If no errors occurred, the resulting string will be empty.</p> <p></p> <p>Now select <code>Event rules</code> and create a rule named <code>Daily backup</code>, select <code>Schedule</code> as trigger and schedule a backup at midnight UTC time.</p> <p></p> <p>As actions select <code>backup</code> and <code>backup notification</code>.</p> <p></p> <p>Done! SFTPGo will make a new backup every day and you will receive an email with the status of the backup. The backup will be saved on the server side in the configured backup directory. The backup files will have names like this <code>backup_&lt;week day&gt;_&lt;hour&gt;.json</code>.</p>"},{"location":"tutorials/eventmanager/#automatically-create-a-folder-structure","title":"Automatically create a folder structure","text":"<p>Suppose you want to automatically create the folders <code>in</code> and <code>out</code> when you create new users.</p> <p>From the WebAdmin expand the <code>Event Manager</code> section, select <code>Event actions</code> and add a new action. Create an action named <code>create dirs</code>, with the settings you can see in the following screen.</p> <p></p> <p>Create another action named <code>create dirs failure notification</code>, set the type to <code>Email</code> and fill the recipient/s. As email subject set <code>Unable to create dirs for user {{.ObjectName}}</code>. As email body set <code>Errors: {{ stringJoin .Errors \", \" }}</code>.</p> <p></p> <p>Now select <code>Event rules</code> and create a rule named <code>Create dirs for users</code>, select <code>Provider event</code> as trigger, <code>add</code> as provider event and <code>user</code> as object filters.</p> <p></p> <p>As actions select <code>create dirs</code> and <code>create dirs failure notification</code>, check <code>Is failure action</code> for the notification action. This way you will only be notified by email if an error occurs.</p> <p></p> <p>Done! Create a new user and check that the defined directories are automatically created.</p>"},{"location":"tutorials/eventmanager/#upload-notifications","title":"Upload notifications","text":"<p>Let's see how you can receive an email notification after each upload and, optionally, the uploaded file as well.</p> <p>From the WebAdmin expand the <code>Event Manager</code> section, select <code>Event actions</code> and add a new action. Create an action named <code>upload notification</code> with the settings you can see in the following screen.</p> <p></p> <p>You can optionally add the uploaded file as an attachment but note that SFTPGo allows you to attach a maximum of 10MB. Then the action will fail for files bigger than 10MB.</p> <p>Now select <code>Event rules</code> and create a rule named <code>Upload rule</code>, select <code>Filesystem events</code> as trigger and <code>upload</code> as filesystem event. You can also filters events based on protocol, user and group name, filepath shell-like patterns, file size. We omit these additional filters for simplicity.</p> <p></p> <p>As actions, select <code>upload notification</code>. Done! Try uploading a new file and you will receive the configured email notification.</p>"},{"location":"tutorials/eventmanager/#pgp-compatible-encryption-and-decryption","title":"PGP-compatible Encryption and Decryption","text":"<p>PGP is a widely adopted encryption standard that ensures data confidentiality and integrity. By encrypting files before they're shared and decrypting them upon receipt, PGP protects valuable business information from unauthorized access or tampering.</p> <p>By using PGP actions, you can automatically encrypt or decrypt files immediately after upload. This supports secure, automated workflows for both sending and receiving files:</p> <ul> <li>Encrypting files for an external party: The external party generates a PGP key pair and shares their public key. SFTPGo is configured to automatically encrypt uploaded files using the public key. The trading partner downloads the files and decrypts them using their private key.</li> <li>Decrypting files from an external party: You share your public key with the external party and ask them to encrypt files before uploading. SFTPGo automatically decrypts the files after upload using your private key. The files are then available in plain form for further processing.</li> </ul> <p>This setup ensures end-to-end file security with minimal manual intervention.</p> <p>PGP actions require either a password or a key pair. When using a key pair:</p> <ul> <li>For encryption, the public key is required, and the private, if provided, will be used for signing.</li> <li>For decryption, the private key is required, and the public key, if provided, will be used for signature verification.</li> </ul> <p>The following example demonstrates how to configure an action to automatically encrypt files after upload. A similar approach can be used to set up automatic decryption.</p> <p>From the WebAdmin expand the \"Event Manager\" section, select \"Actions\" and add a new action. Create an action named <code>PGP encryption</code> set the type to <code>Filesystem</code>, the Filesystem action to <code>PGP</code> and the Public Key, like this.</p> <p></p> <p></p> <p>The source path is defined as <code>/{{.VirtualPath}}</code>, and the target path as <code>/{{.VirtualPath}}.pgp</code>. For example, a file named <code>file.txt</code> will be encrypted and stored as <code>file.txt.pgp</code>.</p> <p>Now define a rule that execute this action after uploads. Additional actions can be configured as part of the rule, such as deleting the original plain text file upon successful encryption and/or sending an email notification.</p>"},{"location":"tutorials/eventmanager/#virtual-folders-integration","title":"Virtual folders integration","text":"<p>Using virtual folders with the EventManager unlocks powerful automation workflows, such as copying uploaded files to different storage locations\u2014either within the same backend (but outside the user\u2019s security context) or to an external server or cloud storage provider. These operations can be triggered by events like file uploads or scheduled tasks, and they require no custom scripting or complex setup.</p> <p>Let\u2019s explore a few example scenarios to see how this feature can be used in practice.</p>"},{"location":"tutorials/eventmanager/#scenario-1","title":"Scenario 1","text":"<p>We have the following scenario.</p> <ul> <li>The user <code>ukg</code> has the key prefix set to <code>ukg/</code> so it can only access this folder.</li> </ul> <p></p> <ul> <li>The user <code>vista</code> has the key prefix set to <code>vista/</code> so it can only access this folder.</li> </ul> <p></p> <p>Each time the user <code>ukg</code> uploads files to the <code>/inbound</code> folder that:</p> <ul> <li>start with <code>vista_</code>, and</li> <li>end with <code>.csv</code></li> </ul> <p>we want to automatically copy those files to the <code>/outbound</code> folder of the user <code>vista</code>.</p> <p>To achieve this, we need to define a copy action that runs after each upload. By default, actions are executed within the security context of the user who performed the upload. Since the user <code>ukg</code> is restricted to their own directory and cannot access the <code>vista</code> user's folder, this operation would normally be blocked.</p> <p>To support this use case, we define a virtual folder with permissions to access the <code>vista</code> user\u2019s directory. The copy action is then configured to use this virtual folder as the destination, allowing the operation to succeed outside the security context of the <code>ukg</code> user.</p> <p>Create a folder named <code>storage</code> without setting a key prefix. This gives the folder visibility over the entire storage and allows it to be reused for other actions. Of course, if needed, you can also assign a key prefix to restrict access to a specific portion of the storage.</p> <p></p> <p>In the EventManager section, create a new action of type <code>Filesystem</code> and choose <code>Copy</code> as the action type. Set the source path to <code>/inbound/{{.ObjectName}}</code> and the target path to <code>/vista/outbound/{{.ObjectName}}</code>. Finally, select <code>storage</code> as the target folder.</p> <p></p> <p>Explore the details:</p> <ul> <li>The source path is set to <code>/inbound/{{.ObjectName}}</code>. The placeholder <code>{{.ObjectName}}</code> is replaced with the file name\u2014for example, if a file is uploaded to <code>/inbound/test.csv</code>, it becomes <code>test.csv</code>. Alternatively, you can use the more generic <code>{{.VirtualPath}}</code> placeholder, which would resolve to <code>/inbound/test.csv</code> in the same scenario.</li> <li>The target folder is set to <code>storage</code>, so the target path is relative to that folder.</li> <li>The target path is <code>/vista/outbound/{{.ObjectName}}</code>. This means that if the user <code>ukg</code> uploads the file <code>/inbound/test.csv</code>, it will be copied to <code>/vista/outbound/test.csv</code>.</li> </ul> <p> All paths are relative. For example, if the storage folder had a key prefix set to <code>vista/</code>, the correct target path would be <code>/outbound/{{.ObjectName}}</code> instead.</p> <p>Finally, define a rule to execute this action after each upload.</p> <p>Set <code>Filesystem events</code> as trigger and <code>upload</code> as event.</p> <p></p> <p>In the <code>Name filters</code> section, you can restrict which users the rule applies to. In this case, we specify <code>ukg</code>, but you can also define multiple users or patterns\u2014for example, <code>user*</code> matches all usernames that start with <code>user</code>.</p> <p></p> <p>Similar filters can be applied based on groups or roles as well.</p> <p>We also want to restrict the rule to files uploaded to the <code>/inbound</code> folder that start with <code>vista_</code> and end with <code>.csv</code>. To do this, configure the following path filters.</p> <ul> <li><code>/inbound/vista_*</code></li> <li><code>/inbound/*.csv</code></li> </ul> <p></p> <p>Keep in mind that paths are relative, not absolute.</p> <p>Finally select the <code>copy</code> action and save the rule.</p> <p></p> <p>That's it! Now upload some test files to confirm everything works as expected. For example:</p> <ul> <li>Files uploaded outside of <code>/inbound</code> \u2192 the action will not be triggered.</li> <li>Files in <code>/inbound</code> with the correct prefix and extension \u2192 the action will be triggered.</li> <li>Files in <code>/inbound</code> with a .txt extension \u2192 the action will not be triggered.</li> <li>Files in a subdirectory like <code>/inbound/subdir</code>, even with the correct extension \u2192 the action will not be triggered, we haven't used the double asterisk syntax to match subdirectories.</li> </ul>"},{"location":"tutorials/eventmanager/#scenario-2","title":"Scenario 2","text":"<p>Each time the user <code>vista</code> uploads files with <code>.csv</code> or <code>.xml</code> extensions to the <code>/inbound</code> folder, we want to automatically transfer these files to the <code>/push</code> directory on an external SFTP server.</p> <p>This is very similar to the <code>Scenario 1</code>, we have to define a copy action and a target folder using the external SFTP server as storage backend.</p> <p>Create a folder that is backed by the remote SFTP server.</p> <p></p> <p>This time, we've set the SFTP root directory to <code>/push</code>, which restricts the folder's access to that directory. As a result, the target paths defined in the copy action are relative to <code>/push</code>.</p> <p>For the action configuration:</p> <ul> <li>Set the source path to <code>/{{.VirtualPath}}</code>.</li> <li>Set the target path to <code>/{{.ObjectName}}</code>. Since the SFTP folder uses <code>/push</code> as its root directory, this path is relative to <code>/push</code>.</li> </ul> <p></p> <p> The <code>push</code> folder must already exist on the remote SFTP server for the action to succeed.</p> <p>For the rule:</p> <ul> <li>we use <code>vista</code> as name filter so that the action will be executed only for this user</li> <li><code>/inbound/*.csv</code> and <code>/inbound/*.xml</code> as path filters to limit the execution to these file extension</li> <li>select <code>sftp copy</code> as the action.</li> </ul> <p>That's it! Now upload some test files to confirm everything works as expected.</p>"},{"location":"tutorials/eventmanager/#recycle-bin","title":"Recycle Bin","text":"<p>Let's see how we can configure a Recycle Bin style function where files are not deleted strait away, but instead moved to a separate folder.</p> <p>To easily apply the Recycle Bin to multiple users we will create a virtual folder and a group, this way all users who belong to the group will have a Recycle Bin.</p> <p>Create a virtual folder named <code>recycle</code> with the settings you can see in the following screen.</p> <p></p> <p>Create a group named <code>recycle</code> with the settings you can see in the following screen.</p> <p></p> <p>Make your users members of the <code>recycle</code> group.</p> <p>From the WebAdmin expand the <code>Event Manager</code> section, select <code>Event actions</code> and add a new action. Create an action named <code>move to recycle</code> with the settings you can see in the following screen.</p> <p></p> <p>Now select <code>Event rules</code> and create a rule named <code>Recycle rule</code>, select <code>Filesystem events</code> as trigger, <code>pre-delete</code> as filesystem event and exclude the <code>/recycle</code> path.</p> <p></p> <p></p> <p>As actions, select <code>move to recycle</code> and set <code>Execute sync</code>.</p> <p>Done! Try deleting a file, it will be moved to the Recycle Bin.</p> <p>You can also add a scheduled event rule to automatically delete files older than a configurable time from the <code>/recycle</code> folder.</p>"},{"location":"tutorials/lets-encrypt-certificate/","title":"Let's Encrypt TLS Certificates","text":""},{"location":"tutorials/lets-encrypt-certificate/#securing-sftpgo-with-a-free-lets-encrypt-tls-certificate","title":"Securing SFTPGo with a free Let's Encrypt TLS Certificate","text":"<p>This tutorial shows how to obtain and renew a free Let's encrypt TLS certificate for the SFTPGo Web UI and REST API, the WebDAV service and the FTP service.</p> <p>Obtaining a Let's Encrypt certificate involves solving a domain validation challenge issued by an ACME (Automatic Certificate Management Environment) server. This challenge verifies your ownership of the domain(s) you're trying to obtain a certificate for. Different challenge types exist, the most commonly used being <code>HTTP-01</code>. As its name suggests, it uses the HTTP protocol. While HTTP servers can be configured to use any TCP port, this challenge will only work on port <code>80</code> due to security measures.</p> <p>More info about the supported challenge types.</p> <p>There are several tools that allow you to obtain a Let's encrypt TLS certificate, in this tutorial we'll show how to use the lego CLI tool and the ACME protocol built into SFTPGo.</p> <p>The <code>lego</code> CLI supports all the Let's encrypt challenge types. The ACME protocol built into SFTPGo supports <code>HTTP-01</code> and <code>TLS-ALPN-01</code> challenge types.</p> <p>In this tutorial we'll focus on <code>HTTP-01</code> challenge type and make the following assumptions:</p> <ul> <li>we are running SFTPGo on Linux</li> <li>we need a TLS certificate for the <code>sftpgo.com</code> domain</li> <li>we have an existing web server already running on port <code>80</code> for the <code>sftpgo.com</code> domain and the web root path is <code>/var/www/sftpgo.com</code></li> </ul>"},{"location":"tutorials/lets-encrypt-certificate/#obtaining-a-certificate-using-the-lego-cli-tool","title":"Obtaining a certificate using the Lego CLI tool","text":"<p>Download the latest lego release and extract the lego binary in <code>/usr/local/bin</code>, then verify that it works.</p> <pre><code>lego -v\nlego version 4.4.0 linux/amd64\n</code></pre> <p>We'll store the certificates in <code>/var/lib/lego</code> so create this directory.</p> <pre><code>sudo mkdir -p /var/lib/lego\n</code></pre> <p>Now obtain a certificate. The HTTP based challenge will be created in a file in <code>/var/www/sftpgo.com/.well-known/acme-challenge</code>. This directory must be publicly served by your web server.</p> <pre><code>sudo lego --accept-tos --path=\"/var/lib/lego\" --email=\"&lt;you email address here&gt;\" --domains=\"sftpgo.com\" --http.webroot=\"/var/www/sftpgo.com\" --http run\n</code></pre> <p>You should be now able to list your certificate.</p> <pre><code>sudo lego --path=\"/var/lib/lego\" list\nFound the following certs:\n  Certificate Name: sftpgo.com\n    Domains: sftpgo.com\n    Expiry Date: 2021-09-09 19:41:51 +0000 UTC\n    Certificate Path: /var/lib/lego/certificates/sftpgo.com.crt\n</code></pre> <p>Now copy the certificate inside a private path to the SFTPGo service.</p> <pre><code>sudo mkdir -p /var/lib/sftpgo/certs\nsudo cp /var/lib/lego/certificates/sftpgo.com.{crt,key} /var/lib/sftpgo/certs\nsudo chown -R sftpgo:sftpgo /var/lib/sftpgo/certs\n</code></pre>"},{"location":"tutorials/lets-encrypt-certificate/#automatic-certificate-renewal-using-the-lego-cli-tool","title":"Automatic certificate renewal using the Lego CLI tool","text":"<p>SFTPGo can reload TLS certificates without service interruption, so we'll create a small bash script that copies the certificates inside the SFTPGo private directory and instructs SFTPGo to load them. We then configure <code>lego</code> to run this script when the certificates are renewed.</p> <p>Create the file <code>/usr/local/bin/sftpgo_lego_hook</code> with the following contents.</p> <pre><code>#!/bin/bash\n\nPATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin\n\nCERTS_DIR=/var/lib/sftpgo/certs\nmkdir -p ${CERTS_DIR}\n\ncp ${LEGO_CERT_PATH} ${LEGO_CERT_KEY_PATH} ${CERTS_DIR}\n\nchown -R sftpgo:sftpgo ${CERTS_DIR}\nsystemctl reload sftpgo\n</code></pre> <p>Ensure that this script is executable.</p> <pre><code>sudo chmod 755 /usr/local/bin/sftpgo_lego_hook\n</code></pre> <p>Now create a daily cron job to check the certificate expiration and renew it if necessary. For example create the file <code>/etc/cron.daily/lego</code> with the following contents.</p> <pre><code>#!/bin/bash\n\nlego --accept-tos --path=\"/var/lib/lego\" --email=\"&lt;you email address here&gt;\" --domains=\"sftpgo.com\" --http-timeout 60 --http.webroot=\"/var/www/sftpgo.com\" --http renew --renew-hook=\"/usr/local/bin/sftpgo_lego_hook\"\n</code></pre> <p>Ensure that this cron script is executable.</p> <pre><code>sudo chmod 755 /etc/cron.daily/lego\n</code></pre> <p>When the certificate is renewed you should see SFTPGo logs like the following to confirm that the new certificate was successfully loaded.</p> <pre><code>{\"level\":\"debug\",\"time\":\"2021-06-14T20:05:15.785\",\"sender\":\"service\",\"message\":\"Received reload request\"}\n{\"level\":\"debug\",\"time\":\"2021-06-14T20:05:15.785\",\"sender\":\"httpd\",\"message\":\"TLS certificate \\\"/var/lib/sftpgo/certs/sftpgo.com.crt\\\" successfully loaded\"}\n{\"level\":\"debug\",\"time\":\"2021-06-14T20:05:15.785\",\"sender\":\"ftpd\",\"message\":\"TLS certificate \\\"/var/lib/sftpgo/certs/sftpgo.com.crt\\\" successfully loaded\"}\n{\"level\":\"debug\",\"time\":\"2021-06-14T20:05:15.786\",\"sender\":\"webdavd\",\"message\":\"TLS certificate \\\"/var/lib/sftpgo/certs/sftpgo.com.crt\\\" successfully loaded\"}\n</code></pre>"},{"location":"tutorials/lets-encrypt-certificate/#obtaining-a-certificate-using-the-acme-protocol-built-into-sftpgo","title":"Obtaining a certificate using the ACME protocol built into SFTPGo","text":"<p> Starting from SFTPGo v2.5.0 you can also request certificates from the Server Manager -&gt; Configurations -&gt; ACME section of the WebAdmin UI.</p> <p>You can open the SFTPGo configuration file, search for the <code>acme</code> section and change it as follow.</p> <pre><code>  \"acme\": {\n    \"domains\": [\"sftpgo.com\"],\n    \"email\": \"&lt;you email address here&gt;\",\n    \"key_type\": \"4096\",\n    \"certs_path\": \"/var/lib/sftpgo/certs\",\n    \"ca_endpoint\": \"https://acme-v02.api.letsencrypt.org/directory\",\n    \"renew_days\": 30,\n    \"http01_challenge\": {\n      \"port\": 80,\n      \"proxy_header\": \"\",\n      \"webroot\": \"/var/www/sftpgo.com\"\n    },\n    \"tls_alpn01_challenge\": {\n      \"port\": 0\n    }\n  }\n</code></pre> <p>Alternatively (recommended), you can use environment variables by creating the file <code>/etc/sftpgo/env.d/acme.env</code> with the following content.</p> <pre><code>SFTPGO_ACME__DOMAINS=\"sftpgo.com\"\nSFTPGO_ACME__EMAIL=\"&lt;you email address here&gt;\"\nSFTPGO_ACME__HTTP01_CHALLENGE__WEBROOT=\"/var/www/sftpgo.com\"\n</code></pre> <p>Make sure that the <code>sftpgo</code> user can write to the <code>/var/www/sftpgo.com</code> directory or pre-create the <code>/var/www/sftpgo.com/.well-known/acme-challenge</code> directory with the appropriate permissions. This directory must be publicly served by your web server.</p> <p> in this example we assume you have an existing HTTP server. If not, you can leave the web root blank and SFTPGo will resolve the HTTP01 challenge by itself.</p> <p>Register your account and obtain certificates by running the following command.</p> <pre><code>sudo -E su - sftpgo -m -s /bin/bash -c 'sftpgo acme run -c /etc/sftpgo'\n</code></pre> <p>If this command completes successfully, you are done. The SFTPGo service will take care of the automatic renewal of certificates for the configured domains. Make sure that the <code>sftpgo</code> system user can read and write to <code>/var/lib/sftpgo/certs</code> directory otherwise the certificate renewal will fail.</p>"},{"location":"tutorials/lets-encrypt-certificate/#enable-https-for-sftpgo-web-ui-and-rest-api","title":"Enable HTTPS for SFTPGo Web UI and REST API","text":"<p>You can open the SFTPGo configuration file, search for the <code>httpd</code> section and change it as follow.</p> <pre><code>  \"httpd\": {\n    \"bindings\": [\n      {\n        \"port\": 9443,\n        \"address\": \"\",\n        \"enable_web_admin\": true,\n        \"enable_web_client\": true,\n        \"enable_rest_api\": true,\n        \"enable_https\": true,\n        \"certificate_file\": \"/var/lib/sftpgo/certs/sftpgo.com.crt\",\n        \"certificate_key_file\": \"/var/lib/sftpgo/certs/sftpgo.com.key\",\n        .....\n</code></pre> <p>Alternatively (recommended), you can use environment variables by creating the file <code>/etc/sftpgo/env.d/httpd.env</code> with the following content.</p> <pre><code>SFTPGO_HTTPD__BINDINGS__0__PORT=9443\nSFTPGO_HTTPD__BINDINGS__0__ENABLE_HTTPS=1\nSFTPGO_HTTPD__BINDINGS__0__CERTIFICATE_FILE=\"/var/lib/sftpgo/certs/sftpgo.com.crt\"\nSFTPGO_HTTPD__BINDINGS__0__CERTIFICATE_KEY_FILE=\"/var/lib/sftpgo/certs/sftpgo.com.key\"\n</code></pre> <p>Restart SFTPGo to apply the changes. The HTTPS service is now available on port <code>9443</code>.</p>"},{"location":"tutorials/lets-encrypt-certificate/#enable-https-for-webdav-service","title":"Enable HTTPS for WebDAV service","text":"<p>You can open the SFTPGo configuration file, search for the <code>webdavd</code> section and change it as follow.</p> <pre><code>  \"webdavd\": {\n    \"bindings\": [\n      {\n        \"port\": 10443,\n        \"address\": \"\",\n        \"enable_https\": true,\n        \"certificate_file\": \"/var/lib/sftpgo/certs/sftpgo.com.crt\",\n        \"certificate_key_file\": \"/var/lib/sftpgo/certs/sftpgo.com.key\",\n        ...\n</code></pre> <p>Alternatively (recommended), you can use environment variables by creating the file <code>/etc/sftpgo/env.d/webdavd.env</code> with the following content.</p> <pre><code>SFTPGO_WEBDAVD__BINDINGS__0__PORT=10443\nSFTPGO_WEBDAVD__BINDINGS__0__ENABLE_HTTPS=1\nSFTPGO_WEBDAVD__CERTIFICATE_FILE=\"/var/lib/sftpgo/certs/sftpgo.com.crt\"\nSFTPGO_WEBDAVD__CERTIFICATE_KEY_FILE=\"/var/lib/sftpgo/certs/sftpgo.com.key\"\n</code></pre> <p>Restart SFTPGo to apply the changes. WebDAV is now availble over HTTPS on port <code>10443</code>.</p>"},{"location":"tutorials/lets-encrypt-certificate/#enable-explicit-ftp-over-tls","title":"Enable explicit FTP over TLS","text":"<p>You can open the SFTPGo configuration file, search for the <code>ftpd</code> section and change it as follow.</p> <pre><code>  \"ftpd\": {\n    \"bindings\": [\n      {\n        \"port\": 2121,\n        \"address\": \"\",\n        \"apply_proxy_config\": true,\n        \"tls_mode\": 1,\n        \"certificate_file\": \"/var/lib/sftpgo/certs/sftpgo.com.crt\",\n        \"certificate_key_file\": \"/var/lib/sftpgo/certs/sftpgo.com.key\",\n        ...\n</code></pre> <p>Alternatively (recommended), you can use environment variables by creating the file <code>/etc/sftpgo/env.d/ftpd.env</code> with the following content.</p> <pre><code>SFTPGO_FTPD__BINDINGS__0__PORT=2121\nSFTPGO_FTPD__BINDINGS__0__TLS_MODE=1\nSFTPGO_FTPD__BINDINGS__0__CERTIFICATE_FILE=\"/var/lib/sftpgo/certs/sftpgo.com.crt\"\nSFTPGO_FTPD__BINDINGS__0__CERTIFICATE_KEY_FILE=\"/var/lib/sftpgo/certs/sftpgo.com.key\"\n</code></pre> <p>Restart SFTPGo to apply the changes. FTPES service is now available on port <code>2121</code> and TLS is required for both control and data connection (<code>tls_mode</code> is 1).</p>"},{"location":"tutorials/migrating/","title":"Migration from Open-Source 2.6.x to Enterprise","text":""},{"location":"tutorials/migrating/#migrating-from-sftpgo-open-source-to-enterprise-edition","title":"Migrating from SFTPGo Open-Source to Enterprise Edition","text":"<p>Migration to the SFTPGo Enterprise Edition is supported starting from open-source version 2.6.x. The Enterprise Edition updates the database schema, but it remains fully compatible with databases from open-source 2.6.x releases.</p> <p>If you're using an earlier open-source version, you must first upgrade to 2.6.x before migrating to the Enterprise Edition.</p> <p>There are two main migration paths, depending on your preferences and environment setup:</p>"},{"location":"tutorials/migrating/#option-1-in-place-upgrade","title":"Option 1: In-Place Upgrade","text":"<p>If you're already running SFTPGo open-source (version 2.6.x or later), you can upgrade directly to the Enterprise Edition by installing the appropriate Enterprise package (e.g., yum or apt repositories, Windows installer) or by switching to the Enterprise Docker image.</p>"},{"location":"tutorials/migrating/#option-2-backup-and-restore","title":"Option 2: Backup and Restore","text":"<p>Alternatively, you can choose to:</p> <ol> <li>Install the Enterprise Edition in a new environment.</li> <li>From the open-source instance, perform a data backup.</li> <li>Restore the backup into the Enterprise instance using the WebAdmin UI.</li> </ol> <p>This process can be completed from the \"Maintenance\" page in the WebAdmin interface.</p> <p></p> <p>After upgrading, you may need to migrate your existing actions to the new Event Manager format (see link above).</p>"},{"location":"tutorials/migrating/#post-upgrade","title":"Post-Upgrade","text":"<p>After upgrading, you may need to migrate your existing actions to the new Event Manager format.</p> <p>For detailed instructions, refer to the documentation for action migration: Event Manager - Migration from previous versions or the open-source edition</p>"},{"location":"tutorials/migrating/#notes","title":"Notes","text":"<p>Both methods preserve your users, folders, groups and other configuration data.</p> <p>However, when using Option 2 (installing the Enterprise Edition in a new environment), keep in mind that the backup includes configuration data only: it does not include files stored on disk.</p> <ul> <li>If you are using the local filesystem as a storage backend, you must manually copy the user files to the new installation, ensuring they are placed in the same paths and have the correct ownership and permissions.</li> <li>If you are using a remote storage backend such as S3, Google Cloud Storage, Azure Blob, your files remain accessible without needing to move them, as the configuration will continue to point to the existing storage.</li> </ul> <p>If you have any questions or encounter issues during the migration, feel free to contact our support team.</p>"},{"location":"tutorials/postgresql-s3/","title":"SFTPGo with PostgreSQL data provider and S3 backend","text":""},{"location":"tutorials/postgresql-s3/#sftpgo-with-postgresql-data-provider-and-s3-backend","title":"SFTPGo with PostgreSQL data provider and S3 backend","text":"<p>This tutorial shows the installation of SFTPGo on Ubuntu 20.04 (Focal Fossa) with PostgreSQL data provider and S3 backend. SFTPGo will run as an unprivileged (non-root) user. We assume that you want to serve a single S3 bucket and you want to assign different \"virtual folders\" of this bucket to different SFTPGo virtual users.</p>"},{"location":"tutorials/postgresql-s3/#preliminary-note","title":"Preliminary Note","text":"<p>Before proceeding further you need to have a basic minimal installation of Ubuntu 20.04.</p>"},{"location":"tutorials/postgresql-s3/#install-postgresql","title":"Install PostgreSQL","text":"<p>Before installing any packages on the Ubuntu system, update and upgrade all packages using the <code>apt</code> commands below.</p> <pre><code>sudo apt update\nsudo apt upgrade\n</code></pre> <p>Install PostgreSQL with this <code>apt</code> command.</p> <pre><code>sudo apt -y install postgresql\n</code></pre> <p>Once installation is completed, start the PostgreSQL service and add it to the system boot.</p> <pre><code>sudo systemctl start postgresql\nsudo systemctl enable postgresql\n</code></pre> <p>Next, check the PostgreSQL service using the following command.</p> <pre><code>systemctl status postgresql\n</code></pre>"},{"location":"tutorials/postgresql-s3/#configure-postgresql","title":"Configure PostgreSQL","text":"<p>PostgreSQL uses roles for user authentication and authorization, it just like Unix-Style permissions. By default, PostgreSQL creates a new user called <code>postgres</code> for basic authentication.</p> <p>In this step, we will create a new PostgreSQL user for SFTPGo.</p> <p>Login to the PostgreSQL shell using the command below.</p> <pre><code>sudo -i -u postgres psql\n</code></pre> <p>Next, create a new role <code>sftpgo</code> with the password <code>sftpgo_pg_pwd</code> using the following query.</p> <pre><code>create user \"sftpgo\" with encrypted password 'sftpgo_pg_pwd';\n</code></pre> <p>Next, create a new database <code>sftpgo.db</code> for the SFTPGo service using the following queries.</p> <pre><code>create database \"sftpgo.db\";\ngrant all privileges on database \"sftpgo.db\" to \"sftpgo\";\n</code></pre> <p>Exit from the PostgreSQL shell typing <code>\\q</code>.</p>"},{"location":"tutorials/postgresql-s3/#install-sftpgo","title":"Install SFTPGo","text":"<p>To install SFTPGo you can use the PPA here.</p> <p>Start by adding the PPA.</p> <pre><code>sudo add-apt-repository ppa:sftpgo/sftpgo\nsudo apt-get update\n</code></pre> <p>Next install SFTPGo.</p> <pre><code>sudo apt install sftpgo\n</code></pre> <p>After installation SFTPGo should already be running with default configuration and configured to start automatically at boot, check its status using the following command.</p> <pre><code>systemctl status sftpgo\n</code></pre>"},{"location":"tutorials/postgresql-s3/#configure-aws-credentials","title":"Configure AWS credentials","text":"<p>We assume that you want to serve a single S3 bucket and you want to assign different \"virtual folders\" of this bucket to different SFTPGo virtual users. In this case is very convenient to configure a credential file so SFTPGo will automatically use it and you don't need to specify the same AWS credentials for each user.</p> <p>You can manually create the <code>/var/lib/sftpgo/.aws/credentials</code> file and write your AWS credentials like this.</p> <pre><code>[default]\naws_access_key_id=AKIAIOSFODNN7EXAMPLE\naws_secret_access_key=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\n</code></pre> <p>Alternately you can install <code>AWS CLI</code> and manage the credential using this tool.</p> <pre><code>sudo apt install awscli\n</code></pre> <p>and now set your credentials, region, and output format with the following command.</p> <pre><code>aws configure\n</code></pre> <p>Confirm that you can list your bucket contents with the following command.</p> <pre><code>aws s3 ls s3://mybucket\n</code></pre> <p>The AWS CLI will create the credential file in <code>~/.aws/credentials</code>. The SFTPGo service runs using the <code>sftpgo</code> system user whose home directory is <code>/var/lib/sftpgo</code> so you need to copy the credentials file to the sftpgo home directory and assign it the proper permissions.</p> <pre><code>sudo mkdir /var/lib/sftpgo/.aws\nsudo cp ~/.aws/credentials /var/lib/sftpgo/.aws/\nsudo chown -R sftpgo:sftpgo /var/lib/sftpgo/.aws\n</code></pre>"},{"location":"tutorials/postgresql-s3/#configure-sftpgo","title":"Configure SFTPGo","text":"<p>Now open the SFTPGo configuration.</p> <pre><code>sudo vi /etc/sftpgo/sftpgo.json\n</code></pre> <p>Search for the <code>data_provider</code> section and change it as follow.</p> <pre><code>  \"data_provider\": {\n    \"driver\": \"postgresql\",\n    \"name\": \"sftpgo.db\",\n    \"host\": \"127.0.0.1\",\n    \"port\": 5432,\n    \"username\": \"sftpgo\",\n    \"password\": \"sftpgo_pg_pwd\",\n    ...\n}\n</code></pre> <p>Alternatively (recommended), you can use environment variables by creating the file <code>/etc/sftpgo/env.d/postgresql.env</code> with the following content.</p> <pre><code>SFTPGO_DATA_PROVIDER__DRIVER=postgresql\nSFTPGO_DATA_PROVIDER__NAME=\"sftpgo.db\"\nSFTPGO_DATA_PROVIDER__HOST=127.0.0.1\nSFTPGO_DATA_PROVIDER__PORT=5432\nSFTPGO_DATA_PROVIDER__USERNAME=sftpgo\nSFTPGO_DATA_PROVIDER__PASSWORD=sftpgo_pg_pwd\n</code></pre> <p>This way we set the PostgreSQL connection parameters.</p> <p>If you want to connect to PostgreSQL over a Unix Domain socket you have to set the value <code>/var/run/postgresql</code> for the <code>host</code> configuration key instead of <code>127.0.0.1</code>.</p> <p>You can further customize your configuration adding custom actions and other hooks. A full explanation of all configuration parameters can be found here.</p> <p>Next, initialize the data provider with the following command.</p> <pre><code>$ sudo su - sftpgo -s /bin/bash -c 'sftpgo initprovider -c /etc/sftpgo'\n2020-10-09T21:07:50.000 INF Initializing provider: \"postgresql\" config file: \"/etc/sftpgo/sftpgo.json\"\n2020-10-09T21:07:50.000 INF updating database schema version: 1 -&gt; 2\n2020-10-09T21:07:50.000 INF updating database schema version: 2 -&gt; 3\n2020-10-09T21:07:50.000 INF updating database schema version: 3 -&gt; 4\n2020-10-09T21:07:50.000 INF Data provider successfully initialized/updated\n</code></pre> <p>The default sftpgo systemd service will start after the network target, in this setup it is more appropriate to start it after the PostgreSQL service, so edit the service using the following command.</p> <pre><code>sudo systemctl edit sftpgo.service\n</code></pre> <p>And override the unit definition with the following snippet.</p> <pre><code>[Unit]\nAfter=postgresql.service\n</code></pre> <p>Confirm that <code>sftpgo.service</code> will start after <code>postgresql.service</code> with the next command.</p> <pre><code>$ systemctl show sftpgo.service | grep After=\nAfter=postgresql.service systemd-journald.socket system.slice -.mount systemd-tmpfiles-setup.service network.target sysinit.target basic.target\n</code></pre> <p>Next restart the sftpgo service to use the new configuration and check that it is running.</p> <pre><code>sudo systemctl restart sftpgo\nsystemctl status sftpgo\n</code></pre>"},{"location":"tutorials/postgresql-s3/#create-the-first-admin","title":"Create the first admin","text":"<p>To start using SFTPGo you need to create an admin user, the easiest way is to use the built-in Web admin interface, so open the Web Admin URL and create the first admin user.</p> <p>http://127.0.0.1:8080/web/admin</p>"},{"location":"tutorials/postgresql-s3/#add-virtual-users","title":"Add virtual users","text":"<p>The easiest way to add virtual users is to use the built-in Web interface.</p> <p>So navigate to the Web Admin URL again and log in using the credentials you just set up.</p> <p>http://127.0.0.1:8080/web/admin</p> <p>Click <code>Add</code> and fill the user details, the minimum required parameters are:</p> <ul> <li><code>Username</code></li> <li><code>Password</code> or <code>Public keys</code></li> <li><code>Permissions</code></li> <li><code>Home Dir</code> can be empty since we defined a default base dir</li> <li>Select <code>AWS S3 (Compatible)</code> as storage and then set <code>Bucket</code>, <code>Region</code> and optionally a <code>Key Prefix</code> if you want to restrict the user to a specific virtual folder in the bucket. The specified virtual folder does not need to be pre-created. You can leave <code>Access Key</code> and <code>Access Secret</code> empty since we defined global credentials for the <code>sftpgo</code> user and we use this system user to run the SFTPGo service.</li> </ul> <p>You are done! Now you can connect to you SFTPGo instance using any compatible <code>sftp</code> client on port <code>2022</code>.</p> <p>You can mix S3 users with local users but please be aware that we are running the service as the unprivileged <code>sftpgo</code> system user so if you set storage as <code>local</code> for an SFTPGo virtual user then the home directory for this user must be owned by the <code>sftpgo</code> system user. If you don't specify an home directory the default will be <code>/srv/sftpgo/data/&lt;username&gt;</code> which should be appropriate.</p>"},{"location":"tutorials/sftpgo-aws/","title":"SFTPGo on AWS","text":""},{"location":"tutorials/sftpgo-aws/#sftpgo-on-aws","title":"SFTPGo on AWS","text":"<p>SFTPGo is available on AWS Marketplace:</p> <ul> <li>SFTPGo Enterprise - Starter</li> <li>SFTPGo Enterprise - Premium</li> <li>SFTPGo Enterprise - Starter (arm64)</li> <li>SFTPGo Enterprise - Premium (arm64)</li> </ul> <p>The Starter tier is a cost-effective solution for small to medium-scale file transfer environments. It supports unlimited users and connections, with up to 20 concurrent uploads and downloads. Storage options include local filesystem or Google Cloud buckets. Detailed audit logs are also available directly within the WebAdmin UI.</p> <p>The Premium tier is designed for deployments that require advanced features and greater flexibility. It includes all capabilities of the Starter tier, plus the following features:</p> <ul> <li>Unlimited users and connections, with up to 100 concurrent uploads and downloads.</li> <li>Additional storage backends: Amazon S3 (Compatible), Azure Blob Storage, other SFTP servers.</li> <li>PGP encryption/decryption.</li> <li>Advanced automation through the EventManager.</li> <li>Plugin for Geo-IP filtering via plugins.</li> <li>Plugin for event publishing to systems like Amazon SNS, RabbitMQ, NATS, Kafka, and other publish/subscribe platforms.</li> </ul> <p> We also offer the open-source version of SFTPGo on AWS Marketplaces. These offers were introduced before the availability of SFTPGo Enterprise and remain fully supported. However, we recommend transitioning to the Starter or Premium tiers to take full advantage of the enhanced features and improved performance provided by SFTPGo Enterprise.</p>"},{"location":"tutorials/sftpgo-aws/#deploy-from-marketplace","title":"Deploy from Marketplace","text":"<p>Access the SFTPGo offering of your choice in AWS Marketplace and click the Try for free button.</p> <p></p> <p>You will be redirected to the AWS subscription screen, where you can select the pricing model. SFTPGo offers use a usage-based pricing model, with the option to save by selecting an annual contract.</p> <p>After selecting your preferred pricing model, click \u201cSubscribe\u201d to complete the subscription.</p> <p></p> <p>Select your preferred AWS region and launch the SFTPGo offer from the EC2 console. The suggested security rules will allow the following ports:</p> <ul> <li>TCP port 8080 is the default port for the SFTPGo WebAdmin and WebClient user interfaces. It will be used for the initial configuration.</li> <li>TCP port 2022 is the default port for the SFTP service.</li> <li>TCP port 22 is the port used for the SSH service (OpenSSH), which is useful for remote access and management of your virtual machine.</li> </ul> <p>Additionally you may consider to add:</p> <ul> <li>TCP port 80 (HTTP traffic from the Internet) is required to obtain and renew Let's Encrypt TLS certificates.</li> <li>TCP port 443 (HTTPS traffic from the Internet) is useful if you want enable HTTPS for the SFTPGo WebAdmin and WebClient and reconfigure SFTPGo to use the standard HTTPS port.</li> </ul> <p>After deploying the virtual machine make note of its IP address and instance ID.</p> <p></p>"},{"location":"tutorials/sftpgo-aws/#create-the-initial-administrator-account","title":"Create the initial administrator account","text":"<p>Before you can use SFTPGo you need to create an admin account, so open http://your_instance_IP:8080/web/admin in your web browser, replacing <code>Your instance ID</code> with the ID of your instance, which you can find in the AWS Console.</p> <p></p> <p>The instance ID is required to validate your installation.</p> <p>After creating the admin account you will be automatically logged in and redirected to the page to set up two-factor authentication. Setting up two-factor authentication is optional.</p> <p></p>"},{"location":"tutorials/sftpgo-aws/#licensed-features","title":"Licensed Features","text":"<p>You can view the enabled licensed features by navigating to the \"License\" section under \"Server Manager\".</p> <p></p>"},{"location":"tutorials/sftpgo-google-cloud/","title":"SFTPGo on Google Cloud Platform","text":""},{"location":"tutorials/sftpgo-google-cloud/#sftpgo-on-google-cloud-platform","title":"SFTPGo on Google Cloud Platform","text":"<p>SFTPGo is available on Google Cloud Marketplace:</p> <ul> <li>SFTPGo Enterprise - Starter</li> <li>SFTPGo Enterprise - Premium</li> </ul> <p>The Starter tier is a cost-effective solution for small to medium-scale file transfer environments. It supports unlimited users and connections, with up to 20 concurrent uploads and downloads. Storage options include local filesystem or Google Cloud buckets. Detailed audit logs are also available directly within the WebAdmin UI.</p> <p>The Premium tier is designed for deployments that require advanced features and greater flexibility. It includes all capabilities of the Starter tier, plus the following features:</p> <ul> <li>Unlimited users and connections, with up to 100 concurrent uploads and downloads.</li> <li>Additional storage backends: Amazon S3 (Compatible), Azure Blob Storage, other SFTP servers.</li> <li>PGP encryption/decryption.</li> <li>Advanced automation through the EventManager.</li> <li>Plugin for Geo-IP filtering via plugins.</li> <li>Plugin for event publishing to systems like Amazon SNS, RabbitMQ, NATS, Kafka, and other publish/subscribe platforms.</li> </ul> <p> We also offer SFTPGo Standard and Professional editions, both based on the open-source version of SFTPGo. These editions were introduced before the availability of SFTPGo Enterprise and remain fully supported. However, we recommend transitioning to the Starter or Premium tiers to take full advantage of the enhanced features and improved performance provided by SFTPGo Enterprise.</p>"},{"location":"tutorials/sftpgo-google-cloud/#deploy-from-marketplace","title":"Deploy from Marketplace","text":"<p>Access the SFTPGo offering of your choice in Google Cloud Marketplace and click the Launch button.</p> <p></p> <p>You may be asked to enable the required API, please enable them.</p> <p></p> <p>Specify your deployment options such as the zone, machine type, disk type. A firewall configuration is proposed.</p> <p></p> <p>Add network traffic restrictions and enable rules based on your specific security requirements. Here what the proposed ports are used for:</p> <ul> <li>TCP port 8080 is the default port for the SFTPGo WebAdmin and WebClient user interfaces. It will be used for the initial configuration.</li> <li>TCP port 2022 is the default port for the SFTP service.</li> <li>TCP port 22 is the port used for the SSH service (OpenSSH), which is useful for remote access and management of your virtual machine.</li> <li>TCP port 80 (HTTP traffic from the Internet) is required to obtain and renew Let's Encrypt TLS certificates.</li> <li>TCP port 443 (HTTPS traffic from the Internet) is useful if you want enable HTTPS for the SFTPGo WebAdmin and WebClient and reconfigure SFTPGo to use the standard HTTPS port.</li> </ul> <p> If you want to use SFTP on port 22 you need to reconfigure OpenSSH to use a different port.</p> <p>After configuring your virtual machine, click Deploy, after few minutes your SFTPGo installation will be ready to use.</p> <p></p> <p>By clicking on the deployed Compute Engine, you can view the IP address of your new SFTPGo installation.</p>"},{"location":"tutorials/sftpgo-google-cloud/#create-the-initial-administrator-account","title":"Create the initial administrator account","text":"<p>Before you can use SFTPGo you need to create an admin account, so open http://your_instance_IP:8080/web/admin in your web browser, replacing <code>your instance IP</code> with the IP address of your instance.</p> <p></p> <p>After creating the admin account you will be automatically logged in and redirected to the page to set up two-factor authentication. Setting up two-factor authentication is optional.</p> <p></p>"},{"location":"tutorials/sftpgo-google-cloud/#licensed-features","title":"Licensed Features","text":"<p>You can view the enabled licensed features by navigating to the \"License\" section under \"Server Manager\".</p> <p></p>"},{"location":"tutorials/sftpgo-google-cloud/#enable-https-and-obtain-a-lets-encrypt-tls-certificate","title":"Enable HTTPS and obtain a Let's Encrypt TLS certificate","text":"<p>In order to obtain a Let's Encrypt TLS certificate for HTTPS access you must create a DNS entry under a custom domain that you own which resolves to your SFTPGo public IP address and the port 80 must be publicly reachable. Also make sure your Compute instance has a static IP address.</p> <p>From the SFTPGo WebAdmin UI go to the \"Server Manager\" section, select \"Configurations\" and then \"ACME\". Specify the domain name associated with the IP address of the virtual machine, set an email address, and the protocols for which you want to use the certificate. Leave the port at <code>80</code>.</p> <p></p> <p>Click Save.</p> <p>To apply the change you need to restart the SFTPGo service, so login via SSH to your virtual machine and execute the following command.</p> <pre><code>sudo systemctl restart sftpgo\n</code></pre> <p>You can now access your installation using https://your_domain_name:8080/.</p>"},{"location":"tutorials/sftpgo-google-cloud/#reconfigure-sftpgo-to-use-the-standard-https-port","title":"Reconfigure SFTPGo to use the standard HTTPS port","text":"<p>Login to your virtual machine via SSH change the port by creating a file named <code>/etc/sftpgo/env.d/custom.env</code> with the following content.</p> <pre><code>SFTPGO_HTTPD__BINDINGS__0__PORT=443\n</code></pre> <p>Restart the service to apply the changes.</p> <pre><code>sudo systemctl restart sftpgo\n</code></pre> <p>You can now access your installation using https://your_domain_name/.</p>"},{"location":"tutorials/sftpgo-google-cloud/#reconfigure-sftpgo-to-use-the-port-22-for-sftp","title":"Reconfigure SFTPGo to use the port 22 for SFTP","text":"<p>To make the SFTP service provided by SFTPGo available on port 22, the OpenSSH service must to be re-configured to use a different port.</p> <p>Stop the SFTPGo service.</p> <pre><code>sudo systemctl stop sftpgo\n</code></pre> <p>Create the file <code>/etc/ssh/sshd_config.d/10-port.conf</code> with the following content.</p> <pre><code>Port 2022\n</code></pre> <p>Restart OpenSSH to apply the change.</p> <pre><code>sudo systemctl restart sshd\n</code></pre> <p>Verify that OpenSSH was able to start correctly.</p> <pre><code>systemctl status sshd\n</code></pre> <p>You should see something like this.</p> <pre><code>Mar 05 09:48:30 sftpgo-2-vm systemd[1]: Starting ssh.service - OpenBSD Secure Shell server...\nMar 05 09:48:30 sftpgo-2-vm sshd[1196]: Server listening on 0.0.0.0 port 2022.\nMar 05 09:48:30 sftpgo-2-vm sshd[1196]: Server listening on :: port 2022.\n</code></pre> <p>To reconfigure SFTPGo to use port <code>22</code> for SFTP create or update the file <code>/etc/sftpgo/env.d/custom.env</code> and add the following content.</p> <pre><code>SFTPGO_SFTPD__BINDINGS__0__PORT=22\n</code></pre> <p>Restart the SFTPGo service to apply the changes.</p> <pre><code>sudo systemctl restart sftpgo\n</code></pre> <p> Make sure OpenSSH is running properly and can accept new SSH connections before disconnecting your current SSH session to avoid becoming locked out of the system.</p>"},{"location":"tutorials/shares/","title":"Public Shares","text":""},{"location":"tutorials/shares/#public-shares","title":"Public Shares","text":"<p>Public shares are a quick and secure way to share files directly from the WebClient UI without creating user accounts, making collaboration with external contacts simple and efficient.</p> <p>Each public share generates a unique, web-accessible URL, and users can configure access controls such as:</p> <ul> <li>Read-only or upload permissions</li> <li>Optional password protection</li> <li>Expiration date</li> <li>Download/upload limits</li> <li>Email-based access for extra security</li> </ul> <p>Public shares are managed by the users themselves, not by administrators. This makes it easy for users with access to files to securely collaborate with clients, partners, or external collaborators \u2014 without requiring administrator intervention.</p>"},{"location":"tutorials/shares/#preliminary-note","title":"Preliminary Note","text":"<p>To enable email-based access to public shares and email notifications, you need to configure an SMTP server.</p> <p>To configure and test your SMTP settings, open the WebAdmin UI, then go to the \"Configurations\" page under the \"Server Manager\" section. There, you can enter the required SMTP configuration parameters.</p> <p></p>"},{"location":"tutorials/shares/#create-a-share-with-email-authentication","title":"Create a Share with Email Authentication","text":"<p>To share a file or folder, open the WebClient, click the three-dot menu next to the item, and select \"Share\".</p> <p></p> <p>Next, configure the sharing options. You can define the access level\u2014read, write, or read/write\u2014to control what actions recipients are allowed to perform.</p> <p>To enable email-based authentication, enter one or more email addresses and check the \"Email authentication\" option.</p> <p></p> <p>You can also require recipients to accept a (customizable) legal agreement before accessing the share. Additionally, you can set an expiration date, limit the maximum number of accesses, and restrict access to specific IP addresses or networks.</p> <p></p> <p>To share content with external users, go to the \"Shares\" page, click the \"Link\" icon next to the desired share, and copy the access URL. In most cases, a single directory will be shared.</p> <p></p>"},{"location":"tutorials/shares/#how-external-users-access-the-share","title":"How External Users Access the Share","text":"<p>External users can access the share link by entering their email address, after which they receive a one-time login code via email, valid for 10 minutes.</p> <p></p> <p></p> <p>The content visible to the user depends on the type of share they\u2019ve been granted access to.</p>"},{"location":"tutorials/shares/#read-only-shares","title":"Read-Only Shares","text":"<p>Read-only shares allow external users to browse the shared directories and files. Users can view file names, structure, and metadata (such as file size and modification date), but cannot upload, modify, or delete any content.</p> <p>Users can:</p> <ul> <li>Download individual files directly.</li> <li>Download all shared files and folders as a single compressed .zip archive for convenience.</li> </ul> <p>This share type is ideal for securely distributing documents, reports, or any other files where write access is not required.</p> <p></p>"},{"location":"tutorials/shares/#write-only-shares","title":"Write-Only shares","text":"<p>Write-only shares allow external users to upload files to a shared location, but they cannot view, browse, or download any existing content.</p> <p>Upon accessing the share, users see a simple upload interface that displays:</p> <ul> <li>The name of the share, to provide context.</li> <li>Options to select files manually or use drag and drop for quick uploads.</li> </ul> <p></p>"},{"location":"tutorials/shares/#readwrite-shares","title":"Read/write Shares","text":"<p>Read/write shares provide external users with full access to the shared content, allowing them to:</p> <ul> <li>Browse files and folders within the share.</li> <li>Download individual files or the entire shared content as a .zip archive.</li> <li>Upload new files via manual selection or drag and drop.</li> <li>Create new folders within the shared structure.</li> </ul> <p>This type of share combines the capabilities of both read-only and write-only shares, making it ideal for collaborative scenarios where external users need to both access and contribute files to a shared workspace.</p> <p></p>"},{"location":"tutorials/shares/#delegating-share-management","title":"Delegating Share Management","text":"<p>By default, a public share is managed only by the user who created it. However, in collaborative environments, you may need to allow colleagues to manage your shares for example, to extend an expiration date or revoke access while you are on vacation.</p> <p>SFTPGo allows you to associate one or more groups with a share. When a share is assigned to a group, other users within that group (who have the necessary permissions) can view and manage the share, with specific limitations to ensure security and data consistency.</p> <p>This feature ensures business continuity and allows teams to collaboratively manage external data exchange without relying on a single account.</p> <p>Only the owner can modify shared paths (files and folders), access scope (read/write), and group associations. File paths are tied to the specific context of the user who created the share (e.g., a virtual path like <code>/docs</code> may map to different storage backends, or to different locations within the same backend, depending on the user).</p> <p>To enable share delegation, a specific configuration is required on the server side (WebAdmin), which then enables the feature for users in the WebClient.</p>"},{"location":"tutorials/shares/#administrator-configuration-webadmin","title":"Administrator Configuration (WebAdmin)","text":"<p>Administrators can define the Share Policy within the \"Advanced settings\" section of a group's configuration. The policy controls how shares created by group members are automatically associated with the group.</p> <p>The policy consists of the Permissions granted to other group members (Read, Edit, Delete) and the Mode:</p> <ul> <li>Enforced: The share policy is mandatory. Every share created by a user in this group is automatically associated with the group using the defined permissions. The user cannot remove this association.</li> <li>Suggested: The share policy is pre-selected by default when creating a share, but the user is free to modify the permissions or remove the group association entirely.</li> </ul> <p></p>"},{"location":"tutorials/shares/#user-experience-webclient","title":"User Experience (WebClient)","text":"<p>When users create or edit a share in the WebClient UI, they can control the group access based on the policy configured by the administrator.</p> <p></p> <p>In the example above, the \"Read\" permission was granted for \"group1\". This results in the following behavior:</p> <ul> <li>Visibility: All members of \"group1\" will see this share in their list, in addition to the shares they created themselves.</li> <li>Access: Because only \"Read\" was granted, they can view the share details (e.g., the link) but cannot modify its settings or delete it.</li> </ul> <p>If \"Edit\" or \"Delete\" permissions were granted, members of \"group1\" would also be able to modify the share's settings (such as the expiration date) or revoke the share entirely.</p>"},{"location":"tutorials/shares/#automatically-send-share-links","title":"Automatically Send Share Links","text":"<p>Administrators can configure an Event Manager rule and corresponding action from the WebAdmin UI to automatically send an email notification to all email addresses associated with a share whenever a new share is created. The email includes the access link, ensuring that recipients are promptly notified without requiring any manual steps.</p> <p>From the WebAdmin UI, create an email action similar to the example below.</p> <p></p> <p>Use the <code>{{.Email}}</code> placeholder to automatically insert the email addresses associated with the share\u2014these are the recipients who can authenticate to access it.</p> <p>The share access URL follows this format:</p> <pre><code>https://sftp.example.com/web/client/pubshares/{{.ObjectName | urlPathEscape }}/browse\n</code></pre> <p>Where:</p> <ul> <li><code>https://sftp.example.com</code> is the externally accessible base URL of your SFTPGo installation.</li> <li><code>{{.ObjectName}}</code> expands to the ID of the share.</li> <li>The <code>urlPathEscape</code> helper function ensures the share ID is properly URL-encoded.</li> </ul> <p>Finally, create an Event Manager rule that triggers this action whenever a new share is created.</p> <p> </p>"},{"location":"tutorials/shares/#enable-uploaddownload-notifications","title":"Enable Upload/Download Notifications","text":"<p>SFTPGo allows administrators to configure notifications when an external user uploads or downloads a file through a share.</p> <p>For example, you can set up an Event Manager rule and action to automatically send an email notification to the SFTPGo user who created the share. The notification can include:</p> <ul> <li>The name and details of the file uploaded or downloaded.</li> <li>The email address of the external user who accessed the share and performed the action.</li> </ul> <p>Here is an example action.</p> <p></p> <p>In this case, the action is triggered by a file system event (such as an upload or download), so:</p> <ul> <li>The <code>{{.Email}}</code> placeholder expands to the email address of the SFTPGo user who created the share.</li> <li>The <code>{{.ExtName}}</code> placeholder expands to the email address used by the external user to access the share.</li> </ul> <p>Here is an example rule to execute the above action.</p> <p></p> <p>Naturally, all operations performed on shares, including uploads and downloads, also recorded in the audit logs.</p>"},{"location":"tutorials/shares/#automating-share-lifecycle-management","title":"Automating Share Lifecycle Management","text":"<p>SFTPGo can automatically manage the lifecycle of public shares to ensure security and compliance. By using the Event Manager, administrators can configure rules to detect shares that are inactive, about to expire, or have exhausted their allowed tokens, and take appropriate actions (such as sending a notification or deleting the share).</p>"},{"location":"tutorials/shares/#step-1-create-the-expiration-check-action","title":"Step 1: Create the Expiration Check Action","text":"<p>First, you need to define the criteria for what constitutes an \"expired\" or \"inactive\" share.</p> <ol> <li>Go to EventManager -&gt; Actions and click Add.</li> <li>Select Share expiration check as the action type.</li> <li>Configure the following parameters:<ul> <li>Inactivity threshold: Defines the validity period (in days) for shares without an explicit expiration date. The expiration is calculated based on the last usage time (or the creation time if the share has never been used). If set to 0, automatic expiration based on inactivity is disabled.</li> <li>Advance notice: How many days before the actual expiration (or the calculated inactivity expiration) to trigger a \"notification\" event.</li> <li>Grace period: How many days to keep an expired share in the database before permanently deleting it (Soft Delete).</li> <li>Split events:<ul> <li>If enabled: The action triggers a separate event for every single share/user found. This populates the <code>{{.ShareExpirationResult}}</code> placeholder, making it ideal for Email notifications where you need the context of a specific share owner.</li> <li>If disabled: The action generates a single event containing the results of all checks. The <code>{{.ShareExpirationChecks}}</code> list is always available in both modes, but this mode is ideal for HTTP webhooks or admin reports where you want to process all data in bulk.</li> </ul> </li> </ul> </li> </ol>"},{"location":"tutorials/shares/#step-2-configure-the-notification-email-or-http","title":"Step 2: Configure the Notification (Email or HTTP)","text":"<p>Once the check is performed, you usually want to do something with the results. You can chain a second action to handle this.</p>"},{"location":"tutorials/shares/#scenario-a-email-notification-to-share-owners","title":"Scenario A: Email Notification to Share Owners","text":"<p>If you enabled Split events in the previous step, you can send a personalized email to the user who created the share (and all group members if the share is in \"warning\" state).</p> <p>Create an Email action with the following template:</p> <p>Subject:</p> <pre><code>Update regarding your shared files\n</code></pre> <p>Body:</p> <pre><code>Hello {{.Name}},\n\nThe following share requires your attention:\n\nShare Name: {{.ShareExpirationResult.Share.Name}}\nID: {{.ShareExpirationResult.Share.ShareID}}\nExpiration Date: {{.ShareExpirationResult.Expiration.Format \"2006-01-02\"}}\n\nStatus: {{ if eq .ShareExpirationResult.Action 1}}Expiring soon{{else}}Expired and deleted{{end}}\nReason: {{.ShareExpirationResult.Reason}}\n\n{{if eq .ShareExpirationResult.Action 1 -}}\nPlease extend the expiration date if you wish to keep this share active.\n{{- else -}}\nThis share has been removed permanently.\n{{- end}}\n</code></pre>"},{"location":"tutorials/shares/#scenario-b-http-report-to-an-external-system","title":"Scenario B: HTTP Report to an External System","text":"<p>If you disabled \"Split events\", you receive a list of all checks in a single payload. You can send this to an external webhook for auditing.</p> <p>Create an HTTP action with a JSON body like this:</p> <pre><code>{\n  \"timestamp\": \"{{.Timestamp.Format \"2006-01-02T15:04:05Z07:00\"}}\",\n  \"report\": {{ toJson .ShareExpirationChecks }}\n}\n</code></pre> <p>The <code>{{.ShareExpirationChecks}}</code> placeholder will expand to a JSON array containing the users and their respective share results.</p>"},{"location":"tutorials/shares/#step-3-define-the-rule","title":"Step 3: Define the Rule","text":"<p>Finally, create a Rule to execute these actions periodically.</p> <ol> <li>Go to Event Manager -&gt; Rules and click Add.</li> <li>Trigger: Select Schedule.</li> <li>Schedule: Define how often to run the check (e.g., daily at 02:00 AM).</li> <li>Actions: Add the actions created in the previous steps in the following order:<ol> <li>The Share expiration check action.</li> <li>The Notification action (Email or HTTP).</li> </ol> </li> </ol>"},{"location":"tutorials/shares/#how-it-works","title":"How it works","text":"<p>When the rule executes:</p> <ol> <li>SFTPGo scans all shares that meet the rules' conditions.</li> <li>If a share is within the Advance notice window, it is flagged with <code>Action: 1</code> (Notify).</li> <li>If a share has passed its expiration (plus the Grace period), it is flagged with <code>Action: 2</code> (Delete) and removed from the database.</li> <li>If Split events is active:<ul> <li>Individual actions are executed for the notification step.</li> <li>Group Shares: If a share belongs to a group and is in the \"Notify\" state, the event is expanded to all group members so everyone is aware. If the share is in the \"Delete\" state, the event is executed only for the owner to avoid redundant notifications.</li> </ul> </li> </ol>"},{"location":"tutorials/two-factor-authentication/","title":"Two-factor Authentication","text":""},{"location":"tutorials/two-factor-authentication/#two-factor-authentication-2fa","title":"Two-factor Authentication (2FA)","text":"<p>Two-factor authentication (also known as 2FA) is a subset of multi-factor authentication. It allows SFTPGo users and admins to enable additional protection for their account by requiring a combination of two different authentication factors:</p> <ul> <li>something they know (e.g. their password)</li> <li>something they have (usually their smartphone).</li> </ul> <p>2FA is an excellent way to improve your security profile and provide an added layer of protection to your data.</p> <p>SFTPGo supports authenticator apps that use TOTP (time based one-time password). These include apps such as Authy, Google Authenticator and any other apps that support time-based one time passwords (RFC 6238).</p>"},{"location":"tutorials/two-factor-authentication/#preliminary-note","title":"Preliminary Note","text":"<p>Before proceeding further you need a working SFTPGo installation.</p>"},{"location":"tutorials/two-factor-authentication/#configure-sftpgo","title":"Configure SFTPGo","text":"<p>Two-factor authentication is enabled by default with the following settings.</p> <pre><code>  \"mfa\": {\n    \"totp\": [\n      {\n        \"name\": \"Default\",\n        \"issuer\": \"SFTPGo\",\n        \"algo\": \"sha1\"\n      }\n    ]\n  },\n</code></pre> <p>The <code>issuer</code> and <code>algo</code> are visible/used in the authenticators apps. For example, you could set your company/organization name as <code>issuer</code> and an <code>algo</code> appropriate for your target apps/devices. The supported algorithms are: <code>sha1</code>, <code>sha256</code>, <code>sha512</code>. Currently Google Authenticator app on iPhone seems to only support <code>sha1</code>, please check the compatibility with your target apps/device before setting a different algorithm.</p> <p>You can also define multiple configurations, for example one that uses <code>sha256</code> or <code>sha512</code> and another one that uses <code>sha1</code> and instruct your users to use the appropriate configuration for their devices/apps. The algorithm should not be changed if there are users or admins using the configuration. The <code>name</code> is visible to the users/admins when they select the 2FA configuration to use and it must be unique. A configuration name should not be changed if there are users or admins using it.</p> <p>SFTPGo can use 2FA for <code>HTTP</code>, <code>SSH</code> (SFTP, SCP) and <code>FTP</code> protocols.</p>"},{"location":"tutorials/two-factor-authentication/#enable-2fa-for-admins","title":"Enable 2FA for admins","text":"<p>Each admin can view/change his/her two-factor authentication by selecting the <code>Two-Factor Auth</code> link from the top-right web UI menu.</p> <p></p> <p>Then select a configuration and click \"Generate new secret key\". A QR code will be generated which you can scan with a compatible app. After you configured your app, enter a test code to ensure everything works correctly and click on \"Save\".</p> <p></p> <p>Then save the configuration.</p> <p>SFTPGo automatically generates some recovery codes. They are a set of one time use codes that can be used in place of the TOTP to login to the web UI. You can use them if you lose access to your phone to login to your account and disable or regenerate TOTP configuration.</p> <p>2FA is now enabled, so the next time you login with this admin you have to provide a valid authentication code after your password.</p> <p></p> <p>Two-factor authentication will also be required to use the REST API as this admin. You can provide the authentication code using the <code>X-SFTPGO-OTP</code> HTTP header.</p> <p>If an admin loses access to their second factor auth device and has no recovery codes, another admin can disable second factor authentication for him/her using the <code>/api/v2/admins/{username}/2fa/disable</code> REST endpoint.</p> <p>For example:</p> <pre><code>curl -X 'PUT' \\\n  'http://localhost:8080/api/v2/admins/admin/2fa/disable' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOlsiQVBJIl0sImV4cCI6MTYzOTkzMTE3MiwianRpIjoiYzZ2bGd0NjEwZDFxYjZrdTBiNWciLCJuYmYiOjE2Mzk5Mjk5NDIsInBlcm1pc3Npb25zIjpbIioiXSwic3ViIjoiV20rYTF2bnVVc1VRYXA0TVZmSGtseWxObmR4TCswYVM3OVVjc1hXZitzdz0iLCJ1c2VybmFtZSI6ImFkbWluMSJ9.043lQFq7WRfJ-rdoCbp_TXEHbAo8Ihj5CAh3k8JQVQQ'\n</code></pre> <p>If you prefer a web UI instead of a CLI command to disable 2FA you can use the swagger UI interface available, by default, at the following URL <code>http://localhost:8080/openapi/swagger-ui</code>.</p>"},{"location":"tutorials/two-factor-authentication/#enable-2fa-for-users","title":"Enable 2FA for users","text":"<p>Two-factor authentication is enabled by default for all SFTPGo users. Admins can disable 2FA per-user by selecting <code>mfa-disabled</code> in the Web client/REST API restrictions.</p> <p></p> <p>If 2FA is not disabled each user can enable it by selecting \"Two-factor auth\" from the left menu in the web UI.</p> <p>Users can enable 2FA for HTTP, SSH and FTP protocols.</p> <p>SSH protocol (SFTP/SCP/SSH commands) will ask for the passcode if the client uses keyboard interactive authentication.</p> <p>HTTP protocol means Web UI and REST APIs. Web UI will ask for the passcode using a specific page. For REST APIs you have to specify the passcode using the <code>X-SFTPGO-OTP</code> HTTP header.</p> <p>FTP has no standard way to support two factor authentication, if you enable the FTP protocol, you have to add the TOTP passcode after the password. For example if your password is \"password\" and your one time passcode is \"123456\" you have to use \"password123456\" as password.</p> <p>To enable 2FA select the wanted protocols, a configuration and click \"Generate new secret key\". A QR code will be generated which you can scan with a compatible app. After you configured your app, enter a test code to ensure everything works correctly and click on \"Save\".</p> <p></p> <p>Then save the configuration.</p> <p>SFTPGo automatically generates some recovery codes. They are a set of one time use codes that can be used in place of the TOTP to login to the web UI. You can use them if you lose access to your phone to login to your account and disable or regenerate TOTP configuration.</p> <p>2FA is now enabled, so the next time you login with this user you have to provide a valid authentication code after your password.</p> <p></p> <p>Two-factor authentication will be also required to use the REST API as this user. You can provide the authentication code using the <code>X-SFTPGO-OTP</code> header.</p> <p>If this user tries to login via SFTP it must provide a valid authentication code after the password.</p> <pre><code>$ sftp -P 2022 nicola@127.0.0.1\n(nicola@127.0.0.1) Password:\n(nicola@127.0.0.1) Authentication code:\nConnected to 127.0.0.1.\nsftp&gt; quit\n</code></pre> <p>If a user loses access to their second factor auth device and has no recovery codes then an admin can disable the second factor authentication using the <code>/api/v2/users/{username}/2fa/disable</code> REST endpoint.</p> <p>For example:</p> <pre><code>curl -X 'PUT' \\\n  'http://localhost:8080/api/v2/users/nicola/2fa/disable' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOlsiQVBJIl0sImV4cCI6MTYzOTkzMzI1MywianRpIjoiYzZ2bTE1ZTEwZDFxcG9iamc3djAiLCJuYmYiOjE2Mzk5MzIwMjMsInBlcm1pc3Npb25zIjpbIioiXSwic3ViIjoiV20rYTF2bnVVc1VRYXA0TVZmSGtseWxObmR4TCswYVM3OVVjc1hXZitzdz0iLCJ1c2VybmFtZSI6ImFkbWluMSJ9.ntR0L2JTuwYwhBy6c0iu10rdmycLdtKZtmDObQ0PUoo'\n</code></pre> <p>If you prefer a web UI instead of a CLI command to disable 2FA you can use the swagger UI interface available, by default, at the following URL <code>http://localhost:8080/openapi/swagger-ui</code>.</p>"}]}